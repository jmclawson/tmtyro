---
title: "Ramping up skills"
subtitle: "Stepping into dplyr"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(dplyr)
library(tmtyro)
```

tmtyro is optimized for a fast start, speeding users along a standard workflow built on tidytext and the tidyverse. But it also serves as a skills ramp, offering vectorized functions that work seamlessly with a broader ecosystem of tools. These functions provide a stepping stone for users transitioning to text mining workflows that leverage the flexibility and power of dplyr. The vectorized functions outlined below present an alternative pathway to the workflows enabled by functions like `add_frequency()` and `add_sentiment()`, bridging the gap to more advanced techniques.

## Working with vectors

We often work with text as a vector of words, sometimes thought of as a "bag" of words. In this form, everything is typically standardized into lowercase spellings, punctuation marks are removed, and words are split at spaces:

```{r}
library(stringr)
primer <- "See Jack run. Run, Jack! Run well!" |> 
  tolower() |> 
  str_remove_all("[:punct:]") |>
  strsplit(" ") |> 
  unlist()

primer
```

tmtyro offers functions for working with such lists or bags of words, returning an equal-length list of some measurement or test. For instance, `get_frequency()` returns word counts for each word in a list:

```{r}
get_frequency(primer)
```

These counts can be converted to percentages by adding `percent = TRUE` or by using the shorthand `get_tf()`:

```{r}
get_frequency(primer, percent = TRUE)

get_tf(primer)
```

Most of tmtyro's functions for working with vectors begin with `get_...()`. This standardization helps to simplify autocomplete. Additionally, two logical tests beginning with `is_...()` return values `TRUE` or `FALSE`:

```{r}
#| echo: false
library(gt)
transitive <- make_dictionary(
  list(
    "no" = "run",
    "yes" = "see"))

tm_fn <- c(
  "`get_frequency()`",
  "`get_frequency(percent = FALSE)` <br>or<br> `get_tf()`",
  "`get_cumulative_vocabulary()`",
  "`get_ttr()`",
  "`get_htr()`",
  "`get_hir()`",
  "`get_match()`",
  "`get_sentiment()`",
  "`is_new()`",
  "`is_hapax()`")

tm_exp <- c(
  "word frequencies as counts",
  "word frequencies as percentages",
  "cumulative count of new words",
  "cumulative type-token ratio",
  "cumulative hapax-token ratio",
  "hapax introduction rate",
  "word matches according to a dictionary",
  "word matches according to a sentiment dictionary",
  "whether a word is newly being added to the list",
  "whether a word is used only once in the list")

tm_code <- c(
  "`get_frequency(primer)`",
  "`get_tf(primer)`",
  "`get_cumulative_vocabulary(primer)`",
  "`get_ttr(primer)`",
  "`get_htr(primer)`",
  "`get_hir(primer)`",
  "`get_match(primer, verbs)`",
  "`get_sentiment(primer)`",
  "`is_new(primer)`",
  "`is_hapax(primer)`")

tm_result <- list(
  get_frequency(primer),
  get_tf(primer),
  get_cumulative_vocabulary(primer),
  get_ttr(primer),
  get_htr(primer),
  get_hir(primer),
  get_match(primer, transitive),
  get_sentiment(primer),
  is_new(primer),
  is_hapax(primer)) |> 
  purrr::map({\(x) 
    if (is.double(x)) {
      round(x, 2)
    } else if (is.character(x)) {
      paste0("â€œ", x, "â€")
    } else {
      x
    }}) |> 
  purrr::map(\(x) tidyr::replace_na(x, "NA")) |> 
  purrr::map({
   \(x)
    paste0("`", x, "`")
  }) |> 
  purrr::map(\(x) str_replace_all(x, "â€œNAâ€", "NA")) |> 
  purrr::map_chr(str_flatten_comma)

tm_table <- data.frame(
  fn = tm_fn,
  returns = tm_exp,
  use = tm_code,
  result = tm_result
)

tm_table |> 
  gt() |> 
  fmt_markdown(columns = c(fn, use, result)) |> 
  cols_label(
    fn = "tmtyro function"
  )
```

Working with and becoming familiar with these vectorized functions can be a useful step for gaining confidence in working with text data.

## Working with tables

Although text analysis often conceives of documents as bags of words, tmtyro typically follows tidytext principals to go further, with data organized in a table with one word per row. This method of organization allows for both *context*, in rows above and below, and *understanding*, in columns to the left and right. 

### Adding columns

tmtyro's typical workflow offers a selection of verbs for adding new columns---all helpfully beginning with `add_...()`. Alternatively, the vector functions listed above work well with dplyr's `mutate()` for adding columns:

```{r}
#| message: false
# Load a corpus
corpus_dubliners <- get_gutenberg_corpus(2814) |> 
  load_texts() |> 
  identify_by(part) |> 
  standardize_titles() |> 
  select(doc_id, word)

# Use mutate() to add columns
corpus_dubliners |> 
  mutate(
    count = get_frequency(word),
    percent = get_tf(word),
    new = is_new(word),
    hapax = is_hapax(word))
```

### Grouping documents

Not every measurement makes sense in a big corpus, where we might care more about things on a document-by-document basis. For this reason, tmtyro offers a few additional functions for measuring grouped values. Functions of this type are named in a pattern using `get_..._by()`:

```{r}
#| echo: false
tm_grp_fn <- c(
  "`get_tf_by()`",
  "`get_idf_by()`",
  "`get_tfidf_by()`")

tm_grp_returns <- c(
  "term frequencies (as a percentage) for each word by document",
  "inverse document frequencies for each word by document",
  "term frequency--inverse document frequencies for each word by document")

tm_grp_table <- data.frame(
  fn = tm_grp_fn,
  returns = tm_grp_returns)

tm_grp_table |> 
  gt() |> 
  fmt_markdown(columns = c(fn, returns)) |> 
  cols_label(
    fn = "function"
  )
```

Because they expect two arguments of equal length, these kinds of vector-document functions are best suited for data organized in a table. All of these `get_..._by()` functions use the same syntax:

```{r}
#| message: false
corpus_dubliners |> 
  mutate(
    tf = get_tf_by(word, doc_id),
    idf = get_idf_by(word, doc_id),
    tf_idf = get_tfidf_by(word, doc_id))
```

Native to dplyr, `group_by()` and `ungroup()` offer another method for calculating values by document:

```{r}
corpus_dubliners |> 
  group_by(doc_id) |> 
  mutate(
    tf = get_tf(word)) |> 
  ungroup()
```

Be aware that that there's no equivalent `get_idf()` or `get_tfidf()` for pairing with `group_by()`. By definition, these calculations need contextual awareness of documents in a corpus. 

Using dplyr in this way allows for a range of measurements beyond those imagined in tmtyro. For instance, it might be helpful to express term frequencies in terms of how far they are from average use:

```{r}
unique_usage <- corpus_dubliners |> 
  group_by(doc_id) |> 
  mutate(
    tf = get_tf(word),
    mean = mean(tf, na.rm = TRUE),
    sd = sd(tf, na.rm = TRUE),
    z_score = (tf - mean)/sd) |> 
  ungroup() |> 
  select(-c(mean, sd))

unique_usage
```

In this way, one could find outlier words by defining them as being at least a standard deviation away from standard usage in a document. 

```{r}
unique_usage |> 
  select(doc_id, word, z_score) |> 
  filter(abs(z_score) >= 1) |> 
  distinct()
```

This particular example unhelpfully emphasizes stopwords, but the process models the kind of checking that often proves helpful when working with text.

### Getting representational data

Instead of studying every word in context, it's sometimes helpful to get representational data from each document. Standard dplyr functions helpfully limit groups to subsets of rows. For instance, `distinct()` drops any rows that repeat:

```{r}
#| message: false
# mutate() keeps every row
simple_freq <- corpus_dubliners |> 
  group_by(doc_id) |> 
  mutate(tf = get_tf(word)) |> 
  ungroup()

# distinct() keeps the first instance of each row
simple_freq |> 
  distinct()
```

Combining elements of both `mutate()` and `distinct()`, the `summarize()` function returns one row per group while allowing new column definitions:

```{r}
#| message: false
# summarize() returns one row per group, here the maximum tf value for combination of doc_id and word
simple_freq |> 
  group_by(doc_id, word) |> 
  summarize(tf = max(tf)) |> 
  ungroup()
```

Offering a little more flexibility, dplyr's `slice_...()` family of functions is helpful for choosing a subset of rows in each group. For instance, `slice_max()` makes it easy to get the top 3 words used in each story from *Dubliners*, ordered by term frequency: 

```{r}
simple_freq |> 
  distinct() |> 
  group_by(doc_id) |> 
  slice_max(
    order_by = tf,
    n = 3) |> 
  ungroup()
```

Other slicing functions like `slice_sample()` and `slice_head()` offer additional options for preparing data to study.

## Dictionary matching

Many of the vectorized `get_...()` functions return numeric or logical results, but two return values based on a dictionary of terms. These functions are perhaps best demonstrated with a new bag of words:

```{r}
primer2 <- "Jack hates rainy days." |> 
  tolower() |> 
  str_remove_all("[:punct:]") |>
  strsplit(" ") |> 
  unlist()
```

The more general `get_match()` function returns the dictionary match for any word or vector. When paired with a dictionary made with `make_dictionary()`, it returns values for any matches found:

```{r}
emoji_weather <- make_dictionary(
  list(
    "ï¸â˜”ï¸" = c("rain", "rains", "rainy", "raining"),
    "ï¸â›ˆï¸" = c("storm", "storms", "stormy", "storming"),
    "â˜ï¸" = c("cloud", "clouds", "cloudy"),
    "ðŸŒž" = c("sun", "sunny"),
    "ðŸŒ«ï¸" = c("fog", "fogs", "foggy", "mist", "misty"),
    "ðŸŒ¬ï¸" = c("wind", "winds", "windy"),
    "ï¸â„ï¸" = c("snow", "snows", "snowing")),
  name = "weather")

primer2
get_match(primer2, emoji_weather)
```

As shown here, unmatched values return `NA` missing values.

The function works with dplyr's `mutate()` much like any other vectorized function:

```{r}
dubliners_weather <- corpus_dubliners |> 
  mutate(weather = get_match(word, emoji_weather))

dubliners_weather |> 
  # show only one story and skip a few hundred words
  filter(doc_id == "The Dead") |> 
  filter(row_number() > 609)

dubliners_weather |> 
  drop_na()
```

### Matching sentiment

A sentiment lexicon is just a special kind of dictionary. To support a specialized case for sentiment analysis, `get_sentiment()` works the same way as `get_match()`:

```{r}
primer2
get_match(primer2, tidytext::get_sentiments("bing"))
get_sentiment(primer2, "bing")
```

Like other functions, it works well with dplyr's `mutate()` for adding a column of sentiment interpretation:

```{r}
corpus_dubliners |> 
  mutate(
    sentiment = get_sentiment(word, "bing")) |> 
  drop_na()
```


## 

By combining simplicity and flexibility, tmtyro helps users move between streamlined workflows and customizable approaches. Whether working with small text datasets or exploring complex corpora, vectorized functions offer a bridge to mastering tools like dplyr. This approach encourages skill development in text mining, data analysis, and broader R programming techniques.
