[{"path":"https://jmclawson.github.io/tmtyro/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 tmtyro authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"getting-started","dir":"Articles","previous_headings":"The easy way with tmtyro","what":"Getting started","title":"Page to Table","text":"’s best start loading necessary package using library() function. tmtyro package provides many simple functions working text, ’s loaded :","code":"library(tmtyro)"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"using-load_texts","dir":"Articles","previous_headings":"The easy way with tmtyro","what":"Using load_texts()","title":"Page to Table","text":"tmtyro loaded, tools available. First load_texts() function, designed load folder texts. use , copy “.txt” files wish study directory project. default, load_texts() look folder called data/ underneath current directory, can tell look elsewhere. example, Jane Austen’s novels saved folder called austen, location added load_texts() function. save work texts later, results need assigned named object. code uses assignment arrow <- assign table name austen_texts: name, table can viewed typing name see whole thing. head() function also useful show just first rows. default, load_texts() prepares three columns: doc_id indicates file name. Think document ID title. par_num indicates paragraph number. Think local context, case ever want use . word divides text one word per row, lowercase. Think letting read book going top bottom, instead left right. point, ’re done! texts loaded table adds structure, making easier apply common methods data analysis. tmtyro’s load_texts() simplified many steps along way.","code":"austen_texts <- load_texts(\"austen/\") head(austen_texts) #> # A tibble: 6 × 3 #>   doc_id par_num word      #>   <chr>    <dbl> <chr>     #> 1 emma         1 volume    #> 2 emma         1 i         #> 3 emma         2 chapter   #> 4 emma         2 i         #> 5 emma         3 emma      #> 6 emma         3 woodhouse"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"the-hard-way","dir":"Articles","previous_headings":"","what":"The hard way","title":"Page to Table","text":"Without resorting packages, can tough effect table. best might build multiple tables, one file, stick together one combined table.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"reading-a-file","dir":"Articles","previous_headings":"The hard way","what":"Reading a file","title":"Page to Table","text":"first step read text file table. tibble() function tibble package readLines() functions make possible: ’ve used assignment arrow <- assign table name emma, can reference later steps even overwrite saving name.","code":"library(tibble)  emma <- tibble(   doc_id = \"emma\",   text = readLines(\"austen/emma.txt\"))  head(emma, n = 15) #> # A tibble: 15 × 2 #>    doc_id text                                                                   #>    <chr>  <chr>                                                                  #>  1 emma   \"\"                                                                     #>  2 emma   \"\"                                                                     #>  3 emma   \"VOLUME I\"                                                             #>  4 emma   \"\"                                                                     #>  5 emma   \"\"                                                                     #>  6 emma   \"\"                                                                     #>  7 emma   \"\"                                                                     #>  8 emma   \"CHAPTER I\"                                                            #>  9 emma   \"\"                                                                     #> 10 emma   \"\"                                                                     #> 11 emma   \"Emma Woodhouse, handsome, clever, and rich, with a comfortable home … #> 12 emma   \"happy disposition, seemed to unite some of the best blessings of\"     #> 13 emma   \"existence; and had lived nearly twenty-one years in the world with v… #> 14 emma   \"little to distress or vex her.\"                                       #> 15 emma   \"\""},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"counting-paragraphs","dir":"Articles","previous_headings":"The hard way","what":"Counting Paragraphs","title":"Page to Table","text":"option results table lot empty lines without paragraph markers, can corrected. mutate() function dplyr package eases process adding new column, paragraph numbering. blank lines offer good way counting paragraphs, using cumsum() function keep running tally: code also chunk shows pipe |> handy passing one step next. Effectively, means result everything pipe |> gets placed inside parentheses whatever function comes pipe |>.","code":"library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  emma <- emma |>    mutate(par_num = cumsum(text == \"\"))  head(emma, n = 15) #> # A tibble: 15 × 3 #>    doc_id text                                                           par_num #>    <chr>  <chr>                                                            <int> #>  1 emma   \"\"                                                                   1 #>  2 emma   \"\"                                                                   2 #>  3 emma   \"VOLUME I\"                                                           2 #>  4 emma   \"\"                                                                   3 #>  5 emma   \"\"                                                                   4 #>  6 emma   \"\"                                                                   5 #>  7 emma   \"\"                                                                   6 #>  8 emma   \"CHAPTER I\"                                                          6 #>  9 emma   \"\"                                                                   7 #> 10 emma   \"\"                                                                   8 #> 11 emma   \"Emma Woodhouse, handsome, clever, and rich, with a comfortab…       8 #> 12 emma   \"happy disposition, seemed to unite some of the best blessing…       8 #> 13 emma   \"existence; and had lived nearly twenty-one years in the worl…       8 #> 14 emma   \"little to distress or vex her.\"                                     8 #> 15 emma   \"\"                                                                   9"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"dropping-empty-lines","dir":"Articles","previous_headings":"The hard way","what":"Dropping empty lines","title":"Page to Table","text":"’s still quite right, since blank lines counted. ’ll drop blank lines recount using different measurement. First things first—filter() function dplyr makes easy select drop rows meet criteria. ’ll tell find rows don’t blank text column:","code":"emma <- emma |>    filter(text != \"\")  head(emma) #> # A tibble: 6 × 3 #>   doc_id text                                                            par_num #>   <chr>  <chr>                                                             <int> #> 1 emma   VOLUME I                                                              2 #> 2 emma   CHAPTER I                                                             6 #> 3 emma   Emma Woodhouse, handsome, clever, and rich, with a comfortable…       8 #> 4 emma   happy disposition, seemed to unite some of the best blessings …       8 #> 5 emma   existence; and had lived nearly twenty-one years in the world …       8 #> 6 emma   little to distress or vex her.                                        8"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"correcting-the-count","dir":"Articles","previous_headings":"The hard way","what":"Correcting the count","title":"Page to Table","text":"blank lines eradicated, paragraph numbers now wrong. Using lag() function dplyr makes easy compare one cell value . Effectively, ’re going make new running tally every time paragraph number changes using cumsum(). one step, may make sense separate multiple columns: step almost works, lag() nowhere look get value first row. Lacking , returns empty string. ’ll need add one step change empty string zero. Piping lag_num logical test (.na()) lets us check see ’s empty (NA), returning TRUE . , ifelse() branches code two directions: lag(par_num) empty, return value 0, ’s , return value :","code":"emma <- emma |>    mutate(     lag_num = lag(par_num),     new_par = lag_num != par_num,     adj_num = cumsum(new_par))  head(emma) #> # A tibble: 6 × 6 #>   doc_id text                                    par_num lag_num new_par adj_num #>   <chr>  <chr>                                     <int>   <int> <lgl>     <int> #> 1 emma   VOLUME I                                      2      NA NA           NA #> 2 emma   CHAPTER I                                     6       2 TRUE         NA #> 3 emma   Emma Woodhouse, handsome, clever, and …       8       6 TRUE         NA #> 4 emma   happy disposition, seemed to unite som…       8       8 FALSE        NA #> 5 emma   existence; and had lived nearly twenty…       8       8 FALSE        NA #> 6 emma   little to distress or vex her.                8       8 FALSE        NA emma <- emma |>    mutate(     lag_num = lag(par_num) |>        is.na() |>        ifelse(0, lag(par_num)),     new_par = lag_num != par_num,     adj_num = cumsum(new_par))  head(emma) #> # A tibble: 6 × 6 #>   doc_id text                                    par_num lag_num new_par adj_num #>   <chr>  <chr>                                     <int>   <dbl> <lgl>     <int> #> 1 emma   VOLUME I                                      2       0 TRUE          1 #> 2 emma   CHAPTER I                                     6       2 TRUE          2 #> 3 emma   Emma Woodhouse, handsome, clever, and …       8       6 TRUE          3 #> 4 emma   happy disposition, seemed to unite som…       8       8 FALSE         3 #> 5 emma   existence; and had lived nearly twenty…       8       8 FALSE         3 #> 6 emma   little to distress or vex her.                8       8 FALSE         3"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"selecting-reordering-and-renaming-columns","dir":"Articles","previous_headings":"The hard way","what":"Selecting, reordering, and renaming columns","title":"Page to Table","text":"new adj_num column looks right. Every new paragraph new number, progress ’d expect. columns aren’t needed, though, can drop old par_num, lag_num, new_par columns rename adj_num lag_num. select() function dplyr easiest way choose columns want keep order want keep . can also rename columns select , ’ll take opportunity rename adj_num par_num:","code":"emma <- emma |>    select(doc_id,          par_num = adj_num,          text)    head(emma) #> # A tibble: 6 × 3 #>   doc_id par_num text                                                            #>   <chr>    <int> <chr>                                                           #> 1 emma         1 VOLUME I                                                        #> 2 emma         2 CHAPTER I                                                       #> 3 emma         3 Emma Woodhouse, handsome, clever, and rich, with a comfortable… #> 4 emma         3 happy disposition, seemed to unite some of the best blessings … #> 5 emma         3 existence; and had lived nearly twenty-one years in the world … #> 6 emma         3 little to distress or vex her."},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"unnesting-words","dir":"Articles","previous_headings":"The hard way","what":"Unnesting words","title":"Page to Table","text":"final step “unnest” lines text just one word per row. ’re , might well convert words lowercase. handy tidytext package just function need unnest_tokens():","code":"library(tidytext)  emma <- emma |>    unnest_tokens(output = word,                  input = text)  head(emma) #> # A tibble: 6 × 3 #>   doc_id par_num word      #>   <chr>    <int> <chr>     #> 1 emma         1 volume    #> 2 emma         1 i         #> 3 emma         2 chapter   #> 4 emma         2 i         #> 5 emma         3 emma      #> 6 emma         3 woodhouse"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"putting-it-all-together","dir":"Articles","previous_headings":"The hard way","what":"Putting it all together","title":"Page to Table","text":"’ve successfully loaded one text hard way! Let’s put one step see takes:","code":"emma <- data.frame(   doc_id = \"emma\",   text = readLines(\"austen/emma.txt\")) |>    mutate(par_num = cumsum(text == \"\")) |>    filter(text != \"\") |>    mutate(     lag_num = lag(par_num) |>        is.na() |>        ifelse(0, lag(par_num)),     new_par = lag_num != par_num,     adj_num = cumsum(new_par)) |>    select(doc_id,          par_num = adj_num,          text) |>    unnest_tokens(output = word,                  input = text)"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"repeating-for-other-files","dir":"Articles","previous_headings":"The hard way","what":"Repeating for other files","title":"Page to Table","text":"load entire folder texts, need repeat process combine tables. Instead whole thing every text data set, let’s just one additional novel. first couple lines, doc_id need adjusted, filename need point new text:","code":"persuasion <- tibble(   doc_id = \"persuasion\",   text = readLines(\"austen/persuasion.txt\")) |>    mutate(par_num = cumsum(text == \"\")) |>    filter(text != \"\") |>    mutate(     lag_num = lag(par_num) |>        is.na() |>        ifelse(0, lag(par_num)),     new_par = lag_num != par_num,     adj_num = cumsum(new_par)) |>    select(doc_id,          par_num = adj_num,          text) |>    unnest_tokens(output = word,                  input = text)"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"combining-multiple-tables","dir":"Articles","previous_headings":"The hard way","what":"Combining multiple tables","title":"Page to Table","text":"multiple texts loaded , can combined one table rbind() bind rows together:","code":"combo <- rbind(emma, persuasion)  head(combo) #>   doc_id par_num      word #> 1   emma       1    volume #> 2   emma       1         i #> 3   emma       2   chapter #> 4   emma       2         i #> 5   emma       3      emma #> 6   emma       3 woodhouse tail(combo) #>            doc_id par_num       word #> 244640 persuasion    1034       than #> 244641 persuasion    1034         in #> 244642 persuasion    1034        its #> 244643 persuasion    1034   national #> 244644 persuasion    1034 importance #> 244645 persuasion    1035      finis"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"reviewing-the-easy-way","dir":"Articles","previous_headings":"","what":"Reviewing the easy way","title":"Page to Table","text":"“hard” way loading texts can take 33 lines code load two files combine , lines number files grows. “easy” way using tmtyro takes just one line code prepare many files folder:","code":"austen_texts <- load_texts(\"austen/\")  head(austen_texts) #> # A tibble: 6 × 3 #>   doc_id par_num word      #>   <chr>    <dbl> <chr>     #> 1 emma         1 volume    #> 2 emma         1 i         #> 3 emma         2 chapter   #> 4 emma         2 i         #> 5 emma         3 emma      #> 6 emma         3 woodhouse  tail(austen_texts) #> # A tibble: 6 × 3 #>   doc_id                par_num word     #>   <chr>                   <dbl> <chr>    #> 1 sense_and_sensibility    1858 coolness #> 2 sense_and_sensibility    1858 between  #> 3 sense_and_sensibility    1858 their    #> 4 sense_and_sensibility    1858 husbands #> 5 sense_and_sensibility    1859 the      #> 6 sense_and_sensibility    1859 end"},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"say-more-do-less","dir":"Articles","previous_headings":"Reviewing the easy way","what":"Say more, do less","title":"Page to Table","text":"default, load_texts() load process entire folder texts. adjusting options, can convince less. can, instance, get load single file naming : (version table hasn’t assigned name assignment arrow <-, hasn’t saved exists fleeting memory.) changing options, load_texts() skip transformations, presenting texts mixed case one line per row column called text: options available, , deserve closer consideration can offered introduction one.","code":"load_texts(\"austen/\",            name = \"emma.txt\") |>    head() #> # A tibble: 6 × 3 #>   doc_id par_num word      #>   <chr>    <dbl> <chr>     #> 1 emma         1 volume    #> 2 emma         1 i         #> 3 emma         2 chapter   #> 4 emma         2 i         #> 5 emma         3 emma      #> 6 emma         3 woodhouse load_texts(\"austen/\",             word = FALSE,            to_lower = FALSE) |>   head() #> # A tibble: 6 × 3 #>   doc_id par_num text                                                            #>   <chr>    <dbl> <chr>                                                           #> 1 emma         1 VOLUME I                                                        #> 2 emma         2 CHAPTER I                                                       #> 3 emma         3 Emma Woodhouse, handsome, clever, and rich, with a comfortable… #> 4 emma         3 happy disposition, seemed to unite some of the best blessings … #> 5 emma         3 existence; and had lived nearly twenty-one years in the world … #> 6 emma         3 little to distress or vex her."},{"path":"https://jmclawson.github.io/tmtyro/articles/Page-to-Table.html","id":"summary-of-documents","dir":"Articles","previous_headings":"Reviewing the easy way","what":"Summary of documents","title":"Page to Table","text":"loaded, corpus texts Jane Austen offers many possibilities text mining analysis.","code":"austen_texts |>    group_by(doc_id) |>    summarize(     paragraphs = max(par_num),     words = n()) |>    ungroup() |>    standardize_titles() |>    rename(title = doc_id) #> # A tibble: 7 × 3 #>   title                 paragraphs  words #>   <chr>                      <dbl>  <int> #> 1 Emma                        2375 160992 #> 2 Lady Susan                   225  23144 #> 3 Mansfield Park              1839 160454 #> 4 Northanger                  1052  77594 #> 5 Persuasion                  1035  83653 #> 6 Pride and Prejudice         2121 122292 #> 7 Sense and Sensibility       1859 119946"},{"path":"https://jmclawson.github.io/tmtyro/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James Clawson. Author, maintainer.","code":""},{"path":"https://jmclawson.github.io/tmtyro/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Clawson J (2024). tmtyro: tmtyro: Simplified Workflows Text Mining Tyros. R package version 0.0.0.9000, https://jmclawson.github.io/tmtyro/, https://github.com/jmclawson/tmtyro.","code":"@Manual{,   title = {tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros},   author = {James Clawson},   year = {2024},   note = {R package version 0.0.0.9000, https://jmclawson.github.io/tmtyro/},   url = {https://github.com/jmclawson/tmtyro}, }"},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"tmtyro-","dir":"","previous_headings":"","what":"tmtyro: Simplified Workflows for Text Mining Tyros","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"goal tmtyro help beginners work analyze text simple complex features. Adopting tidytext principles, tmtyro abstracts processes levels allow tyros apply text mining techniques ’re deeply familiar R code.","code":""},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"can install development version tmtyro GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"jmclawson/tmtyro\")"},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"One first steps text mining workflow load corpus texts directory. , may desirable detect paragraph breaks prepare data frame one word per row. load_texts() function makes easy.","code":"library(tmtyro) mysteries <- load_texts(\"mycorpus\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Measure sentiment — add_sentiment","title":"Measure sentiment — add_sentiment","text":"add_sentiment() provides simple lexicon-based measures sentiment, comparing words text one number controlled dictionaries.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measure sentiment — add_sentiment","text":"","code":"add_sentiment(   df,   lexicon = c(\"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\"),   word = word )"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measure sentiment — add_sentiment","text":"df tidy data frame, potentially containing column called \"word\" lexicon sentiment lexicon use tidytext package. Options include \"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\". word column words containing one word per row, used dictionary look-.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measure sentiment — add_sentiment","text":"original data frame one sentiment columns added.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measure sentiment — add_sentiment","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen |>    add_sentiment() |>    tidyr::drop_na() |>    head() #> Do you want to download: #>  Name: Bing Sentiment Lexicon  #>  URL: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html  #>  License: May be used (research, commercial, etc) with attribution.  #>  Size: 287 KB (cleaned 220 KB)  #>  Download mechanism: http  #> Error in menu(choices = c(\"Yes\", \"No\"), title = title): menu() cannot be used non-interactively"},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a file once — download_once","title":"Download a file once — download_once","text":"download_once() checks local copy file found online. copy exist, downloads copy local use.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a file once — download_once","text":"","code":"download_once(url, filename = NULL, destdir = \"data\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a file once — download_once","text":"url URL online document. filename file name saved locally. many cases parameter necessary, since file name can automatically parsed URL, web addresses obscure . destdir destination directory save file. default, \"data/\" folder, created yet exist.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download a file once — download_once","text":"","code":"if (FALSE) { download_once(\"example.com/sample.csv\") }"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove stopwords — drop_stopwords","title":"Remove stopwords — drop_stopwords","text":"Remove stopwords","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove stopwords — drop_stopwords","text":"","code":"drop_stopwords(df, wordlist = stopwords::stopwords(), word = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove stopwords — drop_stopwords","text":"df tidy data frame, potentially containing column called \"word\" wordlist list stopwords word column words containing one word per row checked stopwords.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove stopwords — drop_stopwords","text":"original data frame fewer rows.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove stopwords — drop_stopwords","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen |>    drop_stopwords() #> # A tibble: 279,628 × 5 #>    doc_id     par_num word     pos   lemma    #>    <chr>        <dbl> <chr>    <chr> <chr>    #>  1 lady_susan       2 lady     NNP   lady     #>  2 lady_susan       2 susan    NNP   susan    #>  3 lady_susan       2 vernon   NNP   vernon   #>  4 lady_susan       2 mr       NNP   mr       #>  5 lady_susan       2 vernon   NNP   vernon   #>  6 lady_susan       3 langford NNP   langford #>  7 lady_susan       3 dec      NNP   dec      #>  8 lady_susan       4 dear     NNP   dear     #>  9 lady_susan       4 brother  NNP   brother  #> 10 lady_susan       4 can      MD    can      #> # ℹ 279,618 more rows"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a corpus or corpora of texts — get_corpus","title":"Prepare a corpus or corpora of texts — get_corpus","text":"get_corpus() works nearly identically load_texts(), two fundamental differences. First, adds \"corpus\" column resulting table help record keeping. Second, adds option caching output local RDS file, saved project directory.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a corpus or corpora of texts — get_corpus","text":"","code":"get_corpus(   corpus,   name = \".txt\",   word = TRUE,   lemma = FALSE,   lemma_replace = FALSE,   to_lower = TRUE,   remove_names = FALSE,   pos = FALSE,   poetry = FALSE,   paragraph = TRUE,   cache = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a corpus or corpora of texts — get_corpus","text":"corpus Vector length, value either string identifying directory texts first part filename cached RDS file prepared tmtyro. name naming pattern search folder. Defaults \".txt\". word Whether split one word per line. Defaults TRUE. lemma Whether lemmatize text. word TRUE, adds new column called lemma. step can add lot time, defaults FALSE. lemma_replace lemma word TRUE, toggles whether replace word column lemmatized tokens. Defaults FALSE to_lower word TRUE, toggles whether convert words lowercase. Defaults TRUE. remove_names word TRUE, toggles whether remove words appear form initial capitals. Defaults FALSE. pos Whether add column part--speech tag. step can add lot time, defaults FALSE. poetry Whether detect indicate stanza breaks line breaks. Defaults FALSE. paragraph Whether detect paragraph breaks prose. Defaults TRUE. cache Whether save cached copy corpus. options like pos = TRUE lemma = TRUE can add significant time corpus preparation, setting cache = TRUE saves need repeat steps time corpus loaded. Defaults TRUE.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare a corpus or corpora of texts — get_corpus","text":"data frame columns corpus, doc_id, data.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare a corpus or corpora of texts — get_corpus","text":"","code":"if (FALSE) {   austen <- get_corpus(\"austen\")    shakespeare <- get_corpus(     c(\"comedy\",       \"history\",       \"tragedy\")) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_document_topics.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore topics interactively — interactive_document_topics","title":"Explore topics interactively — interactive_document_topics","text":"interactive_document_topics() uses plotly prepare interactive visualization explore topic model, showing top \"n\" topics document. kind visualization use interactive IDE web page.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_document_topics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore topics interactively — interactive_document_topics","text":"","code":"interactive_document_topics(   lda,   top_n = 4,   title = FALSE,   height = NULL,   omit = NULL,   smooth = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_document_topics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore topics interactively — interactive_document_topics","text":"lda topic model used. top_n number topics visualize. default, top 4 topics document shown. title default, function add title chart, corresponding name object passed lda parameter. Set FALSE return chart title. height height resulting HTML widget. omit Upon exploration, topics may found contain common stop words unhelpful material. Use omit parameter define vector topic numbers wish omit visualization. smooth samples rejoined, measured value topic vary wildly, even samples beside document. can make charts distractingly jittery. default TRUE value parameter reduces chart noise calculating rolling averages across three samples. Set parameter FALSE skip step allow visualization extreme values.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_document_topics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore topics interactively — interactive_document_topics","text":"Interactive plotly object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_document_topics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explore topics interactively — interactive_document_topics","text":"","code":"if (FALSE) { mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   make_topic_model(k = 10)  interactive_document_topics(mysteries_lda, top_n = 5) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a folder or data frame of texts — load_texts","title":"Load a folder or data frame of texts — load_texts","text":"load_texts() loads corpus folder texts data frame prepares study using tidytext principles. default, load_texts() add paragraph numbers (suitable prose), unnest word level, options exist change defaults poetry, avoid unnesting, even remove words seem like proper nouns apply techniques natural language processing lemmatizing words tagging parts speech.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a folder or data frame of texts — load_texts","text":"","code":"load_texts(   src = \"data\",   name = \".txt\",   word = TRUE,   lemma = FALSE,   lemma_replace = FALSE,   to_lower = TRUE,   remove_names = FALSE,   pos = FALSE,   poetry = FALSE,   paragraph = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a folder or data frame of texts — load_texts","text":"src Either string identifying name directory containing texts data frame containing unnested column called \"text\" one column name ending \"_id\". Files either stored directory within project folder subdirectory called \"data\". Defaults \"data\" load texts directory. name naming pattern search folder. Defaults \".txt\". word Whether split one word per line. Defaults TRUE. lemma Whether lemmatize text. word TRUE, adds new column called lemma. step can add lot time, defaults FALSE. lemma_replace lemma word TRUE, toggles whether replace word column lemmatized tokens. Defaults FALSE to_lower word TRUE, toggles whether convert words lowercase. Defaults TRUE. remove_names word TRUE, toggles whether remove words appear form initial capitals. Defaults FALSE. pos Whether add column part--speech tag. step can add lot time, defaults FALSE. poetry Whether detect indicate stanza breaks line breaks. Defaults FALSE. paragraph Whether detect paragraph breaks prose. Defaults TRUE.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a folder or data frame of texts — load_texts","text":"data frame two five columns one row word (optionally, one row paragraph one row line) corpus.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a folder or data frame of texts — load_texts","text":"","code":"if (FALSE) { mysteries <-   load_texts(\"mystery-novels\")  dickinson <-   load_texts(\"dickinson-poems\",              poetry = TRUE)  # `load_texts()` can also be used with # a traditional tidytext workflow: mysteries <-   load_texts(\"mystery-novels\",              word = FALSE,              to_lower = FALSE) |>   tidytext::unnest_tokens(word, text) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a topic model — make_topic_model","title":"Construct a topic model — make_topic_model","text":"make_topic_model() moves table texts necessary steps preparation building topic model. function applies seven steps: identifies text divisions doc_id column divides texts -sized chunks sample_size words (default 1000 words) unnests text table table one word per row removes stop words proper nouns (identified word appears capitalized first letter) counts word frequencies chunk converts table frequencies document term matrix builds topic model k topics","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a topic model — make_topic_model","text":"","code":"make_topic_model(df, doc_id = title, sample_size = 1000, k = 15)"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a topic model — make_topic_model","text":"df data frame unnested text \"word\" column. doc_id column identifying document. default, \"title\" column used. sample_size sample size document chunk. default, samples include 1000 words. k number topics search . default, 15 topics sought.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a topic model — make_topic_model","text":"topic model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a topic model — make_topic_model","text":"","code":"if (FALSE) { mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   make_topic_model(k = 10)   }"},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_lexical_variety.html","id":null,"dir":"Reference","previous_headings":"","what":"Measure lexical variety — measure_lexical_variety","title":"Measure lexical variety — measure_lexical_variety","text":"measure_lexical_variety() augments tidy text table columns describing lexical variety corpus. Among things, checks uniqueness size vocabulary, additional ratios reporting measurements relation document size.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_lexical_variety.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measure lexical variety — measure_lexical_variety","text":"","code":"measure_lexical_variety(df, by = doc_id, word = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_lexical_variety.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measure lexical variety — measure_lexical_variety","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" grouping column word column words containing one word per row","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_lexical_variety.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measure lexical variety — measure_lexical_variety","text":"data frame 7 added columns , first two logical rest numeric: new_word (logical) Indicates whether first instance given word hapax (logical) Indicates whether word incident given word, hapax legomenon vocabulary (integer) Running count words used ttr (double) Type-token ratio, derived running count words divided total number words used htr (double) Hapax-token ratio, derived running count hapax legomena divided total number words used progress_words (integer) Running count total words used far document progress_percent (double) Words used far percentage total number words used document","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_lexical_variety.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measure lexical variety — measure_lexical_variety","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen |>    measure_lexical_variety() |>    head() #> # A tibble: 6 × 12 #>   doc_id     par_num word   pos   lemma  new_word hapax vocabulary   ttr   htr #>   <chr>        <dbl> <chr>  <chr> <chr>  <lgl>    <lgl>      <int> <dbl> <dbl> #> 1 lady_susan       1 i      PRP   i      TRUE     FALSE          1     1     0 #> 2 lady_susan       2 lady   NNP   lady   TRUE     FALSE          2     1     0 #> 3 lady_susan       2 susan  NNP   susan  TRUE     FALSE          3     1     0 #> 4 lady_susan       2 vernon NNP   vernon TRUE     FALSE          4     1     0 #> 5 lady_susan       2 to     TO    to     TRUE     FALSE          5     1     0 #> 6 lady_susan       2 mr     NNP   mr     TRUE     FALSE          6     1     0 #> # ℹ 2 more variables: progress_words <int>, progress_percent <dbl>"},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Add measures for tf-idf — measure_tf_idf","title":"Add measures for tf-idf — measure_tf_idf","text":"Add measures tf-idf","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add measures for tf-idf — measure_tf_idf","text":"","code":"measure_tf_idf(df, by = doc_id, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add measures for tf-idf — measure_tf_idf","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" column containing document grouping feature column containing terms measured across document groupings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_tf_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add measures for tf-idf — measure_tf_idf","text":"summary original data frame, rows document term pairing columns document identifier, term, n (number times term used document), tf (term's frequency document), idf (inverse document frequency), tf_idf (previous two columns combined).","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/measure_tf_idf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add measures for tf-idf — measure_tf_idf","text":"","code":"library(tmtyro) library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen |>   measure_tf_idf() #> # A tibble: 37,091 × 6 #>    doc_id              word          n      tf   idf  tf_idf #>    <chr>               <chr>     <int>   <dbl> <dbl>   <dbl> #>  1 lady_susan          vernon      104 0.00450  1.79 0.00807 #>  2 lady_susan          reginald     74 0.00320  1.79 0.00574 #>  3 mansfield_park      fanny       816 0.00510  1.10 0.00560 #>  4 lady_susan          frederica    72 0.00312  1.79 0.00558 #>  5 mansfield_park      crawford    493 0.00308  1.79 0.00552 #>  6 pride_and_prejudice darcy       374 0.00307  1.79 0.00549 #>  7 persuasion          elliot      254 0.00305  1.79 0.00546 #>  8 emma                emma        785 0.00489  1.10 0.00537 #>  9 northanger          tilney      196 0.00253  1.79 0.00454 #> 10 pride_and_prejudice bennet      295 0.00242  1.79 0.00433 #> # ℹ 37,081 more rows"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a MICUSP corpus — micusp_corpus","title":"Get a MICUSP corpus — micusp_corpus","text":"function accepts filters columns micusp_metadata() downloads parses MICUSP (Michigan Corpus Upper-level Student Papers) texts locally copies yet exist. returns table combining metadata text data processing.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a MICUSP corpus — micusp_corpus","text":"","code":"micusp_corpus(...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a MICUSP corpus — micusp_corpus","text":"... filter rows columns micusp_metadata(). Accepted columns include following: paper_id, title, discipline, paper_type, student_level, sex, nativeness, textual_features.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a MICUSP corpus — micusp_corpus","text":"data frame 1 row document corpus 9 columns. first 8 columns contain metadata, final column called text contains full text document.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a MICUSP corpus — micusp_corpus","text":"","code":"if (FALSE) { physics_f <- micusp_corpus(discipline == \"Physics\", sex == \"Female\") physics_m <- micusp_corpus(discipline == \"Physics\", sex == \"Male\")  discipline_by_sex <-   micusp_metadata() |>   dplyr::count(discipline, sex) |>   tidyr::pivot_wider(     names_from = \"sex\",     values_from = \"n\") |>   dplyr::mutate(     ratio_f = (Female) / (Male + Female)) |>     dplyr::arrange(ratio_f)   disciplines_low_f <-   discipline_by_sex |>   head(3) |>   dplyr::pull(discipline)   disciplines_low_m <-   discipline_by_sex |>   tail(3) |>   dplyr::pull(discipline)  low_representation_f <- micusp_corpus(   sex == \"Female\",   discipline %in% disciplines_low_f)   low_representation_m <- micusp_corpus(   sex == \"Male\",   discipline %in% disciplines_low_m) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Get MICUSP metadata — micusp_metadata","title":"Get MICUSP metadata — micusp_metadata","text":"Explore metadata available MICUSP (Michigan Corpus Upper-level Student Papers) texts choose corpus. first use, function creates folder working directory downloads \"micusp_metadata.csv\" file opening . Subsequent use function load local copy.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get MICUSP metadata — micusp_metadata","text":"","code":"micusp_metadata(micusp_dir = \"micusp\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get MICUSP metadata — micusp_metadata","text":"micusp_dir name directory storing local copies MICUSP materials. Defaults \"micusp/\".","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get MICUSP metadata — micusp_metadata","text":"data frame 1 row document corpus 8 columns metadata: paper_id, title, discipline, paper_type, student_level, sex, nativeness, textual_features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get MICUSP metadata — micusp_metadata","text":"","code":"if (FALSE) { micusp_metadata() |> head() }"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bar graphs of frequent features — plot_doc_word_bars","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"Plot bar graphs frequent features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"","code":"plot_doc_word_bars(   df,   num = 10,   by = doc_id,   feature = word,   percents = TRUE,   label = FALSE,   label_tweak = 2,   label_inside = FALSE,   colorset = \"default\",   outline_color = NA,   na_rm = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" num number features show column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" percents Whether display word frequencies percentage instead raw counts; defaults TRUE label Whether show value label bar; defaults FALSE label_tweak numeric value tweak label, shown. percentages, value adjusts decimal-point precision. raw counts, value adjusts labels' offset bars label_inside Whether show value label inside bar; defaults FALSE colorset color palette use, whether \"default\", \"okabe\", one named qualitative palettes Viridis Color Brewer outline_color color use outside bar. default, color used. na_rm Whether drop empty features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"ggplot object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"","code":"library(tmtyro) library(dplyr)  austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen |>   plot_doc_word_bars()   austen |>   mutate(     pos_pair = paste(pos, lead(pos)),     `adjective + noun bigram` = paste(word, lead(word))) |>   filter(stringr::str_detect(pos_pair, \"JJ N\")) |>   standardize_titles() |>   plot_doc_word_bars(     num = 5,     feature = `adjective + noun bigram`,     colorset = \"Pastel2\",     percents = FALSE,     label = TRUE,     label_inside = TRUE,     label_tweak = -1)"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a heatmap of ranked features — plot_doc_word_heatmap","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"Plot heatmap ranked features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"","code":"plot_doc_word_heatmap(   df,   num = 10,   by = doc_id,   feature = word,   label = TRUE,   na_color = \"white\",   colorset = \"viridis\",   line_color = \"gray\" )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" num number ranks show, counting ties column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" label Whether show rank label heatmap na_color color show NA values; default \"white\" colorset viridis color palette use; alternatively, two-item vector colors use gradient line_color color grid lines heatmap","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"ggplot object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"","code":"library(tmtyro) library(dplyr)  austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen |>   filter(pos %in% c(\"NN\", \"NNS\")) |>   plot_doc_word_heatmap()   austen |>   filter(pos %in% c(\"JJ\", \"RB\")) |>   plot_doc_word_heatmap(feature = lemma, colorset = c(\"white\", \"red\"))"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_document_topics.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot topic distributions — plot_document_topics","title":"Plot topic distributions — plot_document_topics","text":"plot_document_topics() prepares visualization exploring significant topics document time.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_document_topics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot topic distributions — plot_document_topics","text":"","code":"plot_document_topics(   lda,   top_n = 4,   direct_label = TRUE,   title = TRUE,   save = TRUE,   saveas = \"png\",   savedir = \"plots\",   omit = NULL,   smooth = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_document_topics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot topic distributions — plot_document_topics","text":"lda topic model used. top_n number topics visualize. default, top 4 topics document shown. direct_label default, directly labeles topic numbers chart. Set FALSE show legend corresponding color. title default, function add title chart, corresponding name object passed lda parameter. Set FALSE return chart title. save default, visualization saved. Set FALSE skip saving. saveas filetype saving resulting visualizations. default, files \"png\" format, options \"pdf\" \"jpg also work. savedir directory saving output images. default, set \"plots/\". omit Upon exploration, topics may found contain common stop words unhelpful material. Use omit parameter define vector topic numbers wish omit visualization. smooth samples rejoined, measured value topic vary wildly, even samples beside document. can make charts distractingly jittery. default TRUE value parameter reduces chart noise calculating rolling averages across three samples. Set parameter FALSE skip step allow visualization extreme values.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_document_topics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot topic distributions — plot_document_topics","text":"ggplot2 visualization showing vertical facets texts. length text shown X-axis, area plots Y-axis show distribution strongest topics part text.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_document_topics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot topic distributions — plot_document_topics","text":"","code":"if (FALSE) { mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   make_topic_model(k = 10)  plot_document_topics(mysteries_lda) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":null,"dir":"Reference","previous_headings":"","what":"Project hapax legomena onto vocabulary growth — plot_hapax","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"plot_hapax() visualizes sampling hapax legomena projected faceted curves vocabulary growth time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"","code":"plot_hapax(   df,   prop = 0.01,   x = progress_words,   y = vocabulary,   by = doc_id,   descriptive_labels = TRUE,   feature = hapax )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" prop proportion hapax sample. chart can become illegible proportions ~1% x progress column show. Default option progress_percent, progress_words also appropriate. y Y-axis variable chart. Default value cumulative vocabulary size. grouping column, doc_id descriptive_labels toggle disabling descriptive labels progress_percent X-axis feature column check new features. Defaults hapax, function might also used new_word instead plot sample new additions documents' vocabularies.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"ggplot object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen_measured <- austen |>   measure_lexical_variety()  austen_measured |>   standardize_titles() |>   plot_hapax()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":null,"dir":"Reference","previous_headings":"","what":"Show hapax-token ratio over time — plot_htr","title":"Show hapax-token ratio over time — plot_htr","text":"Show hapax-token ratio time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show hapax-token ratio over time — plot_htr","text":"","code":"plot_htr(   df,   x = progress_words,   by = doc_id,   identity = doc_id,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inline\", \"axis\", \"inset\"),   log_y = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show hapax-token ratio over time — plot_htr","text":"df tidy data frame, potentially containing column called \"doc_id\" \"word\" x progress column show. Default option progress_percent, progress_words also appropriate. grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show hapax-token ratio over time — plot_htr","text":"ggplot object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show hapax-token ratio over time — plot_htr","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen_measured <- austen |>   measure_lexical_variety()  austen_measured |>   standardize_titles() |>   plot_htr()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the top terms by tf-idf — plot_tf_idf","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"Visualize top terms tf-idf","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"","code":"plot_tf_idf(   df,   num = 10,   by = doc_id,   feature = word,   label = FALSE,   label_tweak = 2,   label_inside = FALSE,   colorset = \"default\",   outline_color = NA )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" num number terms chart document column containing document grouping feature column containing terms measured across document groupings label yet working label_tweak yet working label_inside yet working colorset color palette use, whether \"default\", \"okabe\", one named qualitative palettes Viridis Color Brewer outline_color color use outside bar. default, color used.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"ggplot object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"","code":"library(tmtyro) library(dplyr)  austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen |>   plot_tf_idf()   austen |>   filter(pos %in% c(\"NN\", \"NNS\")) #> # A tibble: 93,622 × 5 #>    doc_id     par_num word       pos   lemma      #>    <chr>        <dbl> <chr>      <chr> <chr>      #>  1 lady_susan       4 pleasure   NN    pleasure   #>  2 lady_susan       4 profiting  NN    profit     #>  3 lady_susan       4 kind       NN    kind       #>  4 lady_susan       4 invitation NN    invitation #>  5 lady_susan       4 weeks      NNS   week       #>  6 lady_susan       4 days       NNS   day        #>  7 lady_susan       4 sister     NN    sister     #>  8 lady_susan       4 kind       NN    kind       #>  9 lady_susan       4 friends    NNS   friend     #> 10 lady_susan       4 stay       NN    stay       #> # ℹ 93,612 more rows   plot_tf_idf(feature = lemma) #> Error in plot_tf_idf(feature = lemma): argument \"df\" is missing, with no default"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot topic wordclouds — plot_topic_wordcloud","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"plot_topic_wordcloud() prepares, saves, displays word clouds topics topic model. function can display word clouds one specific topics, can show word clouds every topic.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"","code":"plot_topic_wordcloud(df, topics = NULL, crop = TRUE, savedir = \"plots\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"df loaded topic model topics Topic numbers visualized. left undefined, topics visualized crop Whether remove white space visualized word clouds savedir directory save plots . Defaults \"plots\"","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"Graphic(s) prepared knitr Quarto RMarkdown","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"","code":"if (FALSE) { mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   make_topic_model(k = 10)   }"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":null,"dir":"Reference","previous_headings":"","what":"Show type-token ratio over time — plot_ttr","title":"Show type-token ratio over time — plot_ttr","text":"Show type-token ratio time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show type-token ratio over time — plot_ttr","text":"","code":"plot_ttr(   df,   x = progress_words,   by = doc_id,   identity = doc_id,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inline\", \"axis\", \"inset\"),   log_y = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show type-token ratio over time — plot_ttr","text":"df tidy data frame, potentially containing column called \"doc_id\" \"word\" x progress column show. Default option progress_percent, progress_words also appropriate. grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show type-token ratio over time — plot_ttr","text":"ggplot object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show type-token ratio over time — plot_ttr","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen_measured <- austen |>   measure_lexical_variety()  austen_measured |>   standardize_titles() |>   plot_ttr(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'   austen_measured |>   standardize_titles() |>   plot_ttr()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Show vocabulary growth — plot_vocabulary","title":"Show vocabulary growth — plot_vocabulary","text":"plot_vocabulary() visualizes vocabulary growth new words used document.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show vocabulary growth — plot_vocabulary","text":"","code":"plot_vocabulary(   df,   x = progress_words,   by = doc_id,   identity = doc_id,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inset\", \"inline\", \"axis\") )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show vocabulary growth — plot_vocabulary","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" x column showing cumulative count words grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show vocabulary growth — plot_vocabulary","text":"ggplot object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show vocabulary growth — plot_vocabulary","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  austen_measured <- austen |>   measure_lexical_variety()  austen_measured |>   standardize_titles() |>   plot_vocabulary(progress_percent)   austen_measured |>   standardize_titles() |>   plot_vocabulary()   if (FALSE) {   micusp_corpus(     discipline %in% c(\"Physics\", \"Economics\")) |>     load_texts() |>     measure_lexical_variety() |>     plot_vocabulary(by = discipline) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Part of speech tags — pos_tags","title":"Part of speech tags — pos_tags","text":"Tags descriptions English parts speech, designated Penn Treebank Project.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Part of speech tags — pos_tags","text":"","code":"pos_tags"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"-pos-tags-","dir":"Reference","previous_headings":"","what":"\"pos_tags\"","title":"Part of speech tags — pos_tags","text":"data frame 36 rows 2 columns tag speech tag description meaning tag","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Part of speech tags — pos_tags","text":"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize document titles — standardize_titles","title":"Standardize document titles — standardize_titles","text":"Useful especially visualizations. standardize_titles applies English-language conventions, including converting underscores spaces, capitalizing important words, removing leading articles, dropping subtitles.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize document titles — standardize_titles","text":"","code":"standardize_titles(.data, title = doc_id)"},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize document titles — standardize_titles","text":".data tidy data frame, potentially containing title column called \"doc_id\". Alternatively, simple character vector titles. title column containing titles standardized","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize document titles — standardize_titles","text":"data frame one column adjusted. .data character vector instead data frame, character vector returned.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize document titles — standardize_titles","text":"","code":"austen <- \"austen.rds\" |>   system.file(package = \"tmtyro\") |>   readRDS()  ##### Standardizing strings ##### # Before `standardize_titles()` unique(austen$doc_id) #> [1] \"lady_susan\"          \"northanger\"          \"persuasion\"          #> [4] \"pride_and_prejudice\" \"emma\"                \"mansfield_park\"       # After `standardize_titles()` unique(austen$doc_id) |>   standardize_titles() #> [1] \"Lady Susan\"          \"Northanger\"          \"Persuasion\"          #> [4] \"Pride and Prejudice\" \"Emma\"                \"Mansfield Park\"       ##### Standardizing a data frame #####  austen_measured <- austen |>   measure_lexical_variety()  # Before `standardize_titles()` austen_measured |>   plot_vocabulary(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'   # After `standardize_titles()` austen_measured |>   standardize_titles() |>   plot_vocabulary(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'"},{"path":"https://jmclawson.github.io/tmtyro/reference/tmtyro-package.html","id":null,"dir":"Reference","previous_headings":"","what":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","title":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","text":"Work analyze text simple complex features. Adopting tidytext principles, tmtyro abstracts processes levels allow beginners use familiarize techniques understand much code.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/tmtyro-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","text":"Maintainer: James Clawson clawson@gmail.com (ORCID)","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":null,"dir":"Reference","previous_headings":"","what":"Split text into words and drop proper nouns — unnest_without_caps","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"Split column text using tidytext::unnest_tokens(), flattening table one token per row also omitting token present capitalized form.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"","code":"unnest_without_caps(df, output = \"word\", input = \"text\", to_lower = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"df data frame output Output column created. input Input column gets split word. to_lower Whether convert final words lowercase.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"data frame","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"","code":"if (FALSE) { mysteries <-   load_texts(\"mystery-novels\",              to_lower = FALSE) |>   unnest_without_caps()  # Since `unnest_without_caps()` is # incorporated into `load_texts()`, # it may be unnecessary for many # scenarios. mysteries <-   load_texts(\"mystery-novels\",              remove_names = TRUE)   }"}]
