[{"path":"https://jmclawson.github.io/tmtyro/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 tmtyro authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"in-context","dir":"Articles","previous_headings":"","what":"In context","title":"Differentiating tmtyro","text":"Voyant one best-known tools working text data humanities. Begun development Stéfan Sinclair Geoffrey Rockwell twenty years ago, become standard—good reason. graphical interface makes accessible novices without compromising ability features. Still, Voyant’s easy--use interface ultimately limits users’ growth, since interface can keep Voyant serving skills ramp options. Unlike Voyant, code-based methods working text offer reproducibility open-ended tooling. R, tm package created Ingo Feinerer Kurt Hornik among oldest widely used packages text mining.1 emphasizes corpus creation choosing text features study. First published CRAN 2007, predates packages described almost decade, data design—emphasizing document-term matrices DTMs (sometimes called document-feature matrices DFMs)—makes sometimes hard work common workflows. quanteda package, released Kenneth Benoit 2015, continual development, probably offers robust feature set list. provides workflows corpus creation, choosing features, searching words context, working custom dictionaries, visualizing results, among things, providing helpful documentation along way. beginner, abundance options multiple-step workflows can overwhelming. like tm, quanteda’s primary data design ideally suited popular packages like dplyr.2 Nevertheless, quanteda provides power specialized functionality merit learning curve. newest options tidytext, created Julia Silge David Robinson 2019. Unlike tm quanteda, tidytext made using “tidy” design philosophy consistent many popular R packages.3 Additionally, companion book, Text Mining R, offers impressive documentation, easing learning curve anyone new text mining. book’s preface acknowledges starting point quite ways zero, expecting “reader least slightly familiar dplyr, ggplot2, %>% ‘pipe’ operator R.” expectations make tidytext tough complete beginners must get speed tools using .  context, tmtyro package steps cautiously remaining space fill particular need. Developed teaching two semesters undergraduate course literary text mining, grew folder “helper” functions written students. course taught English department, never meant “coding class” much one induced students think text new ways. syllabus followed examples Text Mining R , ambitiously, Text Analysis R Students Literature, Matthew Jockers Rosamond Thalken, pairing methods applications recent research. week, students applied techniques ask questions selections writing. working tools front us helped everyone test boundaries new world map might follow similar paths laid readings. Like Voyant, tmtyro designed beginner, strives predictability. Workflows provided loading texts folder getting corpus texts online collections. texts loaded, repetitive conventions function names make easy add columns analysis single step, generic functions handle details tables figures. importantly, tmtyro provides skills ramp users outgrow . Code workflows designed help beginners move quickly start try things . , student gains confidence methods provided package might step beyond tweak visualization using functions ggplot2. researcher wishing work subset titles begin understand methods dplyr. since tmtyro’s data design based tidytext, user can transition packages seamlessly, using together. Nobody expected stick tmtyro forever, functions designed remain useful long past “tyro” stage.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"in-code","dir":"Articles","previous_headings":"","what":"In code","title":"Differentiating tmtyro","text":"packages developed different audiences, take different approaches common steps. functions approaches used tmtyro seem similar tidytext. time, many details choices hidden simplify interface prioritize getting results. code use package shown comparison. Every approach assumes object definition showing path folder text files: likely someone familiar given package take different approach, examples demonstrate method someone might try searching documentation internet. methods benchmarked, might faster others, speeds feel comparable testing.","code":"text_directory <- \"path/to/files\""},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"load-texts-from-a-folder","dir":"Articles","previous_headings":"In code","what":"Load texts from a folder","title":"Differentiating tmtyro","text":"first comparison shows first step loading corpus local folder texts. tmtyro tidytext quanteda tm Behind scenes, tmtyro’s load_texts() uses functions base R number packages: dplyr, forcats, purrr, rlang, stringr, tibble, tidyr, tidytext. lemmatizing tagging parts speech, also uses textstem, openNLP, NLP.","code":"library(tmtyro)  my_corpus <- load_texts(text_directory) library(tidytext) library(dplyr) library(readr) library(stringr)  my_corpus_tt <-    data.frame(     doc_id = list.files(text_directory, \"\\\\.txt$\")) |>    mutate(     text = paste(text_directory, doc_id, sep = \"/\") |>        read_file(),     .by = doc_id) |>    mutate(     doc_id = str_remove_all(doc_id, \"[.]txt\")) |>    unnest_tokens(word, text) library(quanteda) library(readtext)  my_corpus_qu <-    readtext(     paste0(text_directory, \"/*.txt\"),     docvarsfrom = \"filenames\") |>    corpus() |>    tokens() library(tm)  my_corpus_tm <- DirSource(text_directory) |>    Corpus(readerControl = list(reader = readPlain))"},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"remove-stop-words","dir":"Articles","previous_headings":"In code","what":"Remove stop words","title":"Differentiating tmtyro","text":"Removing stop words common step text analysis. examples continues directly previous step loading texts. tmtyro tidytext quanteda tm drop_stopwords() uses functions dplyr tidytext.","code":"sans_stopwords <- drop_stopwords(my_corpus) sans_stopwords_tt <- anti_join(my_corpus_tt, get_stopwords()) library(stopwords)  sans_stopwords_qu <- tokens_remove(my_corpus_qu, stopwords(\"english\")) sans_stopwords_tm <-     tm_map(my_corpus_tm,          removeWords,           stopwords(\"english\"))"},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"add-sentiment","dir":"Articles","previous_headings":"In code","what":"Add sentiment","title":"Differentiating tmtyro","text":"pre-trained lexicon needed tag texts sentiment. process differs package. tmtyro tidytext quanteda tm add_sentiment() uses functions rlang, dplyr, textdata, tidytext.","code":"sentiment <- add_sentiment(my_corpus) sentiment_tt <- inner_join(my_corpus_tt, get_sentiments()) sentiment_qu <-    tokens_lookup(     my_corpus_qu,     dictionary = data_dictionary_LSD2015,      exclusive = FALSE) library(syuzhet)  sentiment_tm <- get_sentiment(my_corpus_tm)  # This doesn't actually do the job. I'm not sure what the equivalent would be using tm."},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"measure-tf-idf","dir":"Articles","previous_headings":"In code","what":"Measure Tf-idf","title":"Differentiating tmtyro","text":"Term frequency–inverse document frequency method weighing words contribution distinctness within corpus. tmtyro tidytext quanteda tm summarize_tf_idf() uses functions dplyr tidytext.","code":"tfidf <- summarize_tf_idf(my_corpus) tfidf_tt <- my_corpus_tt |>  count(doc_id, word, sort = TRUE)  total_words <- tfidf_tt |>    group_by(doc_id) |>    summarize(total = sum(n))  tfidf_tt <- left_join(tfidf_tt, total_words) |>    bind_tf_idf(word, doc_id, n) tfidf_qu <- dfm(my_corpus_qu) |>    docfreq(scheme = \"inverse\") tfidf_tm <- weightTfIdf(DocumentTermMatrix(my_corpus_tm))"},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"visualize-most-frequent-words","dir":"Articles","previous_headings":"In code","what":"Visualize most frequent words","title":"Differentiating tmtyro","text":"Measuring word frequency basic step text mining. Well-prepared figures can help communicate results. tmtyro tidytext quanteda tm count() reexported dplyr. showing word counts, visualize() also uses ggplot2. kinds visualizations add forcats, scales, tidyr, ggraph, igraph packages.","code":"my_corpus |>    count(word) |>    visualize() library(ggplot2)  my_corpus_tt |>    count(word, sort = TRUE) |>    slice_head(n = 10) |>    mutate(proportion = n / sum(n)) |>    ggplot(aes(proportion, reorder(word, proportion))) +   geom_col() +   labs(y = NULL) library(quanteda.textstats) library(ggplot2)  tokens(my_corpus_qu,        remove_punct = TRUE) |>    dfm() |>    textstat_frequency(n = 10) |>    ggplot(aes(x = frequency,              y = reorder(feature, -rank))) +   geom_col() +    labs(y = NULL) library(Rgraphviz)  plot(TermDocumentMatrix(my_corpus_tm),      terms = findFreqTerms(TermDocumentMatrix(my_corpus_tm))[1:10])  # This doesn't actually work, since the necessary package was removed from CRAN."},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"complete-workflow","dir":"Articles","previous_headings":"In code","what":"Complete workflow","title":"Differentiating tmtyro","text":"last section compares four packages walking common workflow, using load folder texts, remove stopwords, visualize frequent words. tmtyro tidytext quanteda tm","code":"library(tmtyro)  load_texts(text_directory) |>    drop_stopwords() |>    count(word) |>    visualize() library(tidytext) library(dplyr) library(tibble) library(ggplot2) data(stop_words)  data.frame(     doc_id = list.files(text_directory, \"\\\\.txt$\")) |>    mutate(     text = paste(text_directory, doc_id, sep = \"/\") |>        read_file(),     .by = doc_id) |>    unnest_tokens(word, text) |>    anti_join(stop_words) |>    count(word, sort = TRUE) |>    slice_head(n = 10) |>    mutate(proportion = n / sum(n)) |>    ggplot(aes(proportion, reorder(word, proportion))) +   geom_col() +   labs(y = NULL) library(quanteda) library(readtext) library(stopwords) library(ggplot2)  readtext(     paste0(text_directory, \"/*.txt\"),     docvarsfrom = \"filenames\") |>    corpus() |>    tokens(remove_punct = TRUE) |>    tokens_remove(stopwords(\"english\")) |>    dfm() |>    textstat_frequency(n = 10) |>    ggplot(aes(x = frequency,              y = reorder(feature, -rank))) +   geom_col() +    labs(y = NULL) library(tm) library(Rgraphviz)  Corpus(   DirSource(text_directory),    readerControl = list(reader = readPlain)) |>    tm_map(removeWords,           stopwords(\"english\")) |>    TermDocumentMatrix() |>    plot(terms = findFreqTerms(TermDocumentMatrix(my_corpus_tm))[1:10])  # This doesn't actually work, since the necessary package was removed from CRAN."},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"colors-are-tricky","dir":"Articles","previous_headings":"","what":"Colors are tricky","title":"Customizing colors","text":"ggplot2 can set color many different ways, one way work given scenario. Clearest distinction color fill. first applies color points, lines, edges. ’s adjusted functions color names, like scale_color_manual(). fill aesthetic, hand, defines areas, inside shapes, bars. ’s adjusted functions fill names, like scale_fill_manual(). every case, _fill_ _color_ part function indicate target. Difficulty grows . Colors fills set different ways discrete data, continuous data, binned data. Worse, color palettes chosen using three incompatible methods depending color set, one method custom manual palettes, another method Brewer palettes, third Viridis palettes. Many options available additional packages, combination two aesthetics, three types data, three types palettes built ggplot2. table shows half 18 commonest functions changing colors, ggplot2 offers 44 without counting spelling variants. row functions uses different parameters choosing colors. path color customization steep.","code":"#> Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  #>   object 'type_sum.accel' not found"},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"change_colors-is-easy","dir":"Articles","previous_headings":"","what":"change_colors() is easy","title":"Customizing colors","text":"visualization functions tmtyro can changed one standard method: change_colors(). function considers figure, figures whether makes sense change color fill, applies standard interface manual palettes, Brewer palettes, Viridis palettes. change_colors() manages differentiation among data types. scale_color_manual() works discrete data, scale_color_gradient() good continuous values. scale_color_brewer() work discrete data types, scale_color_distiller() works continuous data scale_color_viridis_d() work discrete data types, scale_color_viridis_c() work continous data. change_colors() accommodates discrete continuous data change_colors() also introduces one standard interface arguments. scale_color_manual() sets colors using named hexadecimal colors values argument scale_color_brewer() sets colors using numbers palette argument scale_color_viridis_d() sets colors using letters option argument change_colors() uses palettes argument everything code easy, difficult part choice.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"manual-colors","dir":"Articles","previous_headings":"Options are many","what":"manual colors","title":"Customizing colors","text":"simply, change_colors() set colors choose. Setting four colors four items assign directly; number make gradient. Color names like “pink” “orange” work R, specific hues like “forestgreen” “steelblue.”1 addition named colors, R accept colors “hex codes” using hexadecimal notation.2 first two digits hex code describe red color 0 255; middle two describe green ; last two describe blue. Combinations following chart give sense work, online color picker may help narrow things .3  Use manual colors—named colors hex codes—combining vector inside change_colors():  Custom colors also work well naming particular values:","code":"dubliners_count |>    change_colors(c(\"#00BBBB\", \"tan\", \"purple\")) joyce_count |>    change_colors(c(     \"#88DD00\", \"#00DDDD\",     he = \"red\")) #> Warning: No shared levels found between `names(values)` of the manual scale and the #> data's fill values. #> No shared levels found between `names(values)` of the manual scale and the #> data's fill values."},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"brewer-palettes","dir":"Articles","previous_headings":"Options are many","what":"Brewer palettes","title":"Customizing colors","text":"’d rather pick colors manually, Brewer palettes excellent choice. Brewer qualitative palettes well suited discrete data, using color distinguish categories like documents words.  Brewer’s sequential palettes ideal showing differences magnitude:  Choose Brewer palette using name number palette argument:","code":"joyce_count |>    change_colors(\"Brewer\", palette = \"Dark2\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"viridis-palettes","dir":"Articles","previous_headings":"Options are many","what":"Viridis palettes","title":"Customizing colors","text":"Viridis palettes offer another set choices colors visualizations. palettes look beautiful screen, typically work well monochrome print designed accommodate color vision needs. palettes work especially well continuous data. Option “H” “turbo” work discrete scales, also caveats: among , ’s poorly suited black white printing since doesn’t follow linear path dark light.  Choose Viridis palette using name letter palette argument:","code":"dubliners_dfm |>    change_colors(\"Viridis\", palette = \"mako\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"loading-a-corpus","dir":"Articles","previous_headings":"","what":"Loading a corpus","title":"Vectorized functions","text":"Regardless user’s starting point, tmtyro’s main verbs gathering preparing corpus prove useful:","code":"library(dplyr) #> Error in get(paste0(generic, \".\", class), envir = get_method_env()) :  #>   object 'type_sum.accel' not found library(ggplot2) library(gt) library(tmtyro) corpus_dubliners <- get_gutenberg_corpus(2814) |>    load_texts(lemma = TRUE, pos = TRUE) |>    identify_by(part) |>    standardize_titles()  corpus_dubliners #> # A tibble: 67,885 × 7 #>    doc_id      title     author       part        word  pos   lemma #>    <fct>       <chr>     <chr>        <chr>       <chr> <chr> <chr> #>  1 The Sisters Dubliners Joyce, James THE SISTERS there EX    there #>  2 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be    #>  3 The Sisters Dubliners Joyce, James THE SISTERS no    DT    no    #>  4 The Sisters Dubliners Joyce, James THE SISTERS hope  NN    hope  #>  5 The Sisters Dubliners Joyce, James THE SISTERS for   IN    for   #>  6 The Sisters Dubliners Joyce, James THE SISTERS him   PRP   him   #>  7 The Sisters Dubliners Joyce, James THE SISTERS this  DT    this  #>  8 The Sisters Dubliners Joyce, James THE SISTERS time  NN    time  #>  9 The Sisters Dubliners Joyce, James THE SISTERS it    PRP   it    #> 10 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be    #> # ℹ 67,875 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"adding-columns-with-dplyr","dir":"Articles","previous_headings":"","what":"Adding columns with dplyr","title":"Vectorized functions","text":"Beyond point, anyone familiar common tidyverse packages like dplyr ggplot2 might forge path. instance, tmtyro offers selection verbs adding new columns—helpfully beginning add_...()—dplyr way add columns mutate(). support workflow, tmtyro offers functions working columns vectors, .","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"word-count-and-frequency","dir":"Articles","previous_headings":"Adding columns with dplyr","what":"Word count and frequency","title":"Vectorized functions","text":"main path adding column word frequencies add_frequency() function. Users familiar dplyr can instead use mutate() paired get_frequency(): frequencies can just easily reported percentages relative whole, using get_frequency(percent = TRUE): course, frequencies relate entire corpus. get document-level numbers, use dplyr functions group_by() ungroup() around mutate():","code":"corpus_dubliners |>    select(doc_id, word, lemma) |>    mutate(     count_word = get_frequency(word),     count_lemma = get_frequency(lemma)) #> # A tibble: 67,885 × 5 #>    doc_id      word  lemma count_word count_lemma #>    <fct>       <chr> <chr>      <int>       <int> #>  1 The Sisters there there        168         168 #>  2 The Sisters was   be          1169        2146 #>  3 The Sisters no    no           168         168 #>  4 The Sisters hope  hope          14          26 #>  5 The Sisters for   for          508         508 #>  6 The Sisters him   him          494         494 #>  7 The Sisters this  this         124         173 #>  8 The Sisters time  time         114         135 #>  9 The Sisters it    it           604         604 #> 10 The Sisters was   be          1169        2146 #> # ℹ 67,875 more rows corpus_dubliners |>    select(doc_id, word, lemma) |>    mutate(     count_word = get_frequency(word, percent = TRUE),     count_lemma = get_frequency(lemma, percent = TRUE)) #> # A tibble: 67,885 × 5 #>    doc_id      word  lemma count_word count_lemma #>    <fct>       <chr> <chr>      <dbl>       <dbl> #>  1 The Sisters there there   0.00247     0.00247  #>  2 The Sisters was   be      0.0172      0.0316   #>  3 The Sisters no    no      0.00247     0.00247  #>  4 The Sisters hope  hope    0.000206    0.000383 #>  5 The Sisters for   for     0.00748     0.00748  #>  6 The Sisters him   him     0.00728     0.00728  #>  7 The Sisters this  this    0.00183     0.00255  #>  8 The Sisters time  time    0.00168     0.00199  #>  9 The Sisters it    it      0.00890     0.00890  #> 10 The Sisters was   be      0.0172      0.0316   #> # ℹ 67,875 more rows corpus_dubliners <- corpus_dubliners |>    select(doc_id, word)   dubliners_count <- corpus_dubliners |>    group_by(doc_id) |>    mutate(     n = get_frequency(word),     freq = get_frequency(word, percent = TRUE)) |>    ungroup()  dubliners_count #> # A tibble: 67,885 × 4 #>    doc_id      word      n    freq #>    <fct>       <chr> <int>   <dbl> #>  1 The Sisters there    15 0.0048  #>  2 The Sisters was      57 0.0182  #>  3 The Sisters no       16 0.00512 #>  4 The Sisters hope      1 0.00032 #>  5 The Sisters for      32 0.0102  #>  6 The Sisters him      43 0.0138  #>  7 The Sisters this      6 0.00192 #>  8 The Sisters time      3 0.00096 #>  9 The Sisters it       40 0.0128  #> 10 The Sisters was      57 0.0182  #> # ℹ 67,875 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"vocabulary-richness","dir":"Articles","previous_headings":"Adding columns with dplyr","what":"Vocabulary richness","title":"Vectorized functions","text":"tmtyro offers add_vocabulary() adding columns devoted vocabulary growth, uniqueness, ratios lexical diversity. using mutate(), features handled testing functions like is_new() is_hapax() measuring functions like get_cumulative_vocabulary(), get_ttr(), get_hir(). word count, ’s usually best calculate values grouped document using group_by() ungroup(): Slower methods, get_htr() offers available add_vocabulary(), returning hapax-token ratio. method can slower, careful applying large corpus","code":"dubliners_vocab <- corpus_dubliners |>    group_by(doc_id) |>    mutate(     new_word = is_new(word),      hapax_word = is_hapax(word),     vocab = get_cumulative_vocabulary(word),      ttr = get_ttr(word),      hir = get_hir(word)) |>    ungroup()  dubliners_vocab #> # A tibble: 67,885 × 7 #>    doc_id      word  new_word hapax_word vocab   ttr   hir #>    <fct>       <chr> <lgl>    <lgl>      <int> <dbl> <dbl> #>  1 The Sisters there TRUE     FALSE          1   1   0     #>  2 The Sisters was   TRUE     FALSE          2   1   0     #>  3 The Sisters no    TRUE     FALSE          3   1   0     #>  4 The Sisters hope  TRUE     TRUE           4   1   0.25  #>  5 The Sisters for   TRUE     FALSE          5   1   0.2   #>  6 The Sisters him   TRUE     FALSE          6   1   0.167 #>  7 The Sisters this  TRUE     FALSE          7   1   0.143 #>  8 The Sisters time  TRUE     FALSE          8   1   0.125 #>  9 The Sisters it    TRUE     FALSE          9   1   0.111 #> 10 The Sisters was   FALSE    FALSE          9   0.9 0.1   #> # ℹ 67,875 more rows dubliners_vocab <-    dubliners_vocab |>    select(doc_id, word, ttr, hir) |>    filter(doc_id %in% c(\"The Sisters\", \"An Encounter\")) |>    group_by(doc_id) |>    mutate(     htr = get_htr(word)   ) |>    ungroup()  dubliners_vocab |>    # skip the first few lines   {\\(x) x[-c(1:6),]}() #> # A tibble: 6,374 × 5 #>    doc_id      word     ttr    hir   htr #>    <fct>       <chr>  <dbl>  <dbl> <dbl> #>  1 The Sisters this   1     0.143  1     #>  2 The Sisters time   1     0.125  1     #>  3 The Sisters it     1     0.111  1     #>  4 The Sisters was    0.9   0.1    0.8   #>  5 The Sisters the    0.909 0.0909 0.818 #>  6 The Sisters third  0.917 0.167  0.833 #>  7 The Sisters stroke 0.923 0.231  0.846 #>  8 The Sisters night  0.929 0.214  0.857 #>  9 The Sisters after  0.933 0.2    0.867 #> 10 The Sisters night  0.875 0.188  0.75  #> # ℹ 6,364 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"dictionary-matching","dir":"Articles","previous_headings":"Adding columns with dplyr","what":"Dictionary Matching","title":"Vectorized functions","text":"add_dictionary() can manage adding columns matching dictionary column like word lemma, get_match() function return dictionary match word vector. ’s used add column dplyr’s mutate() like :","code":"emoji_weather <- make_dictionary(   list(     \"️☔️\" = c(\"rain\", \"rains\", \"rainy\", \"raining\"),     \"️⛈️\" = c(\"storm\", \"storms\", \"stormy\", \"storming\"),     \"☁️\" = c(\"cloud\", \"clouds\", \"cloudy\"),     \"🌞\" = c(\"sun\", \"sunny\"),     \"🌫️\" = c(\"fog\", \"fogs\", \"foggy\", \"mist\", \"misty\"),     \"🌬️\" = c(\"wind\", \"winds\", \"windy\"),     \"️❄️\" = c(\"snow\", \"snows\", \"snowing\")),   name = \"weather\")  dubliners_weather <- corpus_dubliners |>    mutate(weather = get_match(word, emoji_weather))  dubliners_weather |>    # show only one story and skip a few hundred words   filter(doc_id == \"The Dead\") |>    filter(row_number() > 602) #> # A tibble: 15,076 × 3 #>    doc_id   word     weather #>    <fct>    <chr>    <chr>   #>  1 The Dead he       NA      #>  2 The Dead stood    NA      #>  3 The Dead on       NA      #>  4 The Dead the      NA      #>  5 The Dead mat      NA      #>  6 The Dead scraping NA      #>  7 The Dead the      NA      #>  8 The Dead snow     ️❄️       #>  9 The Dead from     NA      #> 10 The Dead his      NA      #> # ℹ 15,066 more rows  dubliners_weather |>    drop_na() #> # A tibble: 53 × 3 #>    doc_id       word   weather #>    <fct>        <chr>  <chr>   #>  1 The Sisters  clouds ☁️       #>  2 The Sisters  sunny  🌞      #>  3 The Sisters  sun    🌞      #>  4 The Sisters  clouds ☁️       #>  5 An Encounter storm  ️⛈️       #>  6 An Encounter sunny  🌞      #>  7 An Encounter sun    🌞      #>  8 An Encounter clouds ☁️       #>  9 Araby        rainy  ️☔️      #> 10 Araby        rain   ️☔️      #> # ℹ 43 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"sentiment","dir":"Articles","previous_headings":"Adding columns with dplyr > Dictionary Matching","what":"Sentiment","title":"Vectorized functions","text":"Matching sentiment get_sentiment() just uses special kind dictionary matching:","code":"corpus_dubliners |>    mutate(     sent_1 = get_match(word, tidytext::get_sentiments(\"bing\")),     sent_2 = get_sentiment(word, \"bing\")) |>    drop_na() #> # A tibble: 3,786 × 4 #>    doc_id      word      sent_1   sent_2   #>    <fct>       <chr>     <chr>    <chr>    #>  1 The Sisters evenly    positive positive #>  2 The Sisters dead      negative negative #>  3 The Sisters darkened  negative negative #>  4 The Sisters blind     negative negative #>  5 The Sisters idle      negative negative #>  6 The Sisters strangely negative negative #>  7 The Sisters like      positive positive #>  8 The Sisters like      positive positive #>  9 The Sisters sinful    negative negative #> 10 The Sisters fear      negative negative #> # ℹ 3,776 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"tf-idf","dir":"Articles","previous_headings":"Adding columns with dplyr","what":"Tf-idf","title":"Vectorized functions","text":"get_tf() function offers shorthand alias get_frequency(percent = TRUE). Importantly, frequency reports values whole group, may often necessary use group_by() ungroup(): Simpler use get_tf_by(), accepts string grouping variable like doc_id. works well get_idf_by() calculate inverse document frequency term. Lastly, multiplying columns together results tf-idf: Alternatively, get_tfidf_by() simplifies process one step:","code":"dubliners_tfidf <- corpus_dubliners |>    group_by(doc_id) |>    mutate(     tf = get_tf(word)) |>    ungroup()  dubliners_tfidf #> # A tibble: 67,885 × 3 #>    doc_id      word       tf #>    <fct>       <chr>   <dbl> #>  1 The Sisters there 0.0048  #>  2 The Sisters was   0.0182  #>  3 The Sisters no    0.00512 #>  4 The Sisters hope  0.00032 #>  5 The Sisters for   0.0102  #>  6 The Sisters him   0.0138  #>  7 The Sisters this  0.00192 #>  8 The Sisters time  0.00096 #>  9 The Sisters it    0.0128  #> 10 The Sisters was   0.0182  #> # ℹ 67,875 more rows dubliners_tfidf <- corpus_dubliners |>    mutate(     tf = get_tf_by(word, doc_id),     idf = get_idf_by(word, doc_id),     tf_idf = tf * idf)  dubliners_tfidf #> # A tibble: 67,885 × 5 #>    doc_id      word       tf    idf   tf_idf #>    <fct>       <chr>   <dbl>  <dbl>    <dbl> #>  1 The Sisters there 0.0048  0      0        #>  2 The Sisters was   0.0182  0      0        #>  3 The Sisters no    0.00512 0      0        #>  4 The Sisters hope  0.00032 0.511  0.000163 #>  5 The Sisters for   0.0102  0      0        #>  6 The Sisters him   0.0138  0      0        #>  7 The Sisters this  0.00192 0.0690 0.000132 #>  8 The Sisters time  0.00096 0      0        #>  9 The Sisters it    0.0128  0      0        #> 10 The Sisters was   0.0182  0      0        #> # ℹ 67,875 more rows dubliners_tfidf |>    select(doc_id, word, tf_idf) |>    mutate(     tf_idf2 = get_tfidf_by(word, doc_id)   ) #> # A tibble: 67,885 × 4 #>    doc_id      word    tf_idf  tf_idf2 #>    <fct>       <chr>    <dbl>    <dbl> #>  1 The Sisters there 0        0        #>  2 The Sisters was   0        0        #>  3 The Sisters no    0        0        #>  4 The Sisters hope  0.000163 0.000163 #>  5 The Sisters for   0        0        #>  6 The Sisters him   0        0        #>  7 The Sisters this  0.000132 0.000132 #>  8 The Sisters time  0        0        #>  9 The Sisters it    0        0        #> 10 The Sisters was   0        0        #> # ℹ 67,875 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"preparing-tables-with-dplyr-and-gt","dir":"Articles","previous_headings":"","what":"Preparing tables with dplyr and gt","title":"Vectorized functions","text":"addition adding new columns, tmtyro’s functions like add_vocabulary() add_sentiment() also prepare objects work easily tabulize(). Users wish prepare similar tables manually need become familiar package like gt, allowing nearly limitless customization. methods creating modifying gt tables shown , found package documentation.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"corpus-details","dir":"Articles","previous_headings":"Preparing tables with dplyr and gt","what":"Corpus details","title":"Vectorized functions","text":"default, corpus prepared tmtyro tabulize() table showing word counts document. simple version can prepared hand little effort: table prepared, gt allows tweaking—instance, format word counts readability, hide doc_id column header, rename n words:","code":"gt_details <- corpus_dubliners |>    count(doc_id) |>    gt()  gt_details gt_details |>    fmt_integer(n) |>    cols_label(     doc_id = \"\",     n = \"words\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"word-frequencies","dir":"Articles","previous_headings":"Preparing tables with dplyr and gt","what":"Word frequencies","title":"Vectorized functions","text":"standard workflow preparing polished table high-frequency word counts tmtyro—add_frequency() |> tabulize()—easily show used words document. use get_frequency() adding columns word counts, chain functions prepare summary table—group_by() |> summarize() |> ungroup() |> slice_max(). ’s ready, gt() rest. cols_label() function gt can adjust headers, tmtyro’s collapse_rows() function cleans repeated values first column: Choosing adjust things manually introduces steeper learning curve, also allows greater customization: Dictionary matches, including sentiment, follow pattern.","code":"dubliners_count <- dubliners_count |>   group_by(doc_id, word) |>    summarize(n = max(n)) |>    ungroup() |>    slice_max(     order_by = n,      by = doc_id,      n = 3) # show three words each  gt_counts <- dubliners_count |>    # limit to three stories for a shorter display   filter(doc_id %in% c(\"The Sisters\", \"An Encounter\", \"The Dead\")) |>    gt()  gt_counts gt_counts |>    cols_label(doc_id = \"\") |>    collapse_rows(doc_id) dubliners_count |>    filter(doc_id %in% c(\"The Sisters\", \"An Encounter\", \"The Dead\")) |>    gt(groupname_col = \"doc_id\") |>    cols_label(     word = \"\") |>    data_color(columns = n, palette = \"PuBuGn\") |>    tab_style(     style = cell_text(weight = \"bold\"),     locations = cells_row_groups())"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"vocabulary-richness-1","dir":"Articles","previous_headings":"Preparing tables with dplyr and gt","what":"Vocabulary richness","title":"Vectorized functions","text":"similar manual workflow can used prepare tables vocabulary richness: , tab spanners can added approximate version created typical tmtyro workflow:","code":"gt_vocab <- corpus_dubliners |>    filter(doc_id %in% c(\"The Sisters\", \"An Encounter\", \"The Dead\")) |>    group_by(doc_id) |>    summarize(     length = n(),     vocab_count = sum(is_new(word)),     ttr = last(get_ttr(word)),     hapax_count = sum(is_hapax(word)),     htr = last(get_hir(word))) |>    ungroup() |>    gt()  gt_vocab gt_vocab |>    tab_spanner(     label = \"vocabulary\",     columns = c(\"vocab_count\", \"ttr\")) |>    tab_spanner(     label = \"hapax\",     columns = c(\"hapax_count\", \"htr\")) |>    cols_label(     vocab_count = \"total\",     ttr = \"ratio\",     hapax_count = \"total\",     htr = \"ratio\") |>    fmt_number(c(ttr, htr), decimals = 3)"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"extending-tabulize","dir":"Articles","previous_headings":"Preparing tables with dplyr and gt","what":"Extending tabulize()","title":"Vectorized functions","text":"Learning gt’s functions can also helpful customizing outputs derived tabulize(), just gt objects. demonstrate usefulness customization, can create short table word counts selecting titles showing default output tabulize(): table functional necessarily pretty. beauty subjective, customization makes possible aim something clean like :","code":"some_docs <- unique(corpus_dubliners$doc_id)[c(1:3, 12, 15)]  gt_1 <- corpus_dubliners |>    filter(doc_id %in% some_docs) |>    tabulize()  gt_1 gt_1 |>    tab_style(     style = cell_borders(       sides = \"all\",        color = NULL),     locations = cells_body()) |>    tab_style(     style = cell_text(size = pct(70)),     locations = cells_column_labels()   ) |>    cols_align(     align = \"right\",     columns = doc_id) |>    opt_css(     css = \".gt_col_headings {border-bottom-color: #FFFFFF !important;}\"   )"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"preparing-figures-with-ggplot2","dir":"Articles","previous_headings":"","what":"Preparing figures with ggplot2","title":"Vectorized functions","text":"Vectorized functions beginning get_...() ...() won’t work well tmtyro’s visualize() function, made standard workflow. visualizations built ggplot2, can recreated little effort nearly limitless customization. Consult ggplot2 documentation learn methods can demonstrated .","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"corpus-details-1","dir":"Articles","previous_headings":"Preparing figures with ggplot2","what":"Corpus details","title":"Vectorized functions","text":"default, corpus prepared load_texts() visualize() bar chart showing word counts document. Preparing something manually pretty simple, even doesn’t compare well default output:  Among things, visualize() preserves order documents top bottom, adjusts labeling, adds settings theme color. Alone, simple change. everything adds polishing publication-ready graphs, including customizing gridlines, adjusting label spacing, formatting numbers:","code":"# default output visualize(corpus_dubliners)  # manual output corpus_dubliners |>    count(doc_id) |>    ggplot(aes(     x = n,      y = doc_id)) +   geom_col() corpus_dubliners |>    count(doc_id) |>    # reverse doc_id order   mutate(doc_id = forcats::fct_rev(doc_id)) |>    ggplot(aes(     x = n,      y = doc_id,      # add color     fill = doc_id)) +   geom_col(show.legend = FALSE) +   # adjust number format and shift y-axis labels   scale_x_continuous(     labels = scales::label_comma(),     expand = c(0, 0)) +   # change the theme background   theme_minimal() +   # adjust labels   labs(     x = \"length (words)\",     y = NULL) +   # adjust grid lines   theme(     panel.grid.minor.x = element_blank(),     panel.grid.major.y = element_blank(),     panel.grid.minor.y = element_blank())"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"word-frequencies-1","dir":"Articles","previous_headings":"Preparing figures with ggplot2","what":"Word frequencies","title":"Vectorized functions","text":"used add_frequency(), visualize() prepare faceted graph top word frequencies document. create something similar manually, using mutate() vectorized function like get_frequency() get_tf_by(), ’s necessary prepare table summarize() slice_max() piping ggplot():  resulting graph can customized ggplot2’s functions.","code":"corpus_dubliners |>   mutate(     n = get_tf_by(word, doc_id)) |>    group_by(doc_id, word) |>    summarize(n = max(n)) |>    ungroup() |>    slice_max(     order_by = n,      by = doc_id,      n = 3) |> # show 3 words each   ggplot(aes(n, word)) +   geom_col() +   facet_wrap(vars(doc_id), scales = \"free\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/03-skills-ramp.html","id":"vocabulary-richness-2","dir":"Articles","previous_headings":"Preparing figures with ggplot2","what":"Vocabulary richness","title":"Vectorized functions","text":"default visualizations tmtyro makes add_vocabulary() highly customized. isn’t hard make simple version vectorized function like get_cumulative_vocabulary(), version can lack readability:  Adding direct labels often worth effort:","code":"corpus_dubliners |>    group_by(doc_id) |>    mutate(     vocab = get_cumulative_vocabulary(word),      progress = row_number()) |>    ungroup() |>    ggplot(aes(     x = progress,      y = vocab,      color = doc_id)) +   geom_line() dubliners_vocab <- corpus_dubliners |>    group_by(doc_id) |>    mutate(     vocab = get_cumulative_vocabulary(word),      progress = row_number()) |>    ungroup()  # table of labels and locations document_labels <- dubliners_vocab |>    group_by(doc_id) |>    summarize(     vocab = last(vocab),     progress = last(progress)) |>    ungroup()  dubliners_vocab |>    ggplot(aes(     x = progress,      y = vocab,      color = doc_id)) +   geom_line() +   geom_point(     data = document_labels) +   # avoid overlapping labels   ggrepel::geom_text_repel(     data = document_labels,     aes(label = doc_id)) +   theme(legend.position = \"none\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"preparing-texts","dir":"Articles","previous_headings":"","what":"Preparing texts","title":"Introduction to tmtyro","text":"tmtyro offers functions gather load texts study: get_gutenberg_corpus() caches HTML version books Project Gutenberg ID, parses text headers, presents table. get_micusp_corpus() caches papers Michigan Corpus Upper-level Student Papers, parses metadata contents, presents table. download_once() caches online file passes local path invisibly. load_texts() prepares table “tidytext” format one word per row columns metadata. texts can loaded folder files passed table. Parameters allow lemmatization, part--speech processing, options. functions aid preparing corpus: move_header_to_text() corrects overzealous identification HTML headers parsing books Project Gutenberg. standardize_titles() converts vector column title case, converts underscores spaces, optionally removes initial articles. identify_by() sets column metadata serve document marker.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"get-a-corpus","dir":"Articles","previous_headings":"Preparing texts","what":"Get a corpus","title":"Introduction to tmtyro","text":"Collecting texts Project Gutenberg common first step many. function get_gutenberg_corpus() needs Gutenberg ID number, found book’s URL. resulting table draws metadata gutenbergr package, columns “gutenberg_id”, “title”, “author”, headers used chapters, “text.” cases, headers may make better sense read part text, “Aeolus” chapter Ulysses, frequent newspaper headlines pepper page: can corrected move_header_to_text(). Headers can moved specific texts corpus specifying filter like title == \"Ulysses\":","code":"library(tmtyro) joyce <- get_gutenberg_corpus(c(2814, 4217, 4300))  joyce #> # A tibble: 10,810 × 7 #>    gutenberg_id title     author       part        section subsection text       #>           <int> <chr>     <chr>        <chr>       <chr>   <chr>      <chr>      #>  1         2814 Dubliners Joyce, James THE SISTERS NA      NA         There was… #>  2         2814 Dubliners Joyce, James THE SISTERS NA      NA         Old Cotte… #>  3         2814 Dubliners Joyce, James THE SISTERS NA      NA         “No, I wo… #>  4         2814 Dubliners Joyce, James THE SISTERS NA      NA         He began … #>  5         2814 Dubliners Joyce, James THE SISTERS NA      NA         “I have m… #>  6         2814 Dubliners Joyce, James THE SISTERS NA      NA         He began … #>  7         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Well, so… #>  8         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Who?” sa… #>  9         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Father F… #> 10         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Is he de… #> # ℹ 10,800 more rows ulysses <- get_gutenberg_corpus(4300)  # dplyr is used here to choose a smaller example for comparison ulysses |>    dplyr::filter(section == \"[ 7 ]\") #> # A tibble: 476 × 7 #>    gutenberg_id title   author       part   section subsection             text  #>           <int> <chr>   <chr>        <chr>  <chr>   <chr>                  <chr> #>  1         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… Befo… #>  2         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… —Rat… #>  3         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… —Com… #>  4         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… Righ… #>  5         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… —Sta… #>  6         4300 Ulysses Joyce, James — II — [ 7 ]   THE WEARER OF THE CRO… Unde… #>  7         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS Gros… #>  8         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS —The… #>  9         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS —Jus… #> 10         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS The … #> # ℹ 466 more rows ulysses <- get_gutenberg_corpus(4300) |>    move_header_to_text(subsection)  # dplyr is used here to choose a smaller example for comparison ulysses |>    dplyr::filter(section == \"[ 7 ]\") #> # A tibble: 539 × 6 #>    gutenberg_id title   author       part   section text                         #>           <int> <chr>   <chr>        <chr>  <chr>   <chr>                        #>  1         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE HIBERNI… #>  2         4300 Ulysses Joyce, James — II — [ 7 ]   Before Nelson’s pillar tram… #>  3         4300 Ulysses Joyce, James — II — [ 7 ]   —Rathgar and Terenure!       #>  4         4300 Ulysses Joyce, James — II — [ 7 ]   —Come on, Sandymount Green!  #>  5         4300 Ulysses Joyce, James — II — [ 7 ]   Right and left parallel cla… #>  6         4300 Ulysses Joyce, James — II — [ 7 ]   —Start, Palmerston Park!     #>  7         4300 Ulysses Joyce, James — II — [ 7 ]   THE WEARER OF THE CROWN      #>  8         4300 Ulysses Joyce, James — II — [ 7 ]   Under the porch of the gene… #>  9         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS       #> 10         4300 Ulysses Joyce, James — II — [ 7 ]   Grossbooted draymen rolled … #> # ℹ 529 more rows joyce <- joyce |>    move_header_to_text(subsection, title == \"Ulysses\")  joyce |>    dplyr::filter(section == \"[ 7 ]\") #> # A tibble: 539 × 6 #>    gutenberg_id title   author       part   section text                         #>           <int> <chr>   <chr>        <chr>  <chr>   <chr>                        #>  1         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE HIBERNI… #>  2         4300 Ulysses Joyce, James — II — [ 7 ]   Before Nelson’s pillar tram… #>  3         4300 Ulysses Joyce, James — II — [ 7 ]   —Rathgar and Terenure!       #>  4         4300 Ulysses Joyce, James — II — [ 7 ]   —Come on, Sandymount Green!  #>  5         4300 Ulysses Joyce, James — II — [ 7 ]   Right and left parallel cla… #>  6         4300 Ulysses Joyce, James — II — [ 7 ]   —Start, Palmerston Park!     #>  7         4300 Ulysses Joyce, James — II — [ 7 ]   THE WEARER OF THE CROWN      #>  8         4300 Ulysses Joyce, James — II — [ 7 ]   Under the porch of the gene… #>  9         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS       #> 10         4300 Ulysses Joyce, James — II — [ 7 ]   Grossbooted draymen rolled … #> # ℹ 529 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"load-texts","dir":"Articles","previous_headings":"Preparing texts","what":"Load texts","title":"Introduction to tmtyro","text":"load_texts() prepares set documents study, either table folder files.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"from-a-table","dir":"Articles","previous_headings":"Preparing texts > Load texts","what":"From a table","title":"Introduction to tmtyro","text":"table like one prepared get_gutenberg_corpus() can prepared tidytext format one word per row using load_texts().","code":"corpus_ulysses <- ulysses |>    load_texts()  corpus_ulysses #> # A tibble: 265,043 × 6 #>    doc_id title   author       part  section word      #>     <int> <chr>   <chr>        <chr> <chr>   <chr>     #>  1   4300 Ulysses Joyce, James — I — [ 1 ]   stately   #>  2   4300 Ulysses Joyce, James — I — [ 1 ]   plump     #>  3   4300 Ulysses Joyce, James — I — [ 1 ]   buck      #>  4   4300 Ulysses Joyce, James — I — [ 1 ]   mulligan  #>  5   4300 Ulysses Joyce, James — I — [ 1 ]   came      #>  6   4300 Ulysses Joyce, James — I — [ 1 ]   from      #>  7   4300 Ulysses Joyce, James — I — [ 1 ]   the       #>  8   4300 Ulysses Joyce, James — I — [ 1 ]   stairhead #>  9   4300 Ulysses Joyce, James — I — [ 1 ]   bearing   #> 10   4300 Ulysses Joyce, James — I — [ 1 ]   a         #> # ℹ 265,033 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"from-files","dir":"Articles","previous_headings":"Preparing texts > Load texts","what":"From files","title":"Introduction to tmtyro","text":"text files already collected folder disk, can prepared table passing path folder inside load_texts(). Used way, load_texts() load every file using “txt” file extension, populating doc_id column first part file name. example, “austen” folder found within current project. instead found somewhere else computer, complete path can passed like :load_texts(\"~/corpora/austen\")","code":"corpus_austen <- load_texts(\"austen\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"choose-a-different-doc_id","dir":"Articles","previous_headings":"Preparing texts","what":"Choose a different doc_id","title":"Introduction to tmtyro","text":"Documents loaded get_gutenberg_corpus() use gutenberg_id column document identifier. different column preferred, identify_by() makes switch. example Dubliners, instance, story’s title shown “part”. identify_by() makes easy identify documents column:","code":"corpus_dubliners <- get_gutenberg_corpus(2814) |>    load_texts(lemma = TRUE, pos = TRUE)  corpus_dubliners #> # A tibble: 67,885 × 7 #>    doc_id title     author       part        word  pos   lemma #>     <int> <chr>     <chr>        <chr>       <chr> <chr> <chr> #>  1   2814 Dubliners Joyce, James THE SISTERS there EX    there #>  2   2814 Dubliners Joyce, James THE SISTERS was   VBD   be    #>  3   2814 Dubliners Joyce, James THE SISTERS no    DT    no    #>  4   2814 Dubliners Joyce, James THE SISTERS hope  NN    hope  #>  5   2814 Dubliners Joyce, James THE SISTERS for   IN    for   #>  6   2814 Dubliners Joyce, James THE SISTERS him   PRP   him   #>  7   2814 Dubliners Joyce, James THE SISTERS this  DT    this  #>  8   2814 Dubliners Joyce, James THE SISTERS time  NN    time  #>  9   2814 Dubliners Joyce, James THE SISTERS it    PRP   it    #> 10   2814 Dubliners Joyce, James THE SISTERS was   VBD   be    #> # ℹ 67,875 more rows corpus_dubliners <- corpus_dubliners |>    identify_by(part)  corpus_dubliners #> # A tibble: 67,885 × 7 #>    doc_id      title     author       part        word  pos   lemma #>    <fct>       <chr>     <chr>        <chr>       <chr> <chr> <chr> #>  1 THE SISTERS Dubliners Joyce, James THE SISTERS there EX    there #>  2 THE SISTERS Dubliners Joyce, James THE SISTERS was   VBD   be    #>  3 THE SISTERS Dubliners Joyce, James THE SISTERS no    DT    no    #>  4 THE SISTERS Dubliners Joyce, James THE SISTERS hope  NN    hope  #>  5 THE SISTERS Dubliners Joyce, James THE SISTERS for   IN    for   #>  6 THE SISTERS Dubliners Joyce, James THE SISTERS him   PRP   him   #>  7 THE SISTERS Dubliners Joyce, James THE SISTERS this  DT    this  #>  8 THE SISTERS Dubliners Joyce, James THE SISTERS time  NN    time  #>  9 THE SISTERS Dubliners Joyce, James THE SISTERS it    PRP   it    #> 10 THE SISTERS Dubliners Joyce, James THE SISTERS was   VBD   be    #> # ℹ 67,875 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"standardize-titles","dir":"Articles","previous_headings":"Preparing texts","what":"Standardize titles","title":"Introduction to tmtyro","text":"standardize_titles() converts titles something cleaner adopting title case.","code":"before <- unique(corpus_dubliners$doc_id)  corpus_dubliners <- corpus_dubliners |>    standardize_titles()  after <- unique(corpus_dubliners$doc_id)  data.frame(before, after) #>                           before                         after #> 1                    THE SISTERS                   The Sisters #> 2                   AN ENCOUNTER                  An Encounter #> 3                          ARABY                         Araby #> 4                        EVELINE                       Eveline #> 5                 AFTER THE RACE                After the Race #> 6                   TWO GALLANTS                  Two Gallants #> 7             THE BOARDING HOUSE            The Boarding House #> 8                 A LITTLE CLOUD                A Little Cloud #> 9                   COUNTERPARTS                  Counterparts #> 10                          CLAY                          Clay #> 11                A PAINFUL CASE                A Painful Case #> 12 IVY DAY IN THE COMMITTEE ROOM Ivy Day in the Committee Room #> 13                      A MOTHER                      A Mother #> 14                         GRACE                         Grace #> 15                      THE DEAD                      The Dead"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"studying-texts","dir":"Articles","previous_headings":"","what":"Studying texts","title":"Introduction to tmtyro","text":"Useful many stages work corpus, contextualize() shows context search term, adjustable window either side options searching regular expressions. functions studying texts follow predictable naming convention: add_frequency() adds column word frequencies. add_vocabulary() adds columns measuring lexical variety texts. add_sentiment() adds column sentiment identifiers chosen lexicon. add_ngrams() adds columns words bigrams, trigrams, . every method preserves size shape data passed : summarize_tf_idf() returns data frame every token document corpus, columns indicating weights term frequency-inverse document frequency. Along , functions assist process: drop_na() drops rows missing data column specified columns. combine_ngrams() combines multiple columns n-grams one. separate_ngrams() separatesa single column n-grams one column per word. understanding context key words show_context() might especially helpful.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"showing-context","dir":"Articles","previous_headings":"Studying texts","what":"Showing context","title":"Introduction to tmtyro","text":"contextualize() finds uses word within corpus returns window context around use. default, contextualize() returns five results, showing window three words exact search term. Adjusting limit changes number results, limit = 0 returning table. options include window adjust number words shown regex accept partial matches. loading texts, load_texts() provides option keep original capitalization punctuation. option doesn’t always work, seems incompatible current implementation part--speech parsing, ’s always appropriate. using contextualize() corpora loaded load_texts(keep_original = TRUE) show search terms much closer original context: Even limit set value 0, table results returned invisibly later recall.","code":"corpus_dubliners |>    contextualize(\"snow\") #> mat scraping the snow from his goloshes #> light fringe of snow lay like a #> home in the snow if she were #> the park the snow would be lying #> standing in the snow on the quay corpus_dubliners |>    contextualize(regex = \"sno\",                 window = 2,                 limit = 0) #> # A tibble: 22 × 4 #>    doc_id         word           index context                             #>    <fct>          <chr>          <int> <chr>                               #>  1 After the Race snorting        1088 to the SNOrting motor the           #>  2 The Dead       snow             610 scraping the SNOw from his          #>  3 The Dead       snow             705 fringe of SNOw lay like             #>  4 The Dead       snow_stiffened   739 through the SNOw_stiffened frieze a #>  5 The Dead       snowing          754 is it SNOwing again mr              #>  6 The Dead       snow            1660 in the SNOw if she                  #>  7 The Dead       snow            5411 park the SNOw would be              #>  8 The Dead       snow            8739 in the SNOw on the                  #>  9 The Dead       snow            8773 weighted with SNOw the wellington   #> 10 The Dead       snow            8782 cap of SNOw that flashed            #> # ℹ 12 more rows corpus_joyce <- joyce |>    load_texts(keep_original = TRUE) |>    identify_by(title)  tundish <-    corpus_joyce |>    contextualize(\"tundish\", limit = 1:7) #> it not a tundish? —What is a #> —What is a tundish? —That. The the #> that called a tundish in Ireland? asked #> is called a tundish in Lower Drumcondra, #> best English. —A tundish, said the dean #> word yet again. —Tundish! Well now, that #> April 13. That tundish has been on tundish #> # A tibble: 7 × 4 #>   doc_id                                  word    index context                  #>   <fct>                                   <chr>   <int> <chr>                    #> 1 A Portrait of the Artist as a Young Man tundish 63827 it not a TUNDISH? —What… #> 2 A Portrait of the Artist as a Young Man tundish 63831 —What is a TUNDISH? —Th… #> 3 A Portrait of the Artist as a Young Man tundish 63840 that called a TUNDISH i… #> 4 A Portrait of the Artist as a Young Man tundish 63858 is called a TUNDISH in … #> 5 A Portrait of the Artist as a Young Man tundish 63872 best English. —A TUNDIS… #> 6 A Portrait of the Artist as a Young Man tundish 64122 word yet again. —TUNDIS… #> 7 A Portrait of the Artist as a Young Man tundish 84352 April 13. That TUNDISH …"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"word-frequencies","dir":"Articles","previous_headings":"Studying texts","what":"Word frequencies","title":"Introduction to tmtyro","text":"add_frequency() adds word counts document new column, n. count column, indicate parentheses:","code":"counts_dubliners <-    corpus_dubliners |>    add_frequency()  counts_dubliners #> # A tibble: 67,885 × 8 #>    doc_id      title     author       part        word  pos   lemma     n #>    <fct>       <chr>     <chr>        <chr>       <chr> <chr> <chr> <int> #>  1 The Sisters Dubliners Joyce, James THE SISTERS there EX    there    15 #>  2 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be       57 #>  3 The Sisters Dubliners Joyce, James THE SISTERS no    DT    no       16 #>  4 The Sisters Dubliners Joyce, James THE SISTERS hope  NN    hope      1 #>  5 The Sisters Dubliners Joyce, James THE SISTERS for   IN    for      32 #>  6 The Sisters Dubliners Joyce, James THE SISTERS him   PRP   him      43 #>  7 The Sisters Dubliners Joyce, James THE SISTERS this  DT    this      6 #>  8 The Sisters Dubliners Joyce, James THE SISTERS time  NN    time      3 #>  9 The Sisters Dubliners Joyce, James THE SISTERS it    PRP   it       40 #> 10 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be       57 #> # ℹ 67,875 more rows corpus_dubliners |>    add_frequency(lemma) #> # A tibble: 67,885 × 8 #>    doc_id      title     author       part        word  pos   lemma     n #>    <fct>       <chr>     <chr>        <chr>       <chr> <chr> <chr> <int> #>  1 The Sisters Dubliners Joyce, James THE SISTERS there EX    there    15 #>  2 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be       98 #>  3 The Sisters Dubliners Joyce, James THE SISTERS no    DT    no       16 #>  4 The Sisters Dubliners Joyce, James THE SISTERS hope  NN    hope      1 #>  5 The Sisters Dubliners Joyce, James THE SISTERS for   IN    for      32 #>  6 The Sisters Dubliners Joyce, James THE SISTERS him   PRP   him      43 #>  7 The Sisters Dubliners Joyce, James THE SISTERS this  DT    this      9 #>  8 The Sisters Dubliners Joyce, James THE SISTERS time  NN    time      3 #>  9 The Sisters Dubliners Joyce, James THE SISTERS it    PRP   it       40 #> 10 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be       98 #> # ℹ 67,875 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"vocabulary-richness","dir":"Articles","previous_headings":"Studying texts","what":"Vocabulary richness","title":"Introduction to tmtyro","text":"add_vocabulary() adds measurements vocabulary richness, including cumulative vocabulary size, indicators hapax legomena, markers progress.","code":"vocab_dubliners <-    corpus_dubliners |>    add_vocabulary()  vocab_dubliners #> # A tibble: 67,885 × 14 #>    doc_id   title author part  word  pos   lemma new_word hapax vocabulary   ttr #>    <fct>    <chr> <chr>  <chr> <chr> <chr> <chr> <lgl>    <lgl>      <int> <dbl> #>  1 The Sis… Dubl… Joyce… THE … there EX    there TRUE     FALSE          1   1   #>  2 The Sis… Dubl… Joyce… THE … was   VBD   be    TRUE     FALSE          2   1   #>  3 The Sis… Dubl… Joyce… THE … no    DT    no    TRUE     FALSE          3   1   #>  4 The Sis… Dubl… Joyce… THE … hope  NN    hope  TRUE     TRUE           4   1   #>  5 The Sis… Dubl… Joyce… THE … for   IN    for   TRUE     FALSE          5   1   #>  6 The Sis… Dubl… Joyce… THE … him   PRP   him   TRUE     FALSE          6   1   #>  7 The Sis… Dubl… Joyce… THE … this  DT    this  TRUE     FALSE          7   1   #>  8 The Sis… Dubl… Joyce… THE … time  NN    time  TRUE     FALSE          8   1   #>  9 The Sis… Dubl… Joyce… THE … it    PRP   it    TRUE     FALSE          9   1   #> 10 The Sis… Dubl… Joyce… THE … was   VBD   be    FALSE    FALSE          9   0.9 #> # ℹ 67,875 more rows #> # ℹ 3 more variables: hir <dbl>, progress_words <int>, progress_percent <dbl>"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"sentiment","dir":"Articles","previous_headings":"Studying texts","what":"Sentiment","title":"Introduction to tmtyro","text":"add_sentiment() adds measurements sentiment using “Bing” lexicon default.","code":"sentiment_dubliners <- corpus_dubliners |>    add_sentiment()  sentiment_dubliners #> # A tibble: 67,886 × 8 #>    doc_id      title     author       part        word  pos   lemma sentiment #>    <fct>       <chr>     <chr>        <chr>       <chr> <chr> <chr> <chr>     #>  1 The Sisters Dubliners Joyce, James THE SISTERS there EX    there NA        #>  2 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be    NA        #>  3 The Sisters Dubliners Joyce, James THE SISTERS no    DT    no    NA        #>  4 The Sisters Dubliners Joyce, James THE SISTERS hope  NN    hope  NA        #>  5 The Sisters Dubliners Joyce, James THE SISTERS for   IN    for   NA        #>  6 The Sisters Dubliners Joyce, James THE SISTERS him   PRP   him   NA        #>  7 The Sisters Dubliners Joyce, James THE SISTERS this  DT    this  NA        #>  8 The Sisters Dubliners Joyce, James THE SISTERS time  NN    time  NA        #>  9 The Sisters Dubliners Joyce, James THE SISTERS it    PRP   it    NA        #> 10 The Sisters Dubliners Joyce, James THE SISTERS was   VBD   be    NA        #> # ℹ 67,876 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"dropping-empty-rows","dir":"Articles","previous_headings":"Studying texts > Sentiment","what":"Dropping empty rows","title":"Introduction to tmtyro","text":"Since many words may found given sentiment lexicon, drop_na() makes easy remove empty rows.","code":"sentiment_dubliners |>    drop_na(sentiment) #> # A tibble: 3,787 × 8 #>    doc_id      title     author       part        word     pos   lemma sentiment #>    <fct>       <chr>     <chr>        <chr>       <chr>    <chr> <chr> <chr>     #>  1 The Sisters Dubliners Joyce, James THE SISTERS evenly   RB    even… positive  #>  2 The Sisters Dubliners Joyce, James THE SISTERS dead     JJ    dead  negative  #>  3 The Sisters Dubliners Joyce, James THE SISTERS darkened VBN   dark… negative  #>  4 The Sisters Dubliners Joyce, James THE SISTERS blind    NN    blind negative  #>  5 The Sisters Dubliners Joyce, James THE SISTERS idle     VB    idle  negative  #>  6 The Sisters Dubliners Joyce, James THE SISTERS strange… RB    stra… negative  #>  7 The Sisters Dubliners Joyce, James THE SISTERS like     IN    like  positive  #>  8 The Sisters Dubliners Joyce, James THE SISTERS like     IN    like  positive  #>  9 The Sisters Dubliners Joyce, James THE SISTERS sinful   JJ    sinf… negative  #> 10 The Sisters Dubliners Joyce, James THE SISTERS fear     NN    fear  negative  #> # ℹ 3,777 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"choosing-a-sentiment-lexicon","dir":"Articles","previous_headings":"Studying texts > Sentiment","what":"Choosing a sentiment lexicon","title":"Introduction to tmtyro","text":"lexicon can chosen measurement.","code":"sentiment_ulysses <- ulysses |>    load_texts() |>    identify_by(section) |>    add_sentiment(lexicon = \"nrc\")  sentiment_ulysses |>    drop_na(sentiment) #> # A tibble: 63,006 × 7 #>    doc_id title   author       part  section word    sentiment    #>    <fct>  <chr>   <chr>        <chr> <chr>   <chr>   <chr>        #>  1 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   stately positive     #>  2 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   plump   anticipation #>  3 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   buck    fear         #>  4 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   buck    negative     #>  5 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   buck    positive     #>  6 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   buck    surprise     #>  7 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   razor   fear         #>  8 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   dark    sadness      #>  9 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   fearful fear         #> 10 [ 1 ]  Ulysses Joyce, James — I — [ 1 ]   fearful negative     #> # ℹ 62,996 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"n-grams","dir":"Articles","previous_headings":"Studying texts","what":"N-grams","title":"Introduction to tmtyro","text":"Following pattern, add_ngrams() adds columns n-length phrases words. default, prepares bigrams (2-grams). n-grams can chosen passing vector numbers.","code":"bigrams_joyce <- corpus_joyce |>    add_ngrams()  bigrams_joyce #> # A tibble: 417,846 × 8 #>    doc_id    title     author       part        section original word_1 word_2 #>    <fct>     <chr>     <chr>        <chr>       <chr>   <chr>    <chr>  <chr>  #>  1 Dubliners Dubliners Joyce, James THE SISTERS NA      There    there  was    #>  2 Dubliners Dubliners Joyce, James THE SISTERS NA      was      was    no     #>  3 Dubliners Dubliners Joyce, James THE SISTERS NA      no       no     hope   #>  4 Dubliners Dubliners Joyce, James THE SISTERS NA      hope     hope   for    #>  5 Dubliners Dubliners Joyce, James THE SISTERS NA      for      for    him    #>  6 Dubliners Dubliners Joyce, James THE SISTERS NA      him      him    this   #>  7 Dubliners Dubliners Joyce, James THE SISTERS NA      this     this   time   #>  8 Dubliners Dubliners Joyce, James THE SISTERS NA      time:    time   it     #>  9 Dubliners Dubliners Joyce, James THE SISTERS NA      it       it     was    #> 10 Dubliners Dubliners Joyce, James THE SISTERS NA      was      was    the    #> # ℹ 417,836 more rows trigrams_joyce <- corpus_joyce |>    add_ngrams(1:3)  trigrams_joyce #> # A tibble: 417,846 × 9 #>    doc_id    title     author       part   section original word_1 word_2 word_3 #>    <fct>     <chr>     <chr>        <chr>  <chr>   <chr>    <chr>  <chr>  <chr>  #>  1 Dubliners Dubliners Joyce, James THE S… NA      There    there  was    no     #>  2 Dubliners Dubliners Joyce, James THE S… NA      was      was    no     hope   #>  3 Dubliners Dubliners Joyce, James THE S… NA      no       no     hope   for    #>  4 Dubliners Dubliners Joyce, James THE S… NA      hope     hope   for    him    #>  5 Dubliners Dubliners Joyce, James THE S… NA      for      for    him    this   #>  6 Dubliners Dubliners Joyce, James THE S… NA      him      him    this   time   #>  7 Dubliners Dubliners Joyce, James THE S… NA      this     this   time   it     #>  8 Dubliners Dubliners Joyce, James THE S… NA      time:    time   it     was    #>  9 Dubliners Dubliners Joyce, James THE S… NA      it       it     was    the    #> 10 Dubliners Dubliners Joyce, James THE S… NA      was      was    the    third  #> # ℹ 417,836 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"tf-idf","dir":"Articles","previous_headings":"Studying texts","what":"Tf-idf","title":"Introduction to tmtyro","text":"add_tf_idf() adds measurements term frequency (tf), inverse document frequency (idf), combined term frequency–inverse document frequency (tf_idf). Term frequency–inverse document frequency commonly used way summarizing language used, paying less attention word order reducing documents one instance token. study texts way, summarize_tf_idf() returns table arranged descending strength tf-idf. Tf-idf’s method understandably emphasizes proper nouns unique document. remove_names argument load_texts() can help filter words appear capitalized form. Removing names Dubliners makes noticeable difference tf-idf results: load_texts() used pos = TRUE, proper nouns can filtered, tags sometimes inaccurate.","code":"corpus_dubliners |>    add_tf_idf() #> # A tibble: 67,885 × 11 #>    doc_id      title author part  word  pos   lemma     n      tf    idf  tf_idf #>    <fct>       <chr> <chr>  <chr> <chr> <chr> <chr> <int>   <dbl>  <dbl>   <dbl> #>  1 The Sisters Dubl… Joyce… THE … there EX    there    15 0.0048  0      0       #>  2 The Sisters Dubl… Joyce… THE … was   VBD   be       57 0.0182  0      0       #>  3 The Sisters Dubl… Joyce… THE … no    DT    no       16 0.00512 0      0       #>  4 The Sisters Dubl… Joyce… THE … hope  NN    hope      1 0.00032 0.511  1.63e-4 #>  5 The Sisters Dubl… Joyce… THE … for   IN    for      32 0.0102  0      0       #>  6 The Sisters Dubl… Joyce… THE … him   PRP   him      43 0.0138  0      0       #>  7 The Sisters Dubl… Joyce… THE … this  DT    this      6 0.00192 0.0690 1.32e-4 #>  8 The Sisters Dubl… Joyce… THE … time  NN    time      3 0.00096 0      0       #>  9 The Sisters Dubl… Joyce… THE … it    PRP   it       40 0.0128  0      0       #> 10 The Sisters Dubl… Joyce… THE … was   VBD   be       57 0.0182  0      0       #> # ℹ 67,875 more rows tfidf_dubliners <- corpus_dubliners |>    summarize_tf_idf()  tfidf_dubliners #> # A tibble: 17,656 × 6 #>    doc_id                        word         n      tf   idf tf_idf #>    <fct>                         <chr>    <int>   <dbl> <dbl>  <dbl> #>  1 Clay                          maria       40 0.0151   2.71 0.0409 #>  2 Two Gallants                  corley      46 0.0117   2.71 0.0318 #>  3 After the Race                jimmy       24 0.0107   2.71 0.0291 #>  4 Ivy Day in the Committee Room henchy      53 0.0101   2.71 0.0272 #>  5 A Little Cloud                gallaher    48 0.00964  2.71 0.0261 #>  6 The Dead                      gabriel    142 0.00906  2.71 0.0245 #>  7 Grace                         kernan      66 0.00873  2.71 0.0236 #>  8 Ivy Day in the Committee Room o’connor    45 0.00854  2.71 0.0231 #>  9 A Little Cloud                chandler    41 0.00823  2.71 0.0223 #> 10 A Mother                      kearney     50 0.0110   2.01 0.0223 #> # ℹ 17,646 more rows tfidf_dubliners <- get_gutenberg_corpus(2814) |>    load_texts(remove_names = TRUE) |>    identify_by(part) |>    standardize_titles() |>    summarize_tf_idf()  tfidf_dubliners #> # A tibble: 16,721 × 6 #>    doc_id         word         n      tf   idf  tf_idf #>    <fct>          <chr>    <int>   <dbl> <dbl>   <dbl> #>  1 The Dead       aunt       101 0.00693 1.61  0.0112  #>  2 Araby          bazaar       9 0.00406 2.71  0.0110  #>  3 The Sisters    aunt        19 0.00649 1.61  0.0104  #>  4 After the Race cars         6 0.00286 2.71  0.00773 #>  5 An Encounter   we          58 0.0189  0.405 0.00767 #>  6 After the Race car         11 0.00524 1.32  0.00692 #>  7 Eveline        avenue       4 0.00225 2.71  0.00610 #>  8 Counterparts   weathers    11 0.00283 2.01  0.00570 #>  9 Counterparts   pa           8 0.00206 2.71  0.00557 #> 10 The Sisters    snuff        6 0.00205 2.71  0.00555 #> # ℹ 16,711 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"preparing-tables","dir":"Articles","previous_headings":"","what":"Preparing tables","title":"Introduction to tmtyro","text":"tabulize() prepares tables every kind measurement. repetition makes easy see appreciate findings without struggling recall specialized function.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"corpus-details","dir":"Articles","previous_headings":"Preparing tables","what":"Corpus details","title":"Introduction to tmtyro","text":"default, tabulize() prepares table showing lengths document.","code":"corpus_joyce |>    tabulize()"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"word-frequencies-1","dir":"Articles","previous_headings":"Preparing tables","what":"Word frequencies","title":"Introduction to tmtyro","text":"add_frequency(), tabulize() show counts -frequent words.","code":"corpus_joyce |>    add_frequency() |>    tabulize()"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"vocabulary-richness-1","dir":"Articles","previous_headings":"Preparing tables","what":"Vocabulary richness","title":"Introduction to tmtyro","text":"used add_vocabulary(), tabulize() prepares clean summary table.","code":"corpus_joyce |>    add_vocabulary() |>    tabulize()"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"sentiment-1","dir":"Articles","previous_headings":"Preparing tables","what":"Sentiment","title":"Introduction to tmtyro","text":"sentiment analysis, tabulize() returns summary figures document. Setting drop_na = TRUE removes rows without sentiment measure. ignore parameter aids selecting subset sentiments, converting rest NA.","code":"# dplyr is used here to choose a smaller example for comparison sentiment_dubliners_part <- sentiment_dubliners |>    dplyr::filter(doc_id %in% c(\"The Sisters\", \"An Encounter\",  \"Araby\"))  sentiment_dubliners_part |>    tabulize() sentiment_dubliners_part |>    tabulize(drop_na = TRUE) # dplyr is used here to choose a smaller example for comparison sentiment_ulysses_part <- sentiment_ulysses |>    dplyr::filter(doc_id %in% c(\"[ 1 ]\", \"[ 2 ]\", \"[ 3 ]\"))  sentiment_ulysses_part |>    tabulize(ignore = c(\"anger\", \"anticipation\", \"disgust\", \"fear\", \"trust\", \"positive\", \"negative\"))"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"n-grams-1","dir":"Articles","previous_headings":"Preparing tables","what":"N-grams","title":"Introduction to tmtyro","text":"add_ngrams(), tabulize() returns top n-grams per document. default, first six shown group, rows can chosen freely.","code":"bigrams_joyce |>    tabulize(rows = 1:2)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"tf-idf-1","dir":"Articles","previous_headings":"Preparing tables","what":"Tf-idf","title":"Introduction to tmtyro","text":"data frames prepared add_tf_idf() summarize_tf_idf(), tabulize() returns six rows top-scoring words document. amount can adjusted rows argument.","code":"tfidf_dubliners |>    tabulize(rows = 1:3)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"preparing-figures","dir":"Articles","previous_headings":"","what":"Preparing figures","title":"Introduction to tmtyro","text":"tmtyro provides many functions preparing figures, one typically needed: visualize() works intuitively tmtyro objects, preparing figures suited whatever work done. Customization easy: change_colors() provides single interface modifying filled colored layers.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"corpus-details-1","dir":"Articles","previous_headings":"Preparing figures","what":"Corpus details","title":"Introduction to tmtyro","text":"default, visualize() prepares figure showing lengths document.","code":"corpus_joyce |>    visualize(inorder = FALSE)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"word-counts","dir":"Articles","previous_headings":"Preparing figures","what":"Word counts","title":"Introduction to tmtyro","text":"Using visualize() add_frequency() chart frequent words document.  visualize() takes additional arguments customizing results.","code":"corpus_joyce |>    add_frequency() |>    visualize() counts_dubliners |>    visualize(rows = 1:3,              color_y = TRUE,              reorder_y = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"vocabulary-richness-2","dir":"Articles","previous_headings":"Preparing figures","what":"Vocabulary richness","title":"Introduction to tmtyro","text":"used add_vocabulary(), visualize() charts document length number unique tokens. figure like useful compare documents rate vocabulary growth.  features, type-token ratio (“ttr”), hapax introduction ratio (“hir”), sampling hapax legomena (“hapax”) can also shown.","code":"corpus_dubliners |>    add_vocabulary() |>    visualize() vocab_dubliners |>    visualize(\"ttr\") corpus_joyce |>    add_vocabulary() |>    visualize(\"hapax\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"sentiment-2","dir":"Articles","previous_headings":"Preparing figures","what":"Sentiment","title":"Introduction to tmtyro","text":"sentiment analysis, visualize() allows comparison among documents set.  ignore parameter stipulates values remove Y-axis focus figure.","code":"sentiment_dubliners |>    visualize() sentiment_ulysses |>    visualize(ignore = c(\"anger\", \"anticipation\", \"disgust\", \"fear\", \"trust\", \"positive\", \"negative\"))"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"n-grams-2","dir":"Articles","previous_headings":"Preparing figures","what":"N-grams","title":"Introduction to tmtyro","text":"n-grams, visualize() typically returns network visualization inspired bigram network Text Mining R.","code":"bigrams_joyce |>    visualize()"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"combining-n-grams","dir":"Articles","previous_headings":"Preparing figures","what":"Combining n-grams","title":"Introduction to tmtyro","text":"N-gram frequencies can compared combining visualization. Certain arguments allow deviation typical charts, including choosing rows chart modifying colors set values Y-axis.","code":"bigrams_joyce |>    dplyr::filter(word_1 == \"he\") |>    combine_ngrams() |>    visualize(rows = 1:5, color_y = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"tf-idf-2","dir":"Articles","previous_headings":"Preparing figures","what":"Tf-idf","title":"Introduction to tmtyro","text":"visualize() returns bars showing top words document. can useful way differentiate texts set . tfidf_dubliners prepared load_texts(remove_names = TRUE), resulting chart shows clearer delineation topics characteristic stories Joyce’s collection:","code":"tfidf_dubliners |>    visualize(rows = 1:4)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"changing-colors","dir":"Articles","previous_headings":"Preparing figures","what":"Changing colors","title":"Introduction to tmtyro","text":"change_colors() name implies. default, adopts “Dark2” palette Brewer.  Colors can chosen manually.  Optionally, use named vector set colors value instead order. default unnamed colors gray.  Unnamed colors fill needed.  choose predetermined color set palette, described function documentation.","code":"sentiment_dubliners |>    visualize() |>    change_colors() library(ggraph) bigrams_joyce |>    visualize(top_n = 60) |>    change_colors(c(\"#999999\",                    \"orange\",                    \"darkred\")) bigrams_joyce |>    dplyr::filter(word_1 == \"he\") |>    combine_ngrams() |>    visualize(rows = 1:5, color_y = TRUE, reorder_y = TRUE) |>    change_colors(c(     \"he is\" = \"darkorange\",     \"he has\" = \"orange\")) bigrams_joyce |>    dplyr::filter(word_1 == \"he\") |>    combine_ngrams() |>    visualize(rows = 1:5, color_y = TRUE, reorder_y = TRUE) |>    change_colors(c(     \"he is\" = \"darkorange\",     \"he has\" = \"orange\",      \"navy\", \"skyblue\")) tfidf_dubliners |>    visualize(rows = 1:4) |>    change_colors(colorset = \"viridis\", palette = \"mako\", direction = -1)"},{"path":"https://jmclawson.github.io/tmtyro/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James Clawson. Author, maintainer.","code":""},{"path":"https://jmclawson.github.io/tmtyro/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Clawson J (2024). tmtyro: tmtyro: Simplified Workflows Text Mining Tyros. R package version 0.5, https://jmclawson.github.io/tmtyro/, https://github.com/jmclawson/tmtyro.","code":"@Manual{,   title = {tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros},   author = {James Clawson},   year = {2024},   note = {R package version 0.5, https://jmclawson.github.io/tmtyro/},   url = {https://github.com/jmclawson/tmtyro}, }"},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"tmtyro-","dir":"","previous_headings":"","what":"tmtyro: Simplified Workflows for Text Mining Tyros","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"tmtyro designed help beginners work analyze text simple complex features. Adopting tidytext principles, tmtyro abstracts processes levels allow tyros apply text mining techniques ’re deeply familiar R code.","code":""},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"can install development version tmtyro GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"jmclawson/tmtyro\")"},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"use","dir":"","previous_headings":"","what":"Use","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"’re ready, begin introduction, start using package right away load texts directory, measure sentiment, visualize results:","code":"library(tmtyro)  mysteries <- load_texts(\"mycorpus\")  mysteries <- add_sentiment(mysteries)  visualize(mysteries)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":null,"dir":"Reference","previous_headings":"","what":"Add values from a dictionary — add_dictionary","title":"Add values from a dictionary — add_dictionary","text":"Add values dictionary","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add values from a dictionary — add_dictionary","text":"","code":"add_dictionary(df, dictionary, feature = word, keep_term = NULL)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add values from a dictionary — add_dictionary","text":"df tidy data frame, potentially containing column called \"word\" dictionary data frame two columns, potentially made make_dictionary() feature column (like \"word\") use looking values dictionary keep_term Whether retain original term value. option especially useful dictionaries containing terms longer one word length; NULL value keep term dictionaries discarding terms one word.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add values from a dictionary — add_dictionary","text":"original data frame one columns added.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add values from a dictionary — add_dictionary","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  emoji_weather <- make_dictionary(   list(     \"️☔️\" = c(\"rain\", \"rains\", \"rainy\", \"raining\"),     \"️⛈️\" = c(\"storm\", \"storms\", \"stormy\", \"storming\"),     \"☁️\" = c(\"cloud\", \"clouds\", \"cloudy\"),     \"🌞\" = c(\"sun\", \"sunny\"),     \"🌫️\" = c(\"fog\", \"fogs\", \"foggy\", \"mist\", \"misty\"),     \"🌬️\" = c(\"wind\", \"winds\", \"windy\"),     \"️❄️\" = c(\"snow\", \"snows\", \"snowing\")),   name = \"weather\")  dubliners |>    add_dictionary(emoji_weather) |>    drop_na() |>    head() #> # A tibble: 6 × 6 #>   doc_id       title     author       part         word   weather #>   <fct>        <chr>     <chr>        <chr>        <chr>  <chr>   #> 1 The Sisters  Dubliners Joyce, James THE SISTERS  clouds ☁️       #> 2 The Sisters  Dubliners Joyce, James THE SISTERS  sunny  🌞      #> 3 The Sisters  Dubliners Joyce, James THE SISTERS  sun    🌞      #> 4 The Sisters  Dubliners Joyce, James THE SISTERS  clouds ☁️       #> 5 An Encounter Dubliners Joyce, James AN ENCOUNTER storm  ️⛈️       #> 6 An Encounter Dubliners Joyce, James AN ENCOUNTER sunny  🌞"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_frequency.html","id":null,"dir":"Reference","previous_headings":"","what":"Count words or other features — add_frequency","title":"Count words or other features — add_frequency","text":"Count words features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_frequency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count words or other features — add_frequency","text":"","code":"add_frequency(df, feature = word, by = doc_id)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_frequency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count words or other features — add_frequency","text":"df tidy data frame, potentially containing column called \"word\" feature feature count document grouping column identifying document, doc_id.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_frequency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count words or other features — add_frequency","text":"original data frame column added count","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_frequency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count words or other features — add_frequency","text":"","code":"if (FALSE) { # \\dontrun{   my_corpus <- load_texts()    my_bigrams <- my_corpus |>     add_frequency() } # }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_frequency() |>   head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word      n #>   <fct>       <chr>     <chr>        <chr>       <chr> <int> #> 1 The Sisters Dubliners Joyce, James THE SISTERS there    15 #> 2 The Sisters Dubliners Joyce, James THE SISTERS was      56 #> 3 The Sisters Dubliners Joyce, James THE SISTERS no       16 #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope      1 #> 5 The Sisters Dubliners Joyce, James THE SISTERS for      32 #> 6 The Sisters Dubliners Joyce, James THE SISTERS him      43"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Index document row numbers — add_index","title":"Index document row numbers — add_index","text":"Index document row numbers","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Index document row numbers — add_index","text":"","code":"add_index(df, by = doc_id, name = word_index)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Index document row numbers — add_index","text":"df tidy data frame, divided lines, words, feature grouping column identifying document, doc_id name name use added column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Index document row numbers — add_index","text":"data frame one additional column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Index document row numbers — add_index","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_index() |>   add_sentiment() |>   drop_na() |>   head() #> # A tibble: 6 × 7 #>   doc_id      title     author       part        word_index word      sentiment #>   <fct>       <chr>     <chr>        <chr>            <int> <chr>     <chr>     #> 1 The Sisters Dubliners Joyce, James THE SISTERS         48 evenly    positive  #> 2 The Sisters Dubliners Joyce, James THE SISTERS         52 dead      negative  #> 3 The Sisters Dubliners Joyce, James THE SISTERS         64 darkened  negative  #> 4 The Sisters Dubliners Joyce, James THE SISTERS         65 blind     negative  #> 5 The Sisters Dubliners Joyce, James THE SISTERS        100 idle      negative  #> 6 The Sisters Dubliners Joyce, James THE SISTERS        128 strangely negative"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Add ngram columns — add_ngrams","title":"Add ngram columns — add_ngrams","text":"Add ngram columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add ngram columns — add_ngrams","text":"","code":"add_ngrams(   df,   n = 1:2,   feature = word,   keep = FALSE,   collapse = FALSE,   by = doc_id )"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add ngram columns — add_ngrams","text":"df tidy data frame, potentially containing column called \"word\" n range defining extent ngram—instance, word 1 word 3. Alternatively, single number signal number words include ngram. Default value 1:2 produce bigrams. feature feature use constructing ngrams keep Whether keep original feature column collapse Whether join ngram parts single column called \"ngram\" grouping column identifying document, doc_id.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add ngram columns — add_ngrams","text":"original data frame columns added subsequent parts ngrams","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add ngram columns — add_ngrams","text":"","code":"if (FALSE) { # \\dontrun{   my_corpus <- load_texts()    my_bigrams <- my_corpus |>     add_ngrams(3) } # }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_ngrams(2) |>   head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word_1 word_2 #>   <fct>       <chr>     <chr>        <chr>       <chr>  <chr>  #> 1 The Sisters Dubliners Joyce, James THE SISTERS there  was    #> 2 The Sisters Dubliners Joyce, James THE SISTERS was    no     #> 3 The Sisters Dubliners Joyce, James THE SISTERS no     hope   #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope   for    #> 5 The Sisters Dubliners Joyce, James THE SISTERS for    him    #> 6 The Sisters Dubliners Joyce, James THE SISTERS him    this"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":null,"dir":"Reference","previous_headings":"","what":"Divide documents in equal lengths — add_partitions","title":"Divide documents in equal lengths — add_partitions","text":"Divide documents equal lengths","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Divide documents in equal lengths — add_partitions","text":"","code":"add_partitions(   df,   size = 1000,   overlap = 0,   minimum = 0.25,   by = doc_id,   character = FALSE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Divide documents in equal lengths — add_partitions","text":"df tidy data frame, potentially containing column called \"word\" size Size partition overlap Size partition overlap. value 0 1 used, overlap calculated percentage size. minimum Minimum partition size. value 0 1 used, minimum calculated percentage size. column containing document grouping character Whether return partition column character vector zeroes added padding. feature may helpful using identify_by() consider partition defining documents corpus.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Divide documents in equal lengths — add_partitions","text":"original data frame column added partition.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Divide documents in equal lengths — add_partitions","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_partitions() |>   head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        partition word  #>   <fct>       <chr>     <chr>        <chr>           <int> <chr> #> 1 The Sisters Dubliners Joyce, James THE SISTERS         1 there #> 2 The Sisters Dubliners Joyce, James THE SISTERS         1 was   #> 3 The Sisters Dubliners Joyce, James THE SISTERS         1 no    #> 4 The Sisters Dubliners Joyce, James THE SISTERS         1 hope  #> 5 The Sisters Dubliners Joyce, James THE SISTERS         1 for   #> 6 The Sisters Dubliners Joyce, James THE SISTERS         1 him"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Add sentiment markers — add_sentiment","title":"Add sentiment markers — add_sentiment","text":"add_sentiment() provides simple lexicon-based measures sentiment, comparing words text one number controlled dictionaries.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add sentiment markers — add_sentiment","text":"","code":"add_sentiment(   df,   lexicon = c(\"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\"),   feature = word )"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add sentiment markers — add_sentiment","text":"df tidy data frame, potentially containing column called \"word\" lexicon sentiment lexicon use tidytext package. Options include \"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\". feature column words containing one word per row, used dictionary look-.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add sentiment markers — add_sentiment","text":"original data frame one sentiment columns added.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add sentiment markers — add_sentiment","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>    add_sentiment() |>    drop_na() |>    head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word      sentiment #>   <fct>       <chr>     <chr>        <chr>       <chr>     <chr>     #> 1 The Sisters Dubliners Joyce, James THE SISTERS evenly    positive  #> 2 The Sisters Dubliners Joyce, James THE SISTERS dead      negative  #> 3 The Sisters Dubliners Joyce, James THE SISTERS darkened  negative  #> 4 The Sisters Dubliners Joyce, James THE SISTERS blind     negative  #> 5 The Sisters Dubliners Joyce, James THE SISTERS idle      negative  #> 6 The Sisters Dubliners Joyce, James THE SISTERS strangely negative"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare usage across a corpus — add_tf_idf","title":"Compare usage across a corpus — add_tf_idf","text":"add_tf_idf() adds measurements including term frequency document \"tf-idf\" measurements weighing relative importance comparison documents set.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare usage across a corpus — add_tf_idf","text":"","code":"add_tf_idf(df, by = doc_id, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare usage across a corpus — add_tf_idf","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" column containing document grouping feature column containing terms measured across document groupings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_tf_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare usage across a corpus — add_tf_idf","text":"original data frame additional columns added term, feature_n, (number times term used document), tf (term's frequency document), idf (inverse document frequency), tf_idf (previous two columns combined).","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/add_tf_idf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare usage across a corpus — add_tf_idf","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_tf_idf() #> # A tibble: 67,945 × 9 #>    doc_id      title     author       part    word      n      tf    idf  tf_idf #>    <fct>       <chr>     <chr>        <chr>   <chr> <int>   <dbl>  <dbl>   <dbl> #>  1 The Sisters Dubliners Joyce, James THE SI… there    15 4.82e-3 0      0       #>  2 The Sisters Dubliners Joyce, James THE SI… was      56 1.80e-2 0      0       #>  3 The Sisters Dubliners Joyce, James THE SI… no       16 5.14e-3 0      0       #>  4 The Sisters Dubliners Joyce, James THE SI… hope      1 3.21e-4 0.511  1.64e-4 #>  5 The Sisters Dubliners Joyce, James THE SI… for      32 1.03e-2 0      0       #>  6 The Sisters Dubliners Joyce, James THE SI… him      43 1.38e-2 0      0       #>  7 The Sisters Dubliners Joyce, James THE SI… this      6 1.93e-3 0.0690 1.33e-4 #>  8 The Sisters Dubliners Joyce, James THE SI… time      3 9.64e-4 0      0       #>  9 The Sisters Dubliners Joyce, James THE SI… it       37 1.19e-2 0      0       #> 10 The Sisters Dubliners Joyce, James THE SI… was      56 1.80e-2 0      0       #> # ℹ 67,935 more rows"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Measure lexical variety — add_vocabulary","title":"Measure lexical variety — add_vocabulary","text":"add_vocabulary() augments tidy text table columns describing lexical variety corpus. Among things, checks uniqueness size vocabulary, additional ratios reporting measurements relation document size.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measure lexical variety — add_vocabulary","text":"","code":"add_vocabulary(df, by = doc_id, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measure lexical variety — add_vocabulary","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" grouping column feature column words containing one word per row","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measure lexical variety — add_vocabulary","text":"data frame 7 added columns , first two logical rest numeric: new_word (logical) Indicates whether first instance given word hapax (logical) Indicates whether word incident given word, hapax legomenon vocabulary (integer) Running count words used ttr (double) Type-token ratio, derived running count words divided total number words used hir (double) Hapax introduction ratio, derived running count hapax legomena divided total number words used. progress_words (integer) Running count total words used far document progress_percent (double) Words used far percentage total number words used document","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measure lexical variety — add_vocabulary","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>    add_vocabulary() |>    head() #> # A tibble: 6 × 12 #>   doc_id      title     author part  word  new_word hapax vocabulary   ttr   hir #>   <fct>       <chr>     <chr>  <chr> <chr> <lgl>    <lgl>      <int> <dbl> <dbl> #> 1 The Sisters Dubliners Joyce… THE … there TRUE     FALSE          1     1 0     #> 2 The Sisters Dubliners Joyce… THE … was   TRUE     FALSE          2     1 0     #> 3 The Sisters Dubliners Joyce… THE … no    TRUE     FALSE          3     1 0     #> 4 The Sisters Dubliners Joyce… THE … hope  TRUE     TRUE           4     1 0.25  #> 5 The Sisters Dubliners Joyce… THE … for   TRUE     FALSE          5     1 0.2   #> 6 The Sisters Dubliners Joyce… THE … him   TRUE     FALSE          6     1 0.167 #> # ℹ 2 more variables: progress_words <int>, progress_percent <dbl>"},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose other colors — change_colors","title":"Choose other colors — change_colors","text":"change_colors() standardizes three methods choosing color palettes color fill mapping, providing access Brewer Viridis palettes alongside custom choices.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose other colors — change_colors","text":"","code":"change_colors(   x,   colorset = \"brewer\",   palette = 2,   kind = \"qualitative\",   direction = 1,   start = 1 )"},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choose other colors — change_colors","text":"x visualization made visualize() colorset Either \"brewer\", \"viridis\", \"okabe-ito\", \"dubois\", vector colors. palette number name palette (dependent setting colorset either \"brewer\" \"viridis\") kind Used Brewer palettes match numbered palette specific subset direction direction colors applied data. Setting anything 1 reverse order. start Useful predefined colorsets Okabe-Ito Brewer start color 1","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choose other colors — change_colors","text":"ggplot2 object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Choose other colors — change_colors","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  # Too many titles for categorical data. selected_titles <- dubliners$doc_id |>   {\\(x) x[grepl(\"^The |^A |^An \", x)]}() |>   unique()  dubliners2 <- dubliners |>   dplyr::filter(doc_id %in% selected_titles)  ### CATEGORICAL DATA ##  # By default, ggplot2's palette is applied dubliners2 |>   visualize()   # change_color() starts with Brewer's \"Dark2\" palette dubliners2 |>   visualize() |>   change_colors()   # Other color sets and palettes can be chosen dubliners2 |>   visualize() |>   change_colors(colorset = \"okabe\")   dubliners2 |>   visualize() |>   change_colors(colorset = \"viridis\", palette = \"turbo\")   dubliners2 |>   visualize() |>   change_colors(colorset = \"brewer\", palette = \"Set1\")   # Named cases can be highlighted dubliners2 |>   visualize(inorder = FALSE) |>   change_colors(c(     rep(\"darkgray\", 6),     \"A Painful Case\" = \"blue\"))   ### SEQUENTIAL DATA ###  # By default, the \"viridis\" palette is applied dubliners2 |>   visualize(type = \"heatmap\")   # change_colors()  starts with Brewer's \"BuGn\" palette dubliners2 |>   visualize(type = \"heatmap\") |>   change_colors() #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.   # Palettes can be numbered or named dubliners2 |>   visualize(type = \"heatmap\") |>   change_colors(\"viridis\", palette = 6) #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.   dubliners2 |>   visualize(type = \"heatmap\") |>   change_colors(\"viridis\", palette = \"mako\") #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.   ### N-GRAMS ### library(ggraph) #> Loading required package: ggplot2  dubliners |>   add_ngrams() |>   visualize() |>   change_colors(c(\"#444488\",\"orange\")) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale."},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse gt rows in the style of kableExtra — collapse_rows","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"Collapse gt rows style kableExtra","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"","code":"collapse_rows(df_g, col, lookleft = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"df_g gt table data object col column collapse lookleft Whether depend collapsing column one step left","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"gt table data object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"","code":"library(gt) library(palmerpenguins) library(tmtyro)  penguins_gt <-   penguins |>   select(-year) |>   summarize(     across(       ends_with(\"_mm\"), mean, na.rm = TRUE),     .by = c(species, island, sex)) |>   gt() |>   fmt_number() |>   tab_spanner(     \"bill\",     columns = starts_with(\"bill_\")) |>   tab_spanner(     \"flipper\",     starts_with(\"flip\")) |>   cols_label(     bill_length_mm = \"length\",     bill_depth_mm = \"depth\",     flipper_length_mm = \"length\") |>   sub_missing()  penguins_gt |>   collapse_rows(species) |>   collapse_rows(island)"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine ngram columns — combine_ngrams","title":"Combine ngram columns — combine_ngrams","text":"Combine ngram columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine ngram columns — combine_ngrams","text":"","code":"combine_ngrams(df, feature = word, keep = FALSE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine ngram columns — combine_ngrams","text":"df tidy data frame, potentially containing columns called \"word_1\", \"word_2\", etc. feature column name prefix numbered columns ngrams keep Whether keep original columns called \"word_1\", \"word_2\", etc., alongside new \"ngram\" column.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine ngram columns — combine_ngrams","text":"data frame column called ngram","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine ngram columns — combine_ngrams","text":"","code":"if (FALSE) { # \\dontrun{   my_corpus <- load_texts(n = 2)    my_bigrams <- my_corpus |>     add_ngrams(collapse = FALSE) |>     combine_ngrams() } # }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_ngrams(2) |>   combine_ngrams() |>   head() #> # A tibble: 6 × 5 #>   doc_id      title     author       part        ngram     #>   <fct>       <chr>     <chr>        <chr>       <chr>     #> 1 The Sisters Dubliners Joyce, James THE SISTERS there was #> 2 The Sisters Dubliners Joyce, James THE SISTERS was no    #> 3 The Sisters Dubliners Joyce, James THE SISTERS no hope   #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope for  #> 5 The Sisters Dubliners Joyce, James THE SISTERS for him   #> 6 The Sisters Dubliners Joyce, James THE SISTERS him this"},{"path":"https://jmclawson.github.io/tmtyro/reference/contextualize.html","id":null,"dir":"Reference","previous_headings":"","what":"Show a term in context — contextualize","title":"Show a term in context — contextualize","text":"Show term context","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/contextualize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show a term in context — contextualize","text":"","code":"contextualize(   df,   term,   window = 3,   limit = 1:5,   by = doc_id,   feature = NULL,   match = word,   regex = NULL )"},{"path":"https://jmclawson.github.io/tmtyro/reference/contextualize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show a term in context — contextualize","text":"df data frame likely contains column called \"word\" term term search , exactly window number terms show limit number results return console using cli, installed document identifier, limiting context window feature column show context. NULL, contextualize() looks first \"original\" column \"word\" column. match column use matching regex defined, regular expression searches using greater control","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/contextualize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show a term in context — contextualize","text":"Invisibly, data frame four columns: <>, <match>, \"index\", \"context\"","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/contextualize.html","id":"hiding-results","dir":"Reference","previous_headings":"","what":"Hiding results","title":"Show a term in context — contextualize","text":"contextualize() uses cli::style_underline() fansi::to_html(), packages installed, show formatted results console document rendered HTML. formatted results can hidden setting limit = 0 function, suppressing messages suppressMessages() console, setting message: false chunk option Quarto R Markdown.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/contextualize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show a term in context — contextualize","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>     load_texts(keep_original = TRUE)  contextualize(dubliners, regex = \"dog[s]?$\") #> on a thick bulldog face and a #> gone to the dogs.” “But Hogan has #> throw to a dog. He stands and #> order. ‘Down, ye dogs! Lie down, ye #> these two fighting dog and devil until"},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":null,"dir":"Reference","previous_headings":"","what":"Count values in one or more columns — count","title":"Count values in one or more columns — count","text":"Count values one columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count values in one or more columns — count","text":"","code":"count(x, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count values in one or more columns — count","text":"x data frame ... columns count. one column chosen, combinations values counted.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count values in one or more columns — count","text":"data frame one column every grouping identified ... additional column number values counted","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count values in one or more columns — count","text":"","code":"mtcars |>   count(cyl) #>   cyl  n #> 1   4 11 #> 2   6  7 #> 3   8 14"},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a file once — download_once","title":"Download a file once — download_once","text":"download_once() checks local copy file found online. copy exist, downloads copy local use.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a file once — download_once","text":"","code":"download_once(url, filename = NULL, destdir = \"data\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a file once — download_once","text":"url URL online document. filename file name saved locally. many cases parameter necessary, since file name can automatically parsed URL, web addresses obscure . destdir destination directory save file. default, \"data/\" folder, created yet exist.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a file once — download_once","text":"Path local file, returned invisibly","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download a file once — download_once","text":"","code":"if (FALSE) { # \\dontrun{ download_once(\"example.com/sample.csv\") } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop rows containing missing values — drop_na","title":"Drop rows containing missing values — drop_na","text":"drop_na() drops rows column specified ... contains missing value.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop rows containing missing values — drop_na","text":"","code":"drop_na(data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop rows containing missing values — drop_na","text":"data data frame. ... <tidy-select> Columns inspect missing values. empty, columns used.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drop rows containing missing values — drop_na","text":"Another way interpret drop_na() keeps \"complete\" rows (rows contain missing values). Internally, completeness computed vctrs::vec_detect_complete().","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drop rows containing missing values — drop_na","text":"","code":"data.frame(   A = 1:3,   B = c(\"red\", NA, \"green\"),   C = c(TRUE, TRUE, TRUE)) |> drop_na() #>   A     B    C #> 1 1   red TRUE #> 2 3 green TRUE"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove stopwords — drop_stopwords","title":"Remove stopwords — drop_stopwords","text":"Remove stopwords","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove stopwords — drop_stopwords","text":"","code":"drop_stopwords(df, wordlist = NULL, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove stopwords — drop_stopwords","text":"df tidy data frame, potentially containing column called \"word\" wordlist list stopwords feature column words containing one word per row checked stopwords.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove stopwords — drop_stopwords","text":"original data frame fewer rows.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove stopwords — drop_stopwords","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>    drop_stopwords() #> # A tibble: 34,242 × 5 #>    doc_id      title     author       part        word     #>    <fct>       <chr>     <chr>        <chr>       <chr>    #>  1 The Sisters Dubliners Joyce, James THE SISTERS hope     #>  2 The Sisters Dubliners Joyce, James THE SISTERS time     #>  3 The Sisters Dubliners Joyce, James THE SISTERS third    #>  4 The Sisters Dubliners Joyce, James THE SISTERS stroke   #>  5 The Sisters Dubliners Joyce, James THE SISTERS night    #>  6 The Sisters Dubliners Joyce, James THE SISTERS night    #>  7 The Sisters Dubliners Joyce, James THE SISTERS passed   #>  8 The Sisters Dubliners Joyce, James THE SISTERS house    #>  9 The Sisters Dubliners Joyce, James THE SISTERS vacation #> 10 The Sisters Dubliners Joyce, James THE SISTERS time     #> # ℹ 34,232 more rows"},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame from long tidy format to wider format — expand_documents","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"resulting data frame simpler form document feature matrix used packages. my_df |> expand_documents(percent = FALSE, sort = FALSE) compares my_df |> count(doc_id, word) |> tidytext::cast_dfm(doc_id, word, n), equivalent. latter prepares DFM used quanteda package.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"","code":"expand_documents(   df,   feature = word,   by = doc_id,   percent = TRUE,   sort = TRUE,   columns = NULL )"},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"df tidy data frame, potentially containing column called \"word\" feature column words containing one word per row, counted frequency column containing document grouping percent Whether frequencies converted percentages per-document basis sort Whether sort features frequency columns features keep","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"data frame one row per document many features words.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   expand_documents() #> # A tibble: 15 × 7,340 #>    doc_id         the    and     of     to      he      a     was     his   `in` #>    <fct>        <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 The Sisters 0.0549 0.0379 0.0222 0.0302 0.0180  0.0148 0.0180  0.0157  0.0173 #>  2 An Encount… 0.0556 0.0329 0.0273 0.0264 0.0310  0.0218 0.0181  0.0107  0.0129 #>  3 Araby       0.0810 0.0299 0.0273 0.0299 0.00682 0.0209 0.0171  0.00341 0.0175 #>  4 Eveline     0.0563 0.0251 0.0257 0.0371 0.0246  0.0218 0.0218  0.00601 0.0180 #>  5 After the … 0.0728 0.0299 0.0446 0.025  0.0196  0.0299 0.0268  0.0183  0.0214 #>  6 Two Gallan… 0.0548 0.0332 0.0334 0.0240 0.0416  0.0288 0.0143  0.0286  0.0120 #>  7 The Boardi… 0.0493 0.0316 0.0312 0.0312 0.0241  0.0273 0.0213  0.0174  0.0135 #>  8 A Little C… 0.0502 0.0356 0.0263 0.0247 0.0346  0.0206 0.0136  0.0261  0.0146 #>  9 Counterpar… 0.0761 0.0328 0.0275 0.0265 0.0335  0.0228 0.0187  0.0236  0.0163 #> 10 Clay        0.0594 0.0530 0.0229 0.0301 0.00978 0.0203 0.0259  0.00414 0.0117 #> 11 A Painful … 0.0665 0.0266 0.0352 0.0275 0.0398  0.0255 0.0137  0.0250  0.0190 #> 12 Ivy Day in… 0.0610 0.0242 0.0233 0.0212 0.0259  0.0274 0.00762 0.0160  0.0128 #> 13 A Mother    0.0619 0.0348 0.0227 0.0304 0.0170  0.0211 0.0227  0.0108  0.0152 #> 14 Grace       0.0643 0.0269 0.0299 0.0224 0.0235  0.0260 0.0178  0.0190  0.0150 #> 15 The Dead    0.0551 0.0362 0.0252 0.0234 0.0180  0.0216 0.0159  0.0160  0.0168 #> # ℹ 7,330 more variables: her <dbl>, had <dbl>, said <dbl>, that <dbl>, #> #   it <dbl>, with <dbl>, `for` <dbl>, him <dbl>, at <dbl>, on <dbl>, i <dbl>, #> #   she <dbl>, but <dbl>, as <dbl>, were <dbl>, when <dbl>, all <dbl>, #> #   you <dbl>, they <dbl>, not <dbl>, out <dbl>, up <dbl>, be <dbl>, by <dbl>, #> #   one <dbl>, from <dbl>, an <dbl>, would <dbl>, then <dbl>, little <dbl>, #> #   what <dbl>, no <dbl>, have <dbl>, there <dbl>, them <dbl>, which <dbl>, #> #   so <dbl>, could <dbl>, `if` <dbl>, into <dbl>, went <dbl>, asked <dbl>, …"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a corpus or corpora of texts — get_corpus","title":"Prepare a corpus or corpora of texts — get_corpus","text":"get_corpus() works nearly identically load_texts(), two fundamental differences. First, adds \"corpus\" column resulting table help record keeping. Second, adds option caching output local RDS file, saved project directory.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a corpus or corpora of texts — get_corpus","text":"","code":"get_corpus(   corpus,   name = \".txt\",   word = TRUE,   lemma = FALSE,   lemma_replace = FALSE,   to_lower = TRUE,   remove_names = FALSE,   pos = FALSE,   poetry = FALSE,   paragraph = TRUE,   cache = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a corpus or corpora of texts — get_corpus","text":"corpus Vector length, value either string identifying directory texts first part filename cached RDS file prepared tmtyro. name naming pattern search folder. Defaults \".txt\". word Whether split one word per line. Defaults TRUE. lemma Whether lemmatize text. word TRUE, adds new column called lemma. step can add lot time, defaults FALSE. lemma_replace lemma word TRUE, toggles whether replace word column lemmatized tokens. Defaults FALSE to_lower word TRUE, toggles whether convert words lowercase. Defaults TRUE. remove_names word TRUE, toggles whether remove words appear form initial capitals. Defaults FALSE. pos Whether add column part--speech tag. step can add lot time, defaults FALSE. poetry Whether detect indicate stanza breaks line breaks. Defaults FALSE. paragraph Whether detect paragraph breaks prose. Defaults TRUE. cache Whether save cached copy corpus. options like pos = TRUE lemma = TRUE can add significant time corpus preparation, setting cache = TRUE saves need repeat steps time corpus loaded. Defaults TRUE.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare a corpus or corpora of texts — get_corpus","text":"data frame columns corpus, doc_id, data.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare a corpus or corpora of texts — get_corpus","text":"","code":"if (FALSE) { # \\dontrun{   austen <- get_corpus(\"austen\")    shakespeare <- get_corpus(     c(\"comedy\",       \"history\",       \"tragedy\")) } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_cumulative_vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative total of vocabulary size — get_cumulative_vocabulary","title":"Cumulative total of vocabulary size — get_cumulative_vocabulary","text":"Cumulative total vocabulary size","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_cumulative_vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative total of vocabulary size — get_cumulative_vocabulary","text":"","code":"get_cumulative_vocabulary(x)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_cumulative_vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative total of vocabulary size — get_cumulative_vocabulary","text":"x vector, column character strings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_cumulative_vocabulary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative total of vocabulary size — get_cumulative_vocabulary","text":"vector counts","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_cumulative_vocabulary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative total of vocabulary size — get_cumulative_vocabulary","text":"","code":"c(\"cat\", \"dog\", \"dog\", \"bat\", \"dog\") |>   get_cumulative_vocabulary() #> [1] 1 2 2 3 3"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_frequency.html","id":null,"dir":"Reference","previous_headings":"","what":"Get get_frequencies of values in a vector — get_frequency","title":"Get get_frequencies of values in a vector — get_frequency","text":"Get get_frequencies values vector","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_frequency.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get get_frequencies of values in a vector — get_frequency","text":"","code":"get_frequency(x, percent = FALSE)  get_tf(x, percent = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_frequency.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get get_frequencies of values in a vector — get_frequency","text":"x vector, column character strings percent Whether return frequencies percentage whole","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_frequency.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get get_frequencies of values in a vector — get_frequency","text":"vector counts ratios value x.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_frequency.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get get_frequencies of values in a vector — get_frequency","text":"","code":"my_values <- c(\"dog\", \"cat\", \"dog\")  get_frequency(my_values) #> [1] 2 1 2"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"get_gutenberg_corpus() improves upon functionality gutenbergr::gutenberg_download() three key ways. Retrieving \".htm\" version texts instead \".zip\" version typically used gutenberger dramatically improves file coverage. Parsing HTML headers allows texts studied sections chapters. Parsing handled parse_html(), move_header_to_text() available corrections. Caching files locally avoids repeated downloads, thereby improving code portability, allowing offline access, reducing network use. changes made consideration server bandwidth, two-second delay introduced download attempt. slow initial acquisition corpora, offline caching speeds things considerably subsequent use.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"","code":"get_gutenberg_corpus(   gutenberg_id,   dir = \"gutenberg\",   meta_fields = c(\"gutenberg_id\", \"title\", \"author\"),   html_title = FALSE,   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"gutenberg_id vector ID numbers Project Gutenberg data frame containing gutenberg_id column, results call gutenbergr::gutenberg_works(). dir directory storing downloaded .txt files. Default value \"gutenberg\". meta_fields Additional fields add gutenbergr::gutenberg_metadata describing book. default, title author added. html_title Whether use h1 header HTML file determine document's title. default, uses gutenbergr::gutenberg_metadata. ... Additional parameters passed along gutenbergr::gutenberg_strip().","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"data frame one row line texts corpus.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"","code":"library(gutenbergr)  dalloway <- gutenberg_works(author == \"Woolf, Virginia\",                             title == \"Mrs Dalloway in Bond Street\") |>   get_gutenberg_corpus()"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_hir.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative hapax introduction ratio — get_hir","title":"Cumulative hapax introduction ratio — get_hir","text":"Hapax introduction ratio tracks use unique words text grows.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_hir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative hapax introduction ratio — get_hir","text":"","code":"get_hir(x)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_hir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative hapax introduction ratio — get_hir","text":"x vector, column character strings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_hir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative hapax introduction ratio — get_hir","text":"vector ratios","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_hir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative hapax introduction ratio — get_hir","text":"","code":"c(\"cat\", \"dog\", \"dog\", \"bat\", \"dog\") |>   get_hir() #> [1] 1.0000000 0.5000000 0.3333333 0.5000000 0.4000000"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_htr.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative hapax-token ratio — get_htr","title":"Cumulative hapax-token ratio — get_htr","text":"HTR reports cumulative ratio hapax legomena (one-words) cumulative size text. operation can slow.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_htr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative hapax-token ratio — get_htr","text":"","code":"get_htr(x)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_htr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative hapax-token ratio — get_htr","text":"x vector, column character strings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_htr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative hapax-token ratio — get_htr","text":"vector ratios","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_htr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative hapax-token ratio — get_htr","text":"","code":"c(\"cat\", \"dog\", \"dog\", \"bat\", \"dog\") |>   get_htr() #> [1] 1.0000000 1.0000000 0.3333333 0.5000000 0.4000000"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_idf_by.html","id":null,"dir":"Reference","previous_headings":"","what":"Get inverse document frequencies of values in one vector x categorized by another vector by. — get_idf_by","title":"Get inverse document frequencies of values in one vector x categorized by another vector by. — get_idf_by","text":"Get inverse document frequencies values one vector x categorized another vector .","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_idf_by.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get inverse document frequencies of values in one vector x categorized by another vector by. — get_idf_by","text":"","code":"get_idf_by(x, by)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_idf_by.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get inverse document frequencies of values in one vector x categorized by another vector by. — get_idf_by","text":"x vector, column character strings vector categories, column document identifiers","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_idf_by.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get inverse document frequencies of values in one vector x categorized by another vector by. — get_idf_by","text":"vector inverse document frequencies value pair x .","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_idf_by.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get inverse document frequencies of values in one vector x categorized by another vector by. — get_idf_by","text":"","code":"my_values <- c(   \"the\", \"cat\", \"was\", \"bad\",   \"the\", \"dog\", \"was\", \"very\", \"good\",   \"the\", \"lizard\", \"is\", \"the\", \"most\", \"bad\") my_docs <- c(   \"A\", \"A\", \"A\", \"A\",   \"B\", \"B\", \"B\", \"B\", \"B\",   \"C\", \"C\", \"C\", \"C\", \"C\", \"C\")  get_idf_by(my_values, my_docs) #>  [1] 0.0000000 1.0986123 0.4054651 0.4054651 0.0000000 1.0986123 0.4054651 #>  [8] 1.0986123 1.0986123 0.0000000 1.0986123 1.0986123 0.0000000 1.0986123 #> [15] 0.4054651"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dictionary matches of values in a vector — get_match","title":"Get dictionary matches of values in a vector — get_match","text":"Get dictionary matches values vector","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dictionary matches of values in a vector — get_match","text":"","code":"get_match(x, dictionary, keep = NULL)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dictionary matches of values in a vector — get_match","text":"x vector, column character strings dictionary data frame two columns, potentially made make_dictionary(). keep number matched values keep. NULL, returns matched values nested list.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dictionary matches of values in a vector — get_match","text":"vector nested list sentiments value x.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dictionary matches of values in a vector — get_match","text":"","code":"my_values <- c(\"It\", \"is\", \"raining\")  emoji_weather <- make_dictionary(   list(     \"️☔️\" = c(\"rain\", \"rains\", \"rainy\", \"raining\"),     \"️⛈️\" = c(\"storm\", \"storms\", \"stormy\", \"storming\"),     \"☁️\" = c(\"cloud\", \"clouds\", \"cloudy\"),     \"🌞\" = c(\"sun\", \"sunny\"),     \"🌫️\" = c(\"fog\", \"fogs\", \"foggy\", \"mist\", \"misty\"),     \"🌬️\" = c(\"wind\", \"winds\", \"windy\"),     \"️❄️\" = c(\"snow\", \"snows\", \"snowing\")),   name = \"weather\")  get_match(my_values, emoji_weather) #> [1] NA   NA   \"️☔️\""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a MICUSP corpus — get_micusp_corpus","title":"Get a MICUSP corpus — get_micusp_corpus","text":"function accepts filters columns micusp_metadata() downloads parses MICUSP (Michigan Corpus Upper-level Student Papers) texts locally copies yet exist. returns table combining metadata text data processing.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a MICUSP corpus — get_micusp_corpus","text":"","code":"get_micusp_corpus(...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a MICUSP corpus — get_micusp_corpus","text":"... filter rows columns micusp_metadata(). Accepted columns include following: paper_id, title, discipline, paper_type, student_level, sex, nativeness, textual_features.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a MICUSP corpus — get_micusp_corpus","text":"data frame 1 row document corpus 9 columns. first 8 columns contain metadata, final column called text contains full text document.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a MICUSP corpus — get_micusp_corpus","text":"","code":"if (FALSE) { # \\dontrun{ physics_f <- get_micusp_corpus(discipline == \"Physics\", sex == \"Female\") physics_m <- get_micusp_corpus(discipline == \"Physics\", sex == \"Male\")  discipline_by_sex <-   micusp_metadata() |>   count(discipline, sex) |>   tidyr::pivot_wider(     names_from = \"sex\",     values_from = \"n\") |>   dplyr::mutate(     ratio_f = (Female) / (Male + Female)) |>     dplyr::arrange(ratio_f)   disciplines_low_f <-   discipline_by_sex |>   head(3) |>   dplyr::pull(discipline)   disciplines_low_m <-   discipline_by_sex |>   tail(3) |>   dplyr::pull(discipline)  low_representation_f <- get_micusp_corpus(   sex == \"Female\",   discipline %in% disciplines_low_f)   low_representation_m <- get_micusp_corpus(   sex == \"Male\",   discipline %in% disciplines_low_m) } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Get sentiment matches of values in a vector — get_sentiment","title":"Get sentiment matches of values in a vector — get_sentiment","text":"Get sentiment matches values vector","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get sentiment matches of values in a vector — get_sentiment","text":"","code":"get_sentiment(   x,   lexicon = c(\"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\"),   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get sentiment matches of values in a vector — get_sentiment","text":"x vector, column character strings lexicon sentiment lexicon use tidytext package. Options include \"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\". ... Additional values passed get_match()","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get sentiment matches of values in a vector — get_sentiment","text":"vector nested list sentiments value x.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_sentiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get sentiment matches of values in a vector — get_sentiment","text":"","code":"my_values <- c(\"I\", \"am\", \"happy\")  get_sentiment(my_values) #> [1] NA         NA         \"positive\""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tf_by.html","id":null,"dir":"Reference","previous_headings":"","what":"Get term frequencies of values in one vector x categorized by another vector by. — get_tf_by","title":"Get term frequencies of values in one vector x categorized by another vector by. — get_tf_by","text":"Get term frequencies values one vector x categorized another vector .","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tf_by.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get term frequencies of values in one vector x categorized by another vector by. — get_tf_by","text":"","code":"get_tf_by(x, by)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tf_by.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get term frequencies of values in one vector x categorized by another vector by. — get_tf_by","text":"x vector, column character strings vector categories, column document identifiers","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tf_by.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get term frequencies of values in one vector x categorized by another vector by. — get_tf_by","text":"vector term frequencies value pair x .","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tf_by.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get term frequencies of values in one vector x categorized by another vector by. — get_tf_by","text":"","code":"my_values <- c(   \"the\", \"cat\", \"was\", \"bad\",   \"the\", \"dog\", \"was\", \"very\", \"good\",   \"the\", \"lizard\", \"is\", \"the\", \"most\", \"bad\") my_docs <- c(   \"A\", \"A\", \"A\", \"A\",   \"B\", \"B\", \"B\", \"B\", \"B\",   \"C\", \"C\", \"C\", \"C\", \"C\", \"C\")  get_tf_by(my_values, my_docs) #>  [1] 0.2500000 0.2500000 0.2500000 0.2500000 0.2000000 0.2000000 0.2000000 #>  [8] 0.2000000 0.2000000 0.3333333 0.1666667 0.1666667 0.3333333 0.1666667 #> [15] 0.1666667"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tfidf_by.html","id":null,"dir":"Reference","previous_headings":"","what":"Term frequency–inverse document frequency — get_tfidf_by","title":"Term frequency–inverse document frequency — get_tfidf_by","text":"Get tf-idf weights values one vector x categorized another vector .","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tfidf_by.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Term frequency–inverse document frequency — get_tfidf_by","text":"","code":"get_tfidf_by(x, by)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tfidf_by.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Term frequency–inverse document frequency — get_tfidf_by","text":"x vector, column character strings vector categories, column document identifiers","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tfidf_by.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Term frequency–inverse document frequency — get_tfidf_by","text":"vector term frequency–inverse document frequencies value pair x .","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_tfidf_by.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Term frequency–inverse document frequency — get_tfidf_by","text":"","code":"my_values <- c(   \"the\", \"cat\", \"was\", \"bad\",   \"the\", \"dog\", \"was\", \"very\", \"good\",   \"the\", \"lizard\", \"is\", \"the\", \"most\", \"bad\") my_docs <- c(   \"A\", \"A\", \"A\", \"A\",   \"B\", \"B\", \"B\", \"B\", \"B\",   \"C\", \"C\", \"C\", \"C\", \"C\", \"C\")  get_tfidf_by(my_values, my_docs) #>  [1] 0.00000000 0.27465307 0.10136628 0.10136628 0.00000000 0.21972246 #>  [7] 0.08109302 0.21972246 0.21972246 0.00000000 0.18310205 0.18310205 #> [13] 0.00000000 0.18310205 0.06757752"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_ttr.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative type-token ratio — get_ttr","title":"Cumulative type-token ratio — get_ttr","text":"TTR reports ratio unique word types total size text.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_ttr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative type-token ratio — get_ttr","text":"","code":"get_ttr(x)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_ttr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative type-token ratio — get_ttr","text":"x vector, column character strings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_ttr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative type-token ratio — get_ttr","text":"vector ratios","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/get_ttr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative type-token ratio — get_ttr","text":"","code":"c(\"cat\", \"dog\", \"dog\", \"bat\", \"dog\") |>   get_ttr() #> [1] 1.0000000 1.0000000 0.6666667 0.7500000 0.6000000"},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose a new doc_id column — identify_by","title":"Choose a new doc_id column — identify_by","text":"Choose new doc_id column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose a new doc_id column — identify_by","text":"","code":"identify_by(data, ..., inorder = TRUE, sep = \"_\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choose a new doc_id column — identify_by","text":"data data frame, potentially doc_id column ... column columns become new identifier inorder Whether establish doc_id order shown document sep Separator values identifying multiple columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choose a new doc_id column — identify_by","text":"data frame redefined doc_id column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Choose a new doc_id column — identify_by","text":"","code":"if (FALSE) {   corpus |>     load_texts() |>     identify_by(author) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore topics interactively — interactive_topic_distributions","title":"Explore topics interactively — interactive_topic_distributions","text":"interactive_topic_distributions() uses plotly prepare interactive visualization explore topic model, showing top \"n\" topics document. kind visualization use interactive IDE web page.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore topics interactively — interactive_topic_distributions","text":"","code":"interactive_topic_distributions(   lda,   top_n = 4,   title = FALSE,   height = NULL,   omit = NULL,   smooth = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore topics interactively — interactive_topic_distributions","text":"lda topic model used. top_n number topics visualize. default, top 4 topics document shown. title default, function add title chart, corresponding name object passed lda parameter. Set FALSE return chart title. height height resulting HTML widget. omit Upon exploration, topics may found contain common stop words unhelpful material. Use omit parameter define vector topic numbers wish omit visualization. smooth samples rejoined, measured value topic vary wildly, even samples beside document. can make charts distractingly jittery. default TRUE value parameter reduces chart noise calculating rolling averages across three samples. Set parameter FALSE skip step allow visualization extreme values.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore topics interactively — interactive_topic_distributions","text":"Interactive plotly object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explore topics interactively — interactive_topic_distributions","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  interactive_topic_distributions(austen_lda)"},{"path":"https://jmclawson.github.io/tmtyro/reference/is_hapax.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for hapax legomena — is_hapax","title":"Check for hapax legomena — is_hapax","text":"Check hapax legomena","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/is_hapax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for hapax legomena — is_hapax","text":"","code":"is_hapax(x)"},{"path":"https://jmclawson.github.io/tmtyro/reference/is_hapax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for hapax legomena — is_hapax","text":"x vector, column character strings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/is_hapax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for hapax legomena — is_hapax","text":"logical vector","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/is_hapax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for hapax legomena — is_hapax","text":"","code":"c(\"cat\", \"dog\", \"dog\", \"bat\", \"dog\") |>   is_hapax() #> [1]  TRUE FALSE FALSE  TRUE FALSE"},{"path":"https://jmclawson.github.io/tmtyro/reference/is_new.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for new words in a vocabulary — is_new","title":"Check for new words in a vocabulary — is_new","text":"Check new words vocabulary","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/is_new.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for new words in a vocabulary — is_new","text":"","code":"is_new(x)"},{"path":"https://jmclawson.github.io/tmtyro/reference/is_new.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for new words in a vocabulary — is_new","text":"x vector, column character strings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/is_new.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for new words in a vocabulary — is_new","text":"logical vector","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/is_new.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for new words in a vocabulary — is_new","text":"","code":"c(\"cat\", \"dog\", \"dog\", \"bat\", \"dog\") |>   is_new() #> [1]  TRUE  TRUE FALSE  TRUE FALSE"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a folder or data frame of texts — load_texts","title":"Load a folder or data frame of texts — load_texts","text":"load_texts() loads corpus folder texts data frame prepares study using tidytext principles. default, load_texts() add paragraph numbers (suitable prose), unnest word level, options exist change defaults poetry, avoid unnesting, even remove words seem like proper nouns apply techniques natural language processing lemmatizing words tagging parts speech.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a folder or data frame of texts — load_texts","text":"","code":"load_texts(   src = \"data\",   name = \".txt\",   word = TRUE,   lemma = FALSE,   lemma_replace = FALSE,   to_lower = TRUE,   remove_names = FALSE,   pos = FALSE,   keep_original = FALSE,   poetry = FALSE,   paragraph = TRUE,   n = 1L,   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a folder or data frame of texts — load_texts","text":"src Either string identifying name directory containing texts data frame containing unnested column called \"text\" one column name ending \"_id\". Files either stored directory within project folder subdirectory called \"data\". Defaults \"data\" load texts directory. name naming pattern search folder. Defaults \".txt\". word Whether split one word per line. Defaults TRUE. lemma Whether lemmatize text. word TRUE, adds new column called lemma. step can add lot time, defaults FALSE. lemma_replace lemma word TRUE, toggles whether replace word column lemmatized tokens. Defaults FALSE to_lower word TRUE, toggles whether convert words lowercase. Defaults TRUE. remove_names word TRUE, toggles whether remove words appear form initial capitals. Defaults FALSE. pos Whether add column part--speech tag. step can add lot time, defaults FALSE. keep_original Whether try retain original punctuation capitalization parallel column. always work, defaults FALSE. poetry Whether detect indicate stanza breaks line breaks. Defaults FALSE. paragraph Whether detect paragraph breaks prose. Defaults TRUE. n number words per row. default, load_texts() unnests text one word time using column called word. n value greater 1, load_texts() instead use tidytext::unnest_tokens() token = \"ngrams\" create column called ngram. ... Additional arguments passed along tidytext::unnest_tokens() use tokenizers","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a folder or data frame of texts — load_texts","text":"data frame two five columns one row token (optionally, one row paragraph one row line) corpus.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a folder or data frame of texts — load_texts","text":"","code":"if (FALSE) { # \\dontrun{ mysteries <-   load_texts(\"mystery-novels\")  dickinson <-   load_texts(\"dickinson-poems\",              poetry = TRUE)  # `load_texts()` can also be used with # a traditional tidytext workflow: mysteries <-   load_texts(\"mystery-novels\",              word = FALSE,              to_lower = FALSE) |>   tidytext::unnest_tokens(word, text) } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Load (or cache and load) a topic model — load_topic_model","title":"Load (or cache and load) a topic model — load_topic_model","text":"load_topic_model() checks see whether cached topic model exists creating one make_topic_model() caching .","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load (or cache and load) a topic model — load_topic_model","text":"","code":"load_topic_model(df, k = 15, by = doc_id, sample_size = 1000, lda_name = NULL)"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load (or cache and load) a topic model — load_topic_model","text":"df data frame nested text \"text\" column. k number topics search . default, 15 topics sought. column identifying document. default, \"title\" column used. sample_size sample size document chunk. default, samples include 1000 words. lda_name name use looking caching model \"data\" folder. default, value derived name data frame passed function, may helpful define explicitly intervening steps loading topic model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load (or cache and load) a topic model — load_topic_model","text":"topic model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load (or cache and load) a topic model — load_topic_model","text":"","code":"if (FALSE) { # \\dontrun{ mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   load_topic_model(k = 10)   } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a lexicon — make_dictionary","title":"Create a lexicon — make_dictionary","text":"make_dictionary() creates dictionary use add_dictionary().","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a lexicon — make_dictionary","text":"","code":"make_dictionary(definitions, name = NULL)"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a lexicon — make_dictionary","text":"definitions list named word vectors name kind dictionary","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a lexicon — make_dictionary","text":"data frame two columns, \"word\" ","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a lexicon — make_dictionary","text":"","code":"emoji_weather <- make_dictionary(   list(     \"️☔️\" = c(\"rain\", \"rains\", \"rainy\", \"raining\"),     \"️⛈️\" = c(\"storm\", \"storms\", \"stormy\", \"storming\"),     \"☁️\" = c(\"cloud\", \"clouds\", \"cloudy\"),     \"🌞\" = c(\"sun\", \"sunny\"),     \"🌫️\" = c(\"fog\", \"fogs\", \"foggy\", \"mist\", \"misty\"),     \"🌬️\" = c(\"wind\", \"winds\", \"windy\"),     \"️❄️\" = c(\"snow\", \"snows\", \"snowing\")),   name = \"weather\")  border_states <- make_dictionary(   definitions = list(     \"Canada\" = c(       \"Alaska\", \"Washington\", \"Idaho\",       \"Montana\", \"North_Dakota\", \"Minnesota\",       \"Wisconsin\", \"Michigan\", \"Ohio\",       \"Pennsylvania\", \"New_York\", \"Vermont\",       \"New_Hampshire\", \"Maine\", \"AK\", \"WA\",       \"ID\", \"MT\", \"ND\", \"MN\", \"WI\", \"MI\",       \"OH\", \"PA\", \"NY\", \"VT\", \"NH\", \"ME\"),     \"Mexico\" = c(       \"California\", \"Arizona\", \"New_Mexico\",       \"Texas\", \"CA\", \"AZ\", \"NM\", \"TX\")),   name = \"borders\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a topic model — make_topic_model","title":"Construct a topic model — make_topic_model","text":"make_topic_model() moves table texts necessary steps preparation building topic model. function applies seven steps: identifies text divisions doc_id column divides texts -sized chunks sample_size words (default 1000 words) unnests text table table one word per row removes stop words proper nouns (identified word appears capitalized first letter) counts word frequencies chunk converts table frequencies document term matrix builds topic model k topics","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a topic model — make_topic_model","text":"","code":"make_topic_model(df, by = doc_id, sample_size = 1000, k = 15, cache = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a topic model — make_topic_model","text":"df data frame nested text \"text\" column. column identifying document. default, \"title\" column used. sample_size sample size document chunk. default, samples include 1000 words. k number topics search . default, 15 topics sought. cache Whether cache resulting model RDS file \"data/\" folder. Set TRUE default. Delete RDS file create new model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a topic model — make_topic_model","text":"topic model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a topic model — make_topic_model","text":"","code":"if (FALSE) { # \\dontrun{ mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   make_topic_model(k = 10)   } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Get MICUSP metadata — micusp_metadata","title":"Get MICUSP metadata — micusp_metadata","text":"Explore metadata available MICUSP (Michigan Corpus Upper-level Student Papers) texts choose corpus. first use, function creates folder working directory downloads \"micusp_metadata.csv\" file opening . Subsequent use function load local copy.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get MICUSP metadata — micusp_metadata","text":"","code":"micusp_metadata(micusp_dir = \"micusp\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get MICUSP metadata — micusp_metadata","text":"micusp_dir name directory storing local copies MICUSP materials. Defaults \"micusp/\".","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get MICUSP metadata — micusp_metadata","text":"data frame 1 row document corpus 8 columns metadata: paper_id, title, discipline, paper_type, student_level, sex, nativeness, textual_features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get MICUSP metadata — micusp_metadata","text":"","code":"if (FALSE) { # \\dontrun{ micusp_metadata() |> head() } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Move a header column to text — move_header_to_text","title":"Move a header column to text — move_header_to_text","text":"texts, header tags particular level indicate typographical variance confused section tags. move_header_to_text() provides simple method adjust table.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move a header column to text — move_header_to_text","text":"","code":"move_header_to_text(.data, column, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move a header column to text — move_header_to_text","text":".data data frame column called text least one column indicating parts, chapters, sections. column header column move ... (optional) Filtering condition, title == \"Ulysses\".","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Move a header column to text — move_header_to_text","text":"data frame header column moved text, conditional ...","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Move a header column to text — move_header_to_text","text":"","code":"if (FALSE) {   joyce2 <- joyce |>     move_column_to_text(subsection, title == \"Ulysses\") }"},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":null,"dir":"Reference","previous_headings":"","what":"Read HTML headers and text from file — parse_html","title":"Read HTML headers and text from file — parse_html","text":"Read HTML headers text file","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read HTML headers and text from file — parse_html","text":"","code":"parse_html(html, title = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read HTML headers and text from file — parse_html","text":"html file HTML format title Whether keep H1 tags even one unique value","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read HTML headers and text from file — parse_html","text":"data frame column called text header columns called title, part, section, subsection needed. Header columns limited page elements tagged h1, h2, h3, h4.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read HTML headers and text from file — parse_html","text":"","code":"if (FALSE) {   library(dplyr)   library(stringr)   library(tmtyro)    orlando <-     \"http://gutenberg.net.au/ebooks02/0200331h.html\" |>     download_once() |>     parse_html() |>     filter(str_detect(part, \"CHAPTER\")) |>     mutate(       chapter = str_extract(part, \"\\\\d\"),       author = \"Virginia Woolf\") |>     select(author, title, chapter, text) |>     drop_na(chapter) |>     identify_by(title, chapter) |>     load_texts() }"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize bigram chains — plot_bigrams","title":"Visualize bigram chains — plot_bigrams","text":"Visualize bigram chains","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize bigram chains — plot_bigrams","text":"","code":"plot_bigrams(   df,   feature = word,   random_seed = TRUE,   set_seed = NULL,   legend = FALSE,   top_n = 35 )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize bigram chains — plot_bigrams","text":"df tidy data frame potentially containing column called \"word\" columns called \"word_1\" \"word_2\". feature feature use constructing ngrams random_seed Whether randomize creation network chart. set_seed specific seed use random legend Whether show legend edge color top_n number pairs visualize","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize bigram chains — plot_bigrams","text":"ggplot2 object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize bigram chains — plot_bigrams","text":"","code":"if (FALSE) { # \\dontrun{ # It isn't necessary to use add_ngrams() df |>   plot_bigrams()  # Adding them first allows for filtering steps df |>   add_ngrams() |>   drop_stopwords(word_1) |>   drop_stopwords(word_2) |>   plot_bigrams()  # Only bigrams influence the visualization These show the same networks: df |>   add_ngrams() |>   plot_bigrams()  df |>   add_ngrams(4) |>   plot_bigrams()  } # }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   plot_bigrams()   # Loading `ggraph` enables edge to show connection strengths library(ggraph)  dubliners |>   plot_bigrams()   dubliners |>   add_ngrams(2) |>   drop_stopwords(feature = word_1) |>   drop_stopwords(feature = word_2) |>   plot_bigrams()   dubliners |>   dplyr::filter(doc_id == \"The Dead\") |>   plot_bigrams(top_n = 70) |>   change_colors(c(\"black\", \"orange\")) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale."},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bar graphs of frequent features — plot_doc_word_bars","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"Plot bar graphs frequent features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"","code":"plot_doc_word_bars(   df,   rows = 1:10,   by = doc_id,   feature = word,   inorder = TRUE,   reorder_y = NULL,   color_y = FALSE,   percents = TRUE,   label = NULL,   label_tweak = 2,   label_inside = FALSE,   label_color = NULL,   na_rm = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" rows features show column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" inorder Whether retain factor order \"\" column reorder_y Whether reorder Y-values facet color_y Whether bars filled Y-values percents Whether display word frequencies percentage instead raw counts label Whether show value label bar label_tweak numeric value tweak label, shown. percentages, value adjusts decimal-point precision. raw counts, value adjusts labels' offset bars label_inside Whether show value label inside bar label_color color use label text. value chosen, labels black label_inside FALSE white TRUE. na_rm Whether drop empty features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts(lemma = TRUE) |>   identify_by(part) |>   standardize_titles()  dubliners |>   plot_doc_word_bars(rows = 1:4)   dubliners |>   dplyr::filter(doc_id %in% c(\"The Sisters\", \"The Dead\")) |>   plot_doc_word_bars(feature = lemma, rows = 1:20)"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a heatmap of ranked features — plot_doc_word_heatmap","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"Plot heatmap ranked features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"","code":"plot_doc_word_heatmap(   df,   rows = 1:10,   by = doc_id,   feature = word,   label = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" rows ranks show, counting ties column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" label Whether show rank label heatmap","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts(lemma = TRUE) |>   identify_by(part) |>   standardize_titles()  # Make a smaller example selected_titles <-   c(\"The Sisters\", \"An Encounter\", \"Araby\",     \"Counterparts\", \"The Dead\")  dubliners |>   dplyr::filter(doc_id %in% selected_titles) |>   plot_doc_word_heatmap()   dubliners |>   dplyr::filter(doc_id %in% selected_titles) |>   plot_doc_word_heatmap(feature = lemma, rows = 1:6)"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":null,"dir":"Reference","previous_headings":"","what":"Project hapax legomena onto vocabulary growth — plot_hapax","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"plot_hapax() visualizes sampling hapax legomena projected faceted curves vocabulary growth time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"","code":"plot_hapax(   df,   prop = 0.01,   x = progress_words,   y = vocabulary,   by = doc_id,   descriptive_labels = TRUE,   feature = hapax )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" prop proportion hapax sample. chart can become illegible proportions ~1% x progress column show. Default option progress_percent, progress_words also appropriate. y Y-axis variable chart. Default value cumulative vocabulary size. grouping column, doc_id descriptive_labels toggle disabling descriptive labels progress_percent X-axis feature column check new features. Defaults hapax, function might also used new_word instead plot sample new additions documents' vocabularies.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"","code":"if (FALSE) {   dubliners <- get_gutenberg_corpus(2814) |>     load_texts() |>     identify_by(part) |>     standardize_titles()    dubliners_measured <- dubliners |>     add_vocabulary()    dubliners_measured |>     plot_hapax() }"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hir.html","id":null,"dir":"Reference","previous_headings":"","what":"Show hapax introduction ratio over time — plot_hir","title":"Show hapax introduction ratio over time — plot_hir","text":"Show hapax introduction ratio time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show hapax introduction ratio over time — plot_hir","text":"","code":"plot_hir(   df,   x = progress_words,   by = doc_id,   identity = doc_id,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inline\", \"axis\", \"inset\"),   log_y = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show hapax introduction ratio over time — plot_hir","text":"df tidy data frame, potentially containing column called \"doc_id\" \"word\" x progress column show. Default option progress_percent, progress_words also appropriate. grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show hapax introduction ratio over time — plot_hir","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show hapax introduction ratio over time — plot_hir","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners_measured <- dubliners |>   add_vocabulary()  dubliners_measured |>   standardize_titles() |>   plot_hir()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the top terms by tf-idf — plot_tf_idf","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"Visualize top terms tf-idf","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"","code":"plot_tf_idf(   df,   rows = 1:10,   by = doc_id,   feature = word,   label = FALSE,   label_tweak = 2,   label_inside = FALSE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" rows rows terms chart document column containing document grouping feature column containing terms measured across document groupings label yet working label_tweak yet working label_inside yet working","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   plot_tf_idf()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bars for words in each topic — plot_topic_bars","title":"Plot bars for words in each topic — plot_topic_bars","text":"Plot bars words topic","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bars for words in each topic — plot_topic_bars","text":"","code":"plot_topic_bars(   lda,   topics,   top_n = 10,   expand_bars = TRUE,   save = TRUE,   saveas = \"png\",   savedir = \"plots\" )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bars for words in each topic — plot_topic_bars","text":"lda topic model used. topics topic numbers view top_n number words show topic expand_bars Whether stretch bars length X-axis facet save default, visualization saved. Set FALSE skip saving. saveas filetype saving resulting visualizations. default, files \"png\" format, options \"pdf\" \"jpg also work. savedir directory saving output images. default, set \"plots/\".","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bars for words in each topic — plot_topic_bars","text":"ggplot2 visualization showing top words chosen topics.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot bars for words in each topic — plot_topic_bars","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  austen_lda |>   plot_topic_bars(topics = c(22, 6)) +   labs(title = \"Competing topics in Northanger Abbey\")"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot topic distributions — plot_topic_distributions","title":"Plot topic distributions — plot_topic_distributions","text":"plot_topic_distributions() prepares visualization exploring significant topics document time.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot topic distributions — plot_topic_distributions","text":"","code":"plot_topic_distributions(   lda,   top_n = 4,   direct_label = TRUE,   title = TRUE,   save = TRUE,   saveas = \"png\",   savedir = \"plots\",   omit = NULL,   smooth = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot topic distributions — plot_topic_distributions","text":"lda topic model used. top_n number topics visualize. default, top 4 topics document shown. direct_label default, directly labels topic numbers chart. Set FALSE show legend corresponding color. title default, function add title chart, corresponding name object passed lda parameter. Set FALSE return chart title. save default, visualization saved. Set FALSE skip saving. saveas filetype saving resulting visualizations. default, files \"png\" format, options \"pdf\" \"jpg also work. savedir directory saving output images. default, set \"plots/\". omit Upon exploration, topics may found contain common stop words unhelpful material. Use omit parameter define vector topic numbers wish omit visualization. smooth samples rejoined, measured value topic vary wildly, even samples beside document. can make charts distractingly jittery. default TRUE value parameter reduces chart noise calculating rolling averages across three samples. Set parameter FALSE skip step allow visualization extreme values.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot topic distributions — plot_topic_distributions","text":"ggplot2 visualization showing vertical facets texts. length text shown X-axis, area plots Y-axis show distribution strongest topics part text.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot topic distributions — plot_topic_distributions","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  plot_topic_distributions(austen_lda)"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot topic wordclouds — plot_topic_wordcloud","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"plot_topic_wordcloud() prepares, saves, displays word clouds topics topic model. function can display word clouds one specific topics, can show word clouds every topic.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"","code":"plot_topic_wordcloud(lda, topics = NULL, crop = TRUE, savedir = \"plots\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"lda topic model used. topics Topic numbers visualized. left undefined, topics visualized crop Whether remove white space visualized word clouds savedir directory save plots . Defaults \"plots\"","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"Graphic(s) prepared knitr Quarto RMarkdown","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  austen_lda |>   plot_topic_wordcloud(topic = 6)"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":null,"dir":"Reference","previous_headings":"","what":"Show type-token ratio over time — plot_ttr","title":"Show type-token ratio over time — plot_ttr","text":"Show type-token ratio time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show type-token ratio over time — plot_ttr","text":"","code":"plot_ttr(   df,   x = progress_words,   by = doc_id,   identity = NULL,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inline\", \"axis\", \"inset\"),   log_y = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show type-token ratio over time — plot_ttr","text":"df tidy data frame, potentially containing column called \"doc_id\" \"word\" x progress column show. Default option progress_percent, progress_words also appropriate. grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show type-token ratio over time — plot_ttr","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show type-token ratio over time — plot_ttr","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners_measured <- dubliners |>   add_vocabulary()  dubliners_measured |>   plot_ttr(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'   dubliners_measured |>   plot_ttr()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Show vocabulary growth — plot_vocabulary","title":"Show vocabulary growth — plot_vocabulary","text":"plot_vocabulary() visualizes vocabulary growth new words used document.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show vocabulary growth — plot_vocabulary","text":"","code":"plot_vocabulary(   df,   x = progress_words,   by = doc_id,   identity = NULL,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inset\", \"inline\", \"axis\") )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show vocabulary growth — plot_vocabulary","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" x column showing cumulative count words grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show vocabulary growth — plot_vocabulary","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show vocabulary growth — plot_vocabulary","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners_measured <- dubliners |>   add_vocabulary()  dubliners_measured |>   plot_vocabulary(progress_percent) #> Warning: `guide_axis_truncated()` was deprecated in ggh4x 0.3.0. #> ℹ Please use `ggplot2::guide_axis(cap = TRUE)` instead. #> ℹ The deprecated feature was likely used in the tmtyro package. #>   Please report the issue at <https://github.com/jmclawson/tmtyro/issues>.   dubliners_measured |>   plot_vocabulary()   if (FALSE) { # \\dontrun{   get_micusp_corpus(     discipline %in% c(\"Physics\", \"Economics\")) |>     load_texts() |>     add_vocabulary() |>     plot_vocabulary(by = discipline) } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Part of speech tags — pos_tags","title":"Part of speech tags — pos_tags","text":"Tags descriptions English parts speech, designated Penn Treebank Project.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Part of speech tags — pos_tags","text":"","code":"pos_tags"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"-pos-tags-","dir":"Reference","previous_headings":"","what":"\"pos_tags\"","title":"Part of speech tags — pos_tags","text":"data frame 36 rows 2 columns tag speech tag description meaning tag","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Part of speech tags — pos_tags","text":"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate one word per column — separate_ngrams","title":"Separate one word per column — separate_ngrams","text":"Separate one word per column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate one word per column — separate_ngrams","text":"","code":"separate_ngrams(df, names_prefix = \"word\", ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate one word per column — separate_ngrams","text":"df tidy data frame containing column called \"ngram\" names_prefix prefixed name new columns, \"word_1\", \"word_2\", etc. ... Additional options passed tidyr::separate_wider_delim()","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Separate one word per column — separate_ngrams","text":"data frame one column separated many","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Separate one word per column — separate_ngrams","text":"","code":"if (FALSE) { # \\dontrun{   my_corpus <- load_texts(n = 2)    my_bigrams <- my_corpus |>     separate_ngrams() } # }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_ngrams() |>   combine_ngrams() |>   separate_ngrams() |>   head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word_1 word_2 #>   <fct>       <chr>     <chr>        <chr>       <chr>  <chr>  #> 1 The Sisters Dubliners Joyce, James THE SISTERS there  was    #> 2 The Sisters Dubliners Joyce, James THE SISTERS was    no     #> 3 The Sisters Dubliners Joyce, James THE SISTERS no     hope   #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope   for    #> 5 The Sisters Dubliners Joyce, James THE SISTERS for    him    #> 6 The Sisters Dubliners Joyce, James THE SISTERS him    this"},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize document titles — standardize_titles","title":"Standardize document titles — standardize_titles","text":"Useful especially visualizations. standardize_titles applies English-language conventions, including converting underscores spaces, capitalizing important words, removing leading articles, dropping subtitles.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize document titles — standardize_titles","text":"","code":"standardize_titles(.data, title = doc_id, drop_articles = FALSE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize document titles — standardize_titles","text":".data tidy data frame, potentially containing title column called \"doc_id\". Alternatively, simple character vector titles. title column containing titles standardized drop_articles Whether remove opening articles like \"\" \"\"","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize document titles — standardize_titles","text":"data frame one column adjusted. .data character vector instead data frame, character vector returned.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize document titles — standardize_titles","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part)  ##### Standardizing strings ##### # Before `standardize_titles()` unique(dubliners$doc_id) #>  [1] THE SISTERS                   AN ENCOUNTER                  #>  [3] ARABY                         EVELINE                       #>  [5] AFTER THE RACE                TWO GALLANTS                  #>  [7] THE BOARDING HOUSE            A LITTLE CLOUD                #>  [9] COUNTERPARTS                  CLAY                          #> [11] A PAINFUL CASE                IVY DAY IN THE COMMITTEE ROOM #> [13] A MOTHER                      GRACE                         #> [15] THE DEAD                      #> 15 Levels: THE SISTERS AN ENCOUNTER ARABY EVELINE ... THE DEAD  # After `standardize_titles()` unique(dubliners$doc_id) |>   standardize_titles() #>  [1] The Sisters                   An Encounter                  #>  [3] Araby                         Eveline                       #>  [5] After the Race                Two Gallants                  #>  [7] The Boarding House            A Little Cloud                #>  [9] Counterparts                  Clay                          #> [11] A Painful Case                Ivy Day in the Committee Room #> [13] A Mother                      Grace                         #> [15] The Dead                      #> 15 Levels: The Sisters An Encounter Araby Eveline ... The Dead  ##### Standardizing a data frame #####  dubliners_measured <- dubliners |>   add_vocabulary()  # Before `standardize_titles()` dubliners_measured |>   plot_vocabulary(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'   # After `standardize_titles()` dubliners_measured |>   standardize_titles() |>   plot_vocabulary(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'"},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare usage across a corpus — summarize_tf_idf","title":"Compare usage across a corpus — summarize_tf_idf","text":"summarize_tf_idf() prepares summary table term corpus, including frequencies document \"tf-idf\" measurements comparing relative importance comparison documents set.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare usage across a corpus — summarize_tf_idf","text":"","code":"summarize_tf_idf(df, by = doc_id, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare usage across a corpus — summarize_tf_idf","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" column containing document grouping feature column containing terms measured across document groupings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare usage across a corpus — summarize_tf_idf","text":"summary original data frame, rows document term pairing columns document identifier, term, n (number times term used document), tf (term's frequency document), idf (inverse document frequency), tf_idf (previous two columns combined).","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare usage across a corpus — summarize_tf_idf","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   summarize_tf_idf() #> # A tibble: 17,686 × 6 #>    doc_id                        word         n      tf   idf tf_idf #>    <fct>                         <chr>    <int>   <dbl> <dbl>  <dbl> #>  1 Clay                          maria       40 0.0150   2.71 0.0407 #>  2 Two Gallants                  corley      46 0.0117   2.71 0.0318 #>  3 After the Race                jimmy       24 0.0107   2.71 0.0290 #>  4 Ivy Day in the Committee Room henchy      53 0.0101   2.71 0.0274 #>  5 A Little Cloud                gallaher    48 0.00972  2.71 0.0263 #>  6 The Dead                      gabriel    142 0.00903  2.71 0.0244 #>  7 Grace                         kernan      66 0.00875  2.71 0.0237 #>  8 Ivy Day in the Committee Room o’connor    45 0.00858  2.71 0.0232 #>  9 A Little Cloud                chandler    41 0.00830  2.71 0.0225 #> 10 A Mother                      kearney     50 0.0110   2.01 0.0222 #> # ℹ 17,676 more rows"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.combined_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","title":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","text":"Prepare table n-gram frequencies","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.combined_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","text":"","code":"# S3 method for class 'combined_ngrams' tabulize(.data, rows = NULL, count = TRUE, digits = 2, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.combined_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","text":".data data processed one functions tmtyro rows Chooses rows shown count Determines whether frequencies counted individual features digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a default table view — tabulize.default","title":"Prepare a default table view — tabulize.default","text":"Prepare default table view","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a default table view — tabulize.default","text":"","code":"# Default S3 method tabulize(   .data,   summary = TRUE,   inorder = TRUE,   count = FALSE,   rows = NULL,   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a default table view — tabulize.default","text":".data data processed one functions tmtyro summary Indicates whether prepare summary table rows exist inorder Indicates whether labels doc_id column order preserved count Determines whether frequencies counted individual features rows Chooses rows shown ... optional parameters (unused)","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.expanded.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table showing a document-feature matrix — tabulize.expanded","title":"Prepare a table showing a document-feature matrix — tabulize.expanded","text":"Prepare table showing document-feature matrix","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.expanded.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table showing a document-feature matrix — tabulize.expanded","text":"","code":"# S3 method for class 'expanded' tabulize(.data, columns = NULL, digits = 2, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.expanded.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table showing a document-feature matrix — tabulize.expanded","text":".data data processed one functions tmtyro columns Chooses columns shown digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of data — tabulize","title":"Prepare a table of data — tabulize","text":"tabulize() provides simple method sharing results. Based previous functions used, tabulize() choose method, resolving one set tables.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of data — tabulize","text":"","code":"tabulize(.data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of data — tabulize","text":".data data processed one functions tmtyro ... Arguments passed tabulize.default summary Indicates whether prepare summary table rows exist inorder Indicates whether labels doc_id column order preserved count Determines whether frequencies counted individual features rows Chooses rows shown","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare a table of data — tabulize","text":"gt table data object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare a table of data — tabulize","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  # A data frame with `doc_id` and `word` columns will show word counts by default dubliners |>    tabulize() # Applying tmtyro functions will prepare other tables   dubliners |>    add_vocabulary() |>    tabulize() dubliners |>      dplyr::filter(doc_id == \"The Dead\") |>      add_sentiment() |>      tabulize()"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of n-gram frequencies — tabulize.ngrams","title":"Prepare a table of n-gram frequencies — tabulize.ngrams","text":"Prepare table n-gram frequencies","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of n-gram frequencies — tabulize.ngrams","text":"","code":"# S3 method for class 'ngrams' tabulize(.data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of n-gram frequencies — tabulize.ngrams","text":".data data processed one functions tmtyro ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table for sentiment analysis — tabulize.sentiment","title":"Prepare a table for sentiment analysis — tabulize.sentiment","text":"Prepare table sentiment analysis","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table for sentiment analysis — tabulize.sentiment","text":"","code":"# S3 method for class 'sentiment' tabulize(   .data,   inorder = TRUE,   digits = 2,   drop_na = FALSE,   ignore = NULL,   rows = NULL,   count = TRUE,   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table for sentiment analysis — tabulize.sentiment","text":".data data processed one functions tmtyro inorder Indicates whether labels doc_id column order preserved digits number digits show past decimal point drop_na Removes rows lacking sentiment ignore Removes rows matching set sentiments rows Chooses rows shown count Determines whether frequencies counted sentiments ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of term frequency–inverse document frequency — tabulize.tf_idf","title":"Prepare a table of term frequency–inverse document frequency — tabulize.tf_idf","text":"Prepare table term frequency–inverse document frequency","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of term frequency–inverse document frequency — tabulize.tf_idf","text":"","code":"# S3 method for class 'tf_idf' tabulize(.data, rows = NULL, digits = 5, feature = word, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of term frequency–inverse document frequency — tabulize.tf_idf","text":".data data processed one functions tmtyro rows Chooses rows shown digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of lexical variety — tabulize.vocabulary","title":"Prepare a table of lexical variety — tabulize.vocabulary","text":"Prepare table lexical variety","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of lexical variety — tabulize.vocabulary","text":"","code":"# S3 method for class 'vocabulary' tabulize(.data, digits = 3, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of lexical variety — tabulize.vocabulary","text":".data data processed one functions tmtyro digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tmtyro-package.html","id":null,"dir":"Reference","previous_headings":"","what":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","title":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","text":"Work analyze text simple complex features. Adopting tidytext principles, tmtyro abstracts processes levels allow beginners use familiarize techniques understand much code.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/tmtyro-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","text":"Maintainer: James Clawson clawson@gmail.com (ORCID)","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":null,"dir":"Reference","previous_headings":"","what":"Split text into words and drop proper nouns — unnest_without_caps","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"Split column text using tidytext::unnest_tokens(), flattening table one token per row also omitting token present capitalized form.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"","code":"unnest_without_caps(df, output = \"word\", input = \"text\", to_lower = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"df data frame output Output column created. input Input column gets split word. to_lower Whether convert final words lowercase.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"data frame","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"","code":"if (FALSE) { # \\dontrun{ mysteries <-   load_texts(\"mystery-novels\",              to_lower = FALSE) |>   unnest_without_caps()  # Since `unnest_without_caps()` is # incorporated into `load_texts()`, # it may be unnecessary for many # scenarios. mysteries <-   load_texts(\"mystery-novels\",              remove_names = TRUE)   } # }"},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize output — visualize","title":"Visualize output — visualize","text":"visualize() provides simple method displaying results. Based previous functions used, visualize() choose method, resolving one visualizing helpers.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize output — visualize","text":"","code":"visualize(.data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize output — visualize","text":".data data processed one functions tmtyro ... Arguments passed plot_doc_word_bars, plot_bigrams, plot_vocabulary, plot_ttr, plot_hir, plot_topic_distributions, plot_topic_bars, plot_topic_wordcloud rows features show column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" inorder Whether retain factor order \"\" column reorder_y Whether reorder Y-values facet color_y Whether bars filled Y-values percents Whether display word frequencies percentage instead raw counts label Whether show value label bar label_tweak numeric value tweak label, shown. percentages, value adjusts decimal-point precision. raw counts, value adjusts labels' offset bars label_inside Whether show value label inside bar na_rm Whether drop empty features random_seed Whether randomize creation network chart. set_seed specific seed use random legend Whether show legend edge color top_n number pairs visualize identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE topics topic numbers view","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize output — visualize","text":"ggplot2 object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Visualize output — visualize","text":"visualizations, optional type parameter may helpful change visualization. example, setting type = \"htr\", type = \"ttr\", type = \"hapax\" add_vocabulary() emphasize different columns added function. Similarly, type = \"cloud\" type = \"wordcloud\" show topic word clouds make_topic_model(), type = \"heatmap\" show alternative visualization word frequencies.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize output — visualize","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  # A data frame with `doc_id` and `word` columns will visualize frequency by default dubliners |>    visualize()   # Applying `tmtyro` functions will choose an appropriate visualization  dubliners |>    add_ngrams() |>    visualize()   dubliners |>    add_ngrams() |>    combine_ngrams() |>    visualize()   dubliners |>    summarize_tf_idf() |>    visualize()   dubliners |>    add_vocabulary() |>    visualize()   if (FALSE) { # sentiment requires interaction on first load   dubliners |>      add_sentiment() |>      visualize() }  # Some visualizations are specified with the `type` argument dubliners |>    add_vocabulary() |>    visualize(type = \"ttr\")   if (FALSE) { # puzzlingly broken for Dubliners, but usually works dubliners |>    add_vocabulary() |>    visualize(type = \"hapax\") }  # Other arguments get passed along dubliners |>    add_ngrams() |>    visualize(top_n = 25)   dubliners |>    add_vocabulary() |>    visualize(x = progress_percent)"},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-05","dir":"Changelog","previous_headings":"","what":"tmtyro 0.5","title":"tmtyro 0.5","text":"New functions add_frequency() add_tf_idf() allow consistent phrasing workflows. new methods supported visualize() tabulize(). New vectorized functions support using dplyr’s mutate() similar use cases: get_frequency() returning counts ratios values vector; is_new() is_hapax() testing uniqueness values vector; get_cumulative_vocabulary(), get_ttr(), get_hir(), get_htr() measuring cumulative change vector time; get_match() get_sentiment() matching values dictionary; get_tf(), get_tf_by(), get_idf_by(), get_tfidf_by() weighing elements term frequency–inverse document frequency. Bar plots words per document now use better logic labels, new label_color argument allows customizing label color needed. Added “skills ramp” article documenting vectorized functions customized tables figures","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-041","dir":"Changelog","previous_headings":"","what":"tmtyro 0.4.1","title":"tmtyro 0.4.1","text":"get_gutenberg_corpus() less, now . functionality available via gutenbergr.","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-040","dir":"Changelog","previous_headings":"","what":"tmtyro 0.4.0","title":"tmtyro 0.4.0","text":"New function contextualize() shows terms window context New function add_index() adds column showing word indices within document load_texts() adds support keep original capitalization punctuation alongside tokenized word column keep_original argument. process work instances, option defaults FALSE. add_dictionary() includes option keep original terms. useful n-gram dictionaries, match might otherwise span multiple rows. add_ngrams() supports negative ranges, building context windows add_partitions() supports overlapping partitions standardize_titles() capitalizes words terminal punctuation","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-030","dir":"Changelog","previous_headings":"","what":"tmtyro 0.3.0","title":"tmtyro 0.3.0","text":"add_dictionary() now supports n-gram dictionaries, matching across multiple words make_dictionary() slightly changed syntax, clearer argument names definitions name Along related visualize() methods, plot_doc_word_bars() improves support color_y = TRUE reorder_y = TRUE naming colors, change_color() now allows setting colors unnamed values standardize_titles() capitalizes Roman numerals load_texts() adds support custom tokenization using dots parameter tidytext::unnest_tokens()","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-020","dir":"Changelog","previous_headings":"","what":"tmtyro 0.2.0","title":"tmtyro 0.2.0","text":"New function add_partitions() adds partition column, useful getting -sized samples identify_by() now works multiple columns, keeps existing metadata columns. especially useful new add_partitions() column, using something like my_corpus() |> add_partitions() |> identify_by(title, partition) continuing work partitioned documents. return framing unpartitioned data, used identify_by(title) whatever column relevant. New visualization tabulization methods expand_documents() Functions now imported: count() drop_na() ggraph package loaded, plot_bigrams() now uses color scale edges, rather spot color nodes, full support change_color() Improved documentation website articles customizing colors showing code comparisons","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-010","dir":"Changelog","previous_headings":"","what":"tmtyro 0.1.0","title":"tmtyro 0.1.0","text":"First “public” release! 🎉 Unnecessary components removed dependencies reduced Examples standardized made reproducible change_colors() now works plot_bigrams() change_colors() now includes “dubois” colorset tabulize() documentation now improved online output standardize_titles() now works factors Added default behavior visualize() corpus Part speech tagging now work texts","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-development-version-0089000","dir":"Changelog","previous_headings":"","what":"tmtyro (development version 0.0.8.9000)","title":"tmtyro (development version 0.0.8.9000)","text":"New tabulize() generic function preparing tables supported methods Standardizing argument names visualize() tabulize() New package documentation getting started New collapse_rows() function clean tables using gt::gt() New feature standardize_titles() keep initial articles New options plot_doc_word_bars() keep order Y-axis values consistent color Y-axis value instead facet Rename add_lexical_diversity() add_vocabulary() Add option renaming existing doc_id column using identify_by()","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-development-version-0079000","dir":"Changelog","previous_headings":"","what":"tmtyro (development version 0.0.7.9000)","title":"tmtyro (development version 0.0.7.9000)","text":"get_gutenberg_corpus() now retrieves HTML versions texts Project Gutenberg parses header tags section markers New function parse_html() reading headers HTML file New function move_header_to_text() converting header text New function identify_by() simplify using something doc_id Improved internal linking within documentation","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-development-version-0069000","dir":"Changelog","previous_headings":"","what":"tmtyro (development version 0.0.6.9000)","title":"tmtyro (development version 0.0.6.9000)","text":"Better working visualize() function generic supported methods Improved change_colors() added support Okabe-Ito colorset option starting something first color palette. changes, color options removed visualization functions consolidate within change_colors(). data set includes one unique doc_id, visualizations longer divided facets. effort reduce number dependencies, many packages removed “Imports” (geomtextpath, ggrepel, glue, NLP, openNLP, plotly, RColorBrewer, stopwords, textstem, wordcloud). appropriate, shifted “Suggests” dropped entirely.","code":""}]
