[{"path":"https://jmclawson.github.io/tmtyro/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 tmtyro authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"in-context","dir":"Articles","previous_headings":"","what":"In context","title":"Differentiating tmtyro","text":"Voyant one best-known tools working text data humanities. Begun development Stéfan Sinclair Geoffrey Rockwell twenty years ago, become standard—good reason. graphical interface makes accessible novices without compromising ability features. Still, Voyant’s easy--use interface ultimately limits users’ growth, since interface can keep Voyant serving skills ramp options. Unlike Voyant, code-based methods working text offer reproducibility open-ended tooling. R, tm package created Ingo Feinerer Kurt Hornik among oldest widely used packages text mining.1 emphasizes corpus creation choosing text features study. First published CRAN 2007, predates packages described almost decade, data design makes sometimes hard work modern workflows. quanteda package, released Kenneth Benoit 2015, continual development. provides workflows corpus creation, choosing features, searching words context, working custom dictionaries, visualizing results, among things, providing helpful documentation along way. abundance options multiple-step workflows can overwhelming beginner. like tm, quanteda’s primary data design ideally suited popular packages.2 Nevertheless, quanteda provides power specialized functionality makes worth steep learning curve. newest four tidytext, created Julia Silge David Robinson 2019. Unlike two, tidytext made using “tidy” design philosophy consistent many popular R packages.3 Additionally, companion book, Text Mining R, offers impressive documentation, easing learning curve anyone new text mining. book’s preface acknowledges starting point quite ways zero, expecting “reader least slightly familiar dplyr, ggplot2, %>% ‘pipe’ operator R.” expectations make tidytext tough complete beginners must get speed tools using .  context, tmtyro package steps cautiously remaining space fill particular need. Developed teaching two semesters undergraduate course literary text mining, grew folder “helper” functions written students. course taught English department, never meant “coding class” much one induced students think text new ways. syllabus followed examples Text Mining R , ambitiously, Text Analysis R Students Literature, Matthew Jockers Rosamond Thalken, pairing methods applications recent research. week, students applied techniques ask questions selections writing. working tools front us helped everyone test boundaries new world map might follow similar paths laid readings. Like Voyant, tmtyro designed beginner, strives predictability. Workflows provided loading texts folder getting corpus texts online collections. texts loaded, repetitive conventions function names make easy add columns analysis single step, generic functions handle details tables figures. importantly, tmtyro provides skills ramp users outgrow . Code workflows designed help beginners move quickly start try things . , student gains confidence methods provided package might step beyond tweak visualization using functions ggplot2. researcher wishing work subset titles begin understand methods dplyr. since tmtyro’s data design based tidytext, user can transition packages seamlessly, using together. Nobody expected stick tmtyro forever, functions designed remain useful long past “tyro” stage.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"in-code","dir":"Articles","previous_headings":"","what":"In code","title":"Differentiating tmtyro","text":"packages developed different audiences, take different approaches common steps. functions approaches used tmtyro seem similar tidytext. time, many details choices hidden simplify interface prioritize getting results. code use package shown comparison. Every approach assumes object definition showing path folder text files: likely someone familiar given package take different approach, examples demonstrate method someone might try searching documentation internet. methods benchmarked, might faster others, speeds feel comparable testing.","code":"text_directory <- \"path/to/files\""},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"load-texts-from-a-folder","dir":"Articles","previous_headings":"In code","what":"Load texts from a folder","title":"Differentiating tmtyro","text":"first comparison shows first step loading corpus local folder texts. tmtyro tidytext quanteda tm Behind scenes, tmtyro’s load_texts() uses functions base R number packages: dplyr, forcats, purrr, rlang, stringr, tibble, tidyr, tidytext. lemmatizing tagging parts speech, also uses textstem, openNLP, NLP.","code":"library(tmtyro)  my_corpus <- load_texts(text_directory) library(tidytext) library(dplyr) library(readr) library(stringr)  my_corpus_tt <-    data.frame(     doc_id = list.files(text_directory, \"\\\\.txt$\")) |>    mutate(     text = paste(text_directory, doc_id, sep = \"/\") |>        read_file(),     .by = doc_id) |>    mutate(     doc_id = str_remove_all(doc_id, \"[.]txt\")) |>    unnest_tokens(word, text) library(quanteda) library(readtext)  my_corpus_qu <-    readtext(     paste0(text_directory, \"/*.txt\"),     docvarsfrom = \"filenames\") |>    corpus() |>    tokens() library(tm)  my_corpus_tm <- DirSource(text_directory) |>    Corpus(readerControl = list(reader = readPlain))"},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"remove-stop-words","dir":"Articles","previous_headings":"In code","what":"Remove stop words","title":"Differentiating tmtyro","text":"Removing stop words common step text analysis. examples continues directly previous step loading texts. tmtyro tidytext quanteda tm drop_stopwords() uses functions dplyr tidytext.","code":"sans_stopwords <- drop_stopwords(my_corpus) sans_stopwords_tt <- anti_join(my_corpus_tt, get_stopwords()) library(stopwords)  sans_stopwords_qu <- tokens_remove(my_corpus_qu, stopwords(\"english\")) sans_stopwords_tm <-     tm_map(my_corpus_tm,          removeWords,           stopwords(\"english\"))"},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"add-sentiment","dir":"Articles","previous_headings":"In code","what":"Add sentiment","title":"Differentiating tmtyro","text":"pre-trained lexicon needed tag texts sentiment. process differs package. tmtyro tidytext quanteda tm add_sentiment() uses functions rlang, dplyr, textdata, tidytext.","code":"sentiment <- add_sentiment(my_corpus) sentiment_tt <- inner_join(my_corpus_tt, get_sentiments()) sentiment_qu <-    tokens_lookup(     my_corpus_qu,     dictionary = data_dictionary_LSD2015,      exclusive = FALSE) library(syuzhet)  sentiment_tm <- get_sentiment(my_corpus_tm)  # This doesn't actually do the job. I'm not sure what the equivalent would be using tm."},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"measure-tf-idf","dir":"Articles","previous_headings":"In code","what":"Measure Tf-idf","title":"Differentiating tmtyro","text":"Term frequency–inverse document frequency method weighing words contribution distinctness within corpus. tmtyro tidytext quanteda tm summarize_tf_idf() uses functions dplyr tidytext.","code":"tfidf <- summarize_tf_idf(my_corpus) tfidf_tt <- my_corpus_tt |>  count(doc_id, word, sort = TRUE)  total_words <- tfidf_tt |>    group_by(doc_id) |>    summarize(total = sum(n))  tfidf_tt <- left_join(tfidf_tt, total_words) |>    bind_tf_idf(word, doc_id, n) tfidf_qu <- dfm(my_corpus_qu) |>    docfreq(scheme = \"inverse\") tfidf_tm <- weightTfIdf(DocumentTermMatrix(my_corpus_tm))"},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"visualize-most-frequent-words","dir":"Articles","previous_headings":"In code","what":"Visualize most frequent words","title":"Differentiating tmtyro","text":"Measuring word frequency basic step text mining. Well-prepared figures can help communicate results. tmtyro tidytext quanteda tm count() function reexported dplyr. showing word counts, visualize() also uses ggplot2. kinds visualizations add forcats, scales, tidyr, ggraph, igraph packages.","code":"my_corpus |>    count(word) |>    visualize() library(ggplot2)  my_corpus_tt |>    count(word, sort = TRUE) |>    slice_head(n = 10) |>    mutate(proportion = n / sum(n)) |>    ggplot(aes(proportion, reorder(word, proportion))) +   geom_col() +   labs(y = NULL) library(quanteda.textstats) library(ggplot2)  tokens(my_corpus_qu,        remove_punct = TRUE) |>    dfm() |>    textstat_frequency(n = 10) |>    ggplot(aes(x = frequency,              y = reorder(feature, -rank))) +   geom_col() +    labs(y = NULL) library(Rgraphviz)  plot(TermDocumentMatrix(my_corpus_tm),      terms = findFreqTerms(TermDocumentMatrix(my_corpus_tm))[1:10])  # This doesn't actually work, since the necessary package was removed from CRAN."},{"path":"https://jmclawson.github.io/tmtyro/articles/01-differentiating.html","id":"complete-workflow","dir":"Articles","previous_headings":"In code","what":"Complete workflow","title":"Differentiating tmtyro","text":"last section compares four packages walking common workflow, using load folder texts, remove stopwords, visualize frequent words. tmtyro tidytext quanteda tm","code":"library(tmtyro)  load_texts(text_directory) |>    drop_stopwords() |>    count(word) |>    visualize() library(tidytext) library(dplyr) library(tibble) library(ggplot2) data(stop_words)  data.frame(     doc_id = list.files(text_directory, \"\\\\.txt$\")) |>    mutate(     text = paste(text_directory, doc_id, sep = \"/\") |>        read_file(),     .by = doc_id) |>    unnest_tokens(word, text) |>    anti_join(stop_words) |>    count(word, sort = TRUE) |>    slice_head(n = 10) |>    mutate(proportion = n / sum(n)) |>    ggplot(aes(proportion, reorder(word, proportion))) +   geom_col() +   labs(y = NULL) library(quanteda) library(readtext) library(stopwords) library(ggplot2)  readtext(     paste0(text_directory, \"/*.txt\"),     docvarsfrom = \"filenames\") |>    corpus() |>    tokens(remove_punct = TRUE) |>    tokens_remove(stopwords(\"english\")) |>    dfm() |>    textstat_frequency(n = 10) |>    ggplot(aes(x = frequency,              y = reorder(feature, -rank))) +   geom_col() +    labs(y = NULL) library(tm) library(Rgraphviz)  Corpus(   DirSource(text_directory),    readerControl = list(reader = readPlain)) |>    tm_map(removeWords,           stopwords(\"english\")) |>    TermDocumentMatrix() |>    plot(terms = findFreqTerms(TermDocumentMatrix(my_corpus_tm))[1:10])  # This doesn't actually work, since the necessary package was removed from CRAN."},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"colors-are-tricky","dir":"Articles","previous_headings":"","what":"Colors are tricky","title":"Customizing colors","text":"ggplot2 can set color many different ways, one way work given scenario. Clearest distinction color fill. first applies color points, lines, edges. ’s adjusted functions color names, like scale_color_manual(). fill aesthetic, hand, defines areas, inside shapes, bars. ’s adjusted functions fill names, like scale_fill_manual(). every case, _fill_ _color_ part function indicate target. Difficulty grows . Colors fills set different ways discrete data, continuous data, binned data. Worse, color palettes chosen using three incompatible methods depending color set, one method custom manual palettes, another method Brewer palettes, third Viridis palettes. Many options available additional packages, combination two aesthetics, three types data, three types palettes built ggplot2. manual1 scale_color_manual() scale_color_gradient() scale_color_steps() Brewer2 scale_color_brewer() scale_color_distiller() scale_color_fermenter() Viridis3 scale_color_viridis_d() scale_color_viridis_c() scale_color_viridis_b() table shows half 18 commonest functions changing colors, ggplot2 offers 44 without counting spelling variants. row functions uses different parameters choosing colors. path color customization steep.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"change_colors-is-easy","dir":"Articles","previous_headings":"","what":"change_colors() is easy","title":"Customizing colors","text":"visualization functions tmtyro can changed one standard method: change_colors(). function considers figure, figures whether makes sense change color fill, applies standard interface manual palettes, Brewer palettes, Viridis palettes. change_colors() manages differentiation among data types. scale_color_manual() works discrete data, scale_color_gradient() good continuous values. scale_color_brewer() work discrete data types, scale_color_distiller() works continuous data scale_color_viridis_d() work discrete data types, scale_color_viridis_c() work continous data. change_colors() accommodates discrete continuous data change_colors() also introduces one standard interface arguments. scale_color_manual() sets colors using named hexadecimal colors values argument scale_color_brewer() sets colors using numbers palette argument scale_color_viridis_d() sets colors using letters option argument change_colors() uses palettes argument everything code easy, difficult part choice.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"manual-colors","dir":"Articles","previous_headings":"Options are many","what":"manual colors","title":"Customizing colors","text":"simply, change_colors() set colors choose. Setting four colors four items assign directly; number make gradient. Color names like “pink” “orange” work R, specific hues like “forestgreen” “steelblue.”1 addition named colors, R accept colors “hex codes” using hexadecimal notation.2 first two digits hex code describe red color ; middle two describe green ; last two describe blue. Combinations following chart give sense work, online color picker may help narrow things .3  Use manual colors—named colors hex codes—combining vector inside change_colors():  Custom colors also work well naming particular values:","code":"dubliners_count |>    change_colors(c(\"#00BBBB\", \"tan\", \"purple\")) joyce_count |>    change_colors(c(     to = \"#88FF00\",      the = \"#00FF00\",     of = \"#00FF88\",      and = \"#00DDBB\",     a = \"#00EEEE\",     he = \"red\"))"},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"brewer-palettes","dir":"Articles","previous_headings":"Options are many","what":"Brewer palettes","title":"Customizing colors","text":"’d rather pick colors manually, Brewer palettes excellent choice. Brewer qualitative palettes well suited discrete data, using color distinguish categories like documents words.  Brewer’s sequential palettes ideal showing differences magnitude:  Choose Brewer palette using name number palette argument:","code":"joyce_count |>    change_colors(\"Brewer\", palette = \"Dark2\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/02-changing-colors.html","id":"viridis-palettes","dir":"Articles","previous_headings":"Options are many","what":"Viridis palettes","title":"Customizing colors","text":"Viridis palettes offer another set choices colors visualizations. palettes look beautiful screen, typically work well monochrome print designed accommodate color vision needs. palettes work especially well continuous data. Option “H” “turbo” work discrete scales, also caveats: among , ’s poorly suited black white printing since doesn’t follow linear path dark light.  Choose Viridis palette using name letter palette argument:","code":"dubliners_dfm |>    change_colors(\"Viridis\", palette = \"mako\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"preparing-texts","dir":"Articles","previous_headings":"","what":"Preparing texts","title":"Introduction to tmtyro","text":"tmtyro offers functions gather load texts study: get_gutenberg_corpus() caches HTML version books Project Gutenberg ID, parses text headers, presents table. get_micusp_corpus() caches papers Michigan Corpus Upper-level Student Papers, parses metadata contents, presents table. download_once() caches online file passes local path invisibly. load_texts() prepares table “tidytext” format one word per row columns metadata. texts can loaded folder files passed table. Parameters allow lemmatization, part--speech processing, options. functions aid preparing corpus: move_header_to_text() corrects overzealous identification HTML headers parsing books Project Gutenberg. standardize_titles() converts vector column title case, converts underscores spaces, optionally removes initial articles. identify_by() sets column metadata serve document marker.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"get-a-corpus","dir":"Articles","previous_headings":"Preparing texts","what":"Get a corpus","title":"Introduction to tmtyro","text":"Collecting texts Project Gutenberg common first step many. function get_gutenberg_corpus() needs Gutenberg ID number, found book’s URL. resulting table draws metadata gutenbergr package, columns “gutenberg_id”, “title”, “author”, headers used chapters, “text.” cases, headers may make better sense read part text, “Aeolus” chapter Ulysses, frequent newspaper headlines pepper page: can corrected move_header_to_text(). Headers can moved specific texts corpus specifying filter like title == \"Ulysses\":","code":"library(tmtyro) joyce <- get_gutenberg_corpus(c(2814, 4217, 4300))  joyce #> # A tibble: 10,810 × 7 #>    gutenberg_id title     author       part        section subsection text       #>           <int> <chr>     <chr>        <chr>       <chr>   <chr>      <chr>      #>  1         2814 Dubliners Joyce, James THE SISTERS NA      NA         There was… #>  2         2814 Dubliners Joyce, James THE SISTERS NA      NA         Old Cotte… #>  3         2814 Dubliners Joyce, James THE SISTERS NA      NA         “No, I wo… #>  4         2814 Dubliners Joyce, James THE SISTERS NA      NA         He began … #>  5         2814 Dubliners Joyce, James THE SISTERS NA      NA         “I have m… #>  6         2814 Dubliners Joyce, James THE SISTERS NA      NA         He began … #>  7         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Well, so… #>  8         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Who?” sa… #>  9         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Father F… #> 10         2814 Dubliners Joyce, James THE SISTERS NA      NA         “Is he de… #> # ℹ 10,800 more rows ulysses <- get_gutenberg_corpus(4300)  # dplyr is used here to choose a smaller example for comparison ulysses |>    dplyr::filter(section == \"[ 7 ]\") #> # A tibble: 476 × 7 #>    gutenberg_id title   author       part   section subsection             text  #>           <int> <chr>   <chr>        <chr>  <chr>   <chr>                  <chr> #>  1         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… Befo… #>  2         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… —Rat… #>  3         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… —Com… #>  4         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… Righ… #>  5         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE H… —Sta… #>  6         4300 Ulysses Joyce, James — II — [ 7 ]   THE WEARER OF THE CRO… Unde… #>  7         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS Gros… #>  8         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS —The… #>  9         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS —Jus… #> 10         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS The … #> # ℹ 466 more rows ulysses <- get_gutenberg_corpus(4300) |>    move_header_to_text(subsection)  # dplyr is used here to choose a smaller example for comparison ulysses |>    dplyr::filter(section == \"[ 7 ]\") #> # A tibble: 539 × 6 #>    gutenberg_id title   author       part   section text                         #>           <int> <chr>   <chr>        <chr>  <chr>   <chr>                        #>  1         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE HIBERNI… #>  2         4300 Ulysses Joyce, James — II — [ 7 ]   Before Nelson’s pillar tram… #>  3         4300 Ulysses Joyce, James — II — [ 7 ]   —Rathgar and Terenure!       #>  4         4300 Ulysses Joyce, James — II — [ 7 ]   —Come on, Sandymount Green!  #>  5         4300 Ulysses Joyce, James — II — [ 7 ]   Right and left parallel cla… #>  6         4300 Ulysses Joyce, James — II — [ 7 ]   —Start, Palmerston Park!     #>  7         4300 Ulysses Joyce, James — II — [ 7 ]   THE WEARER OF THE CROWN      #>  8         4300 Ulysses Joyce, James — II — [ 7 ]   Under the porch of the gene… #>  9         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS       #> 10         4300 Ulysses Joyce, James — II — [ 7 ]   Grossbooted draymen rolled … #> # ℹ 529 more rows joyce <- joyce |>    move_header_to_text(subsection, title == \"Ulysses\")  joyce |>    dplyr::filter(section == \"[ 7 ]\") #> # A tibble: 539 × 6 #>    gutenberg_id title   author       part   section text                         #>           <int> <chr>   <chr>        <chr>  <chr>   <chr>                        #>  1         4300 Ulysses Joyce, James — II — [ 7 ]   IN THE HEART OF THE HIBERNI… #>  2         4300 Ulysses Joyce, James — II — [ 7 ]   Before Nelson’s pillar tram… #>  3         4300 Ulysses Joyce, James — II — [ 7 ]   —Rathgar and Terenure!       #>  4         4300 Ulysses Joyce, James — II — [ 7 ]   —Come on, Sandymount Green!  #>  5         4300 Ulysses Joyce, James — II — [ 7 ]   Right and left parallel cla… #>  6         4300 Ulysses Joyce, James — II — [ 7 ]   —Start, Palmerston Park!     #>  7         4300 Ulysses Joyce, James — II — [ 7 ]   THE WEARER OF THE CROWN      #>  8         4300 Ulysses Joyce, James — II — [ 7 ]   Under the porch of the gene… #>  9         4300 Ulysses Joyce, James — II — [ 7 ]   GENTLEMEN OF THE PRESS       #> 10         4300 Ulysses Joyce, James — II — [ 7 ]   Grossbooted draymen rolled … #> # ℹ 529 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"load-texts","dir":"Articles","previous_headings":"Preparing texts","what":"Load texts","title":"Introduction to tmtyro","text":"load_texts() prepares set documents study, either table folder files.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"from-a-table","dir":"Articles","previous_headings":"Preparing texts > Load texts","what":"From a table","title":"Introduction to tmtyro","text":"table like one prepared get_gutenberg_corpus() can prepared tidytext format one word per row using load_texts().","code":"corpus_ulysses <- ulysses |>    load_texts()  corpus_ulysses #> # A tibble: 265,043 × 6 #>    doc_id title   author       part  section word      #>     <int> <chr>   <chr>        <chr> <chr>   <chr>     #>  1   4300 Ulysses Joyce, James — I — [ 1 ]   stately   #>  2   4300 Ulysses Joyce, James — I — [ 1 ]   plump     #>  3   4300 Ulysses Joyce, James — I — [ 1 ]   buck      #>  4   4300 Ulysses Joyce, James — I — [ 1 ]   mulligan  #>  5   4300 Ulysses Joyce, James — I — [ 1 ]   came      #>  6   4300 Ulysses Joyce, James — I — [ 1 ]   from      #>  7   4300 Ulysses Joyce, James — I — [ 1 ]   the       #>  8   4300 Ulysses Joyce, James — I — [ 1 ]   stairhead #>  9   4300 Ulysses Joyce, James — I — [ 1 ]   bearing   #> 10   4300 Ulysses Joyce, James — I — [ 1 ]   a         #> # ℹ 265,033 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"from-files","dir":"Articles","previous_headings":"Preparing texts > Load texts","what":"From files","title":"Introduction to tmtyro","text":"text files already collected folder disk, can prepared table passing path folder inside load_texts(). Used way, load_texts() load every file using “txt” file extension, populating doc_id column first part file name. example, “austen” folder found within current project. instead found somewhere else computer, complete path can passed like :load_texts(\"~/corpora/austen\")","code":"corpus_austen <- load_texts(\"austen\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"choose-a-different-doc_id","dir":"Articles","previous_headings":"Preparing texts","what":"Choose a different doc_id","title":"Introduction to tmtyro","text":"Documents loaded get_gutenberg_corpus() use gutenberg_id column document identifier. different column preferred, identify_by() makes switch. example Dubliners, instance, story’s title shown “part”. identify_by() function makes easy identify documents column:","code":"corpus_dubliners <- get_gutenberg_corpus(2814) |>    load_texts(lemma = TRUE, pos = TRUE)  corpus_dubliners #> # A tibble: 67,885 × 7 #>    doc_id title     author       part        word  pos   lemma #>     <int> <chr>     <chr>        <chr>       <chr> <chr> <chr> #>  1   2814 Dubliners Joyce, James THE SISTERS there EX    there #>  2   2814 Dubliners Joyce, James THE SISTERS was   VBD   be    #>  3   2814 Dubliners Joyce, James THE SISTERS no    DT    no    #>  4   2814 Dubliners Joyce, James THE SISTERS hope  NN    hope  #>  5   2814 Dubliners Joyce, James THE SISTERS for   IN    for   #>  6   2814 Dubliners Joyce, James THE SISTERS him   PRP   him   #>  7   2814 Dubliners Joyce, James THE SISTERS this  DT    this  #>  8   2814 Dubliners Joyce, James THE SISTERS time  NN    time  #>  9   2814 Dubliners Joyce, James THE SISTERS it    PRP   it    #> 10   2814 Dubliners Joyce, James THE SISTERS was   VBD   be    #> # ℹ 67,875 more rows corpus_dubliners <- corpus_dubliners |>    identify_by(part)  corpus_dubliners #> # A tibble: 67,885 × 7 #>    doc_id      title     author       part        word  pos   lemma #>    <fct>       <chr>     <chr>        <chr>       <chr> <chr> <chr> #>  1 THE SISTERS Dubliners Joyce, James THE SISTERS there EX    there #>  2 THE SISTERS Dubliners Joyce, James THE SISTERS was   VBD   be    #>  3 THE SISTERS Dubliners Joyce, James THE SISTERS no    DT    no    #>  4 THE SISTERS Dubliners Joyce, James THE SISTERS hope  NN    hope  #>  5 THE SISTERS Dubliners Joyce, James THE SISTERS for   IN    for   #>  6 THE SISTERS Dubliners Joyce, James THE SISTERS him   PRP   him   #>  7 THE SISTERS Dubliners Joyce, James THE SISTERS this  DT    this  #>  8 THE SISTERS Dubliners Joyce, James THE SISTERS time  NN    time  #>  9 THE SISTERS Dubliners Joyce, James THE SISTERS it    PRP   it    #> 10 THE SISTERS Dubliners Joyce, James THE SISTERS was   VBD   be    #> # ℹ 67,875 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"standardize-titles","dir":"Articles","previous_headings":"Preparing texts","what":"Standardize titles","title":"Introduction to tmtyro","text":"standardize_titles() function converts titles something cleaner adopting title case.","code":"before <- unique(corpus_dubliners$doc_id)  corpus_dubliners <- corpus_dubliners |>    standardize_titles()  after <- unique(corpus_dubliners$doc_id)  data.frame(before, after) #>                           before                         after #> 1                    THE SISTERS                   The Sisters #> 2                   AN ENCOUNTER                  An Encounter #> 3                          ARABY                         Araby #> 4                        EVELINE                       Eveline #> 5                 AFTER THE RACE                After the Race #> 6                   TWO GALLANTS                  Two Gallants #> 7             THE BOARDING HOUSE            The Boarding House #> 8                 A LITTLE CLOUD                A Little Cloud #> 9                   COUNTERPARTS                  Counterparts #> 10                          CLAY                          Clay #> 11                A PAINFUL CASE                A Painful Case #> 12 IVY DAY IN THE COMMITTEE ROOM Ivy Day in the Committee Room #> 13                      A MOTHER                      A Mother #> 14                         GRACE                         Grace #> 15                      THE DEAD                      The Dead"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"studying-texts","dir":"Articles","previous_headings":"","what":"Studying texts","title":"Introduction to tmtyro","text":"functions studying texts follow predictable naming convention: add_vocabulary() adds columns measuring lexical variety texts. add_sentiment() adds column sentiment identifiers chosen lexicon. add_ngrams() adds columns words bigrams, trigrams, . every method preserves size shape data passed : summarize_tf_idf() returns data frame every token document corpus, columns indicating weights term frequency-inverse document frequency. Along , functions assist process: drop_na() drops rows missing data column specified columns. combine_ngrams() combines multiple columns n-grams one. separate_ngrams() separatesa single column n-grams one column per word.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"vocabulary-richness","dir":"Articles","previous_headings":"Studying texts","what":"Vocabulary richness","title":"Introduction to tmtyro","text":"add_vocabulary() function adds measurements vocabulary richness, including cumulative vocabulary size, indicators hapax legomena, markers progress.","code":"vocab_dubliners <-    corpus_dubliners |>    add_vocabulary()  vocab_dubliners #> # A tibble: 67,885 × 14 #>    doc_id   title author part  word  pos   lemma new_word hapax vocabulary   ttr #>    <fct>    <chr> <chr>  <chr> <chr> <chr> <chr> <lgl>    <lgl>      <int> <dbl> #>  1 The Sis… Dubl… Joyce… THE … there EX    there TRUE     FALSE          1   1   #>  2 The Sis… Dubl… Joyce… THE … was   VBD   be    TRUE     FALSE          2   1   #>  3 The Sis… Dubl… Joyce… THE … no    DT    no    TRUE     FALSE          3   1   #>  4 The Sis… Dubl… Joyce… THE … hope  NN    hope  TRUE     TRUE           4   1   #>  5 The Sis… Dubl… Joyce… THE … for   IN    for   TRUE     FALSE          5   1   #>  6 The Sis… Dubl… Joyce… THE … him   PRP   him   TRUE     FALSE          6   1   #>  7 The Sis… Dubl… Joyce… THE … this  DT    this  TRUE     FALSE          7   1   #>  8 The Sis… Dubl… Joyce… THE … time  NN    time  TRUE     FALSE          8   1   #>  9 The Sis… Dubl… Joyce… THE … it    PRP   it    TRUE     FALSE          9   1   #> 10 The Sis… Dubl… Joyce… THE … was   VBD   be    FALSE    FALSE          9   0.9 #> # ℹ 67,875 more rows #> # ℹ 3 more variables: htr <dbl>, progress_words <int>, progress_percent <dbl>"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"sentiment","dir":"Articles","previous_headings":"Studying texts","what":"Sentiment","title":"Introduction to tmtyro","text":"add_sentiment() adds measurements sentiment using “Bing” lexicon default.","code":"sentiment_dubliners <- corpus_dubliners |>    add_sentiment()  sentiment_dubliners #> # A tibble: 67,946 × 5 #>    title     author       doc_id      word  sentiment #>    <chr>     <chr>        <fct>       <chr> <chr>     #>  1 Dubliners Joyce, James The Sisters there NA        #>  2 Dubliners Joyce, James The Sisters was   NA        #>  3 Dubliners Joyce, James The Sisters no    NA        #>  4 Dubliners Joyce, James The Sisters hope  NA        #>  5 Dubliners Joyce, James The Sisters for   NA        #>  6 Dubliners Joyce, James The Sisters him   NA        #>  7 Dubliners Joyce, James The Sisters this  NA        #>  8 Dubliners Joyce, James The Sisters time  NA        #>  9 Dubliners Joyce, James The Sisters it    NA        #> 10 Dubliners Joyce, James The Sisters was   NA        #> # ℹ 67,936 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"dropping-empty-rows","dir":"Articles","previous_headings":"Studying texts > Sentiment","what":"Dropping empty rows","title":"Introduction to tmtyro","text":"Since many words may found given sentiment lexicon, drop_na() makes easy remove empty rows.","code":"sentiment_dubliners |>    drop_na(sentiment) #> # A tibble: 3,868 × 5 #>    title     author       doc_id      word      sentiment #>    <chr>     <chr>        <fct>       <chr>     <chr>     #>  1 Dubliners Joyce, James The Sisters evenly    positive  #>  2 Dubliners Joyce, James The Sisters dead      negative  #>  3 Dubliners Joyce, James The Sisters darkened  negative  #>  4 Dubliners Joyce, James The Sisters blind     negative  #>  5 Dubliners Joyce, James The Sisters idle      negative  #>  6 Dubliners Joyce, James The Sisters strangely negative  #>  7 Dubliners Joyce, James The Sisters like      positive  #>  8 Dubliners Joyce, James The Sisters like      positive  #>  9 Dubliners Joyce, James The Sisters sinful    negative  #> 10 Dubliners Joyce, James The Sisters fear      negative  #> # ℹ 3,858 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"choosing-a-sentiment-lexicon","dir":"Articles","previous_headings":"Studying texts > Sentiment","what":"Choosing a sentiment lexicon","title":"Introduction to tmtyro","text":"lexicon can chosen measurement.","code":"sentiment_ulysses <- ulysses |>    load_texts() |>    identify_by(section) |>    add_sentiment(lexicon = \"nrc\")  sentiment_ulysses |>    drop_na(sentiment) #> # A tibble: 63,006 × 6 #>    title   author       part  doc_id word    sentiment    #>    <chr>   <chr>        <chr> <fct>  <chr>   <chr>        #>  1 Ulysses Joyce, James — I — [ 1 ]  stately positive     #>  2 Ulysses Joyce, James — I — [ 1 ]  plump   anticipation #>  3 Ulysses Joyce, James — I — [ 1 ]  buck    fear         #>  4 Ulysses Joyce, James — I — [ 1 ]  buck    negative     #>  5 Ulysses Joyce, James — I — [ 1 ]  buck    positive     #>  6 Ulysses Joyce, James — I — [ 1 ]  buck    surprise     #>  7 Ulysses Joyce, James — I — [ 1 ]  razor   fear         #>  8 Ulysses Joyce, James — I — [ 1 ]  dark    sadness      #>  9 Ulysses Joyce, James — I — [ 1 ]  fearful fear         #> 10 Ulysses Joyce, James — I — [ 1 ]  fearful negative     #> # ℹ 62,996 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"n-grams","dir":"Articles","previous_headings":"Studying texts","what":"N-grams","title":"Introduction to tmtyro","text":"Following pattern, add_ngrams() adds columns n-length phrases words. default, prepares bigrams (2-grams). n-grams can chosen passing vector numbers.","code":"corpus_joyce <- joyce |>    load_texts() |>    identify_by(title)  bigrams_joyce <- corpus_joyce |>    add_ngrams()  bigrams_joyce #> # A tibble: 417,846 × 7 #>    doc_id    title     author       part        section word_1 word_2 #>    <fct>     <chr>     <chr>        <chr>       <chr>   <chr>  <chr>  #>  1 Dubliners Dubliners Joyce, James THE SISTERS NA      there  was    #>  2 Dubliners Dubliners Joyce, James THE SISTERS NA      was    no     #>  3 Dubliners Dubliners Joyce, James THE SISTERS NA      no     hope   #>  4 Dubliners Dubliners Joyce, James THE SISTERS NA      hope   for    #>  5 Dubliners Dubliners Joyce, James THE SISTERS NA      for    him    #>  6 Dubliners Dubliners Joyce, James THE SISTERS NA      him    this   #>  7 Dubliners Dubliners Joyce, James THE SISTERS NA      this   time   #>  8 Dubliners Dubliners Joyce, James THE SISTERS NA      time   it     #>  9 Dubliners Dubliners Joyce, James THE SISTERS NA      it     was    #> 10 Dubliners Dubliners Joyce, James THE SISTERS NA      was    the    #> # ℹ 417,836 more rows trigrams_joyce <- corpus_joyce |>    add_ngrams(1:3)  trigrams_joyce #> # A tibble: 417,846 × 8 #>    doc_id    title     author       part        section word_1 word_2 word_3 #>    <fct>     <chr>     <chr>        <chr>       <chr>   <chr>  <chr>  <chr>  #>  1 Dubliners Dubliners Joyce, James THE SISTERS NA      there  was    no     #>  2 Dubliners Dubliners Joyce, James THE SISTERS NA      was    no     hope   #>  3 Dubliners Dubliners Joyce, James THE SISTERS NA      no     hope   for    #>  4 Dubliners Dubliners Joyce, James THE SISTERS NA      hope   for    him    #>  5 Dubliners Dubliners Joyce, James THE SISTERS NA      for    him    this   #>  6 Dubliners Dubliners Joyce, James THE SISTERS NA      him    this   time   #>  7 Dubliners Dubliners Joyce, James THE SISTERS NA      this   time   it     #>  8 Dubliners Dubliners Joyce, James THE SISTERS NA      time   it     was    #>  9 Dubliners Dubliners Joyce, James THE SISTERS NA      it     was    the    #> 10 Dubliners Dubliners Joyce, James THE SISTERS NA      was    the    third  #> # ℹ 417,836 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"tf-idf","dir":"Articles","previous_headings":"Studying texts","what":"Tf-idf","title":"Introduction to tmtyro","text":"Unlike measurements, term frequency–inverse document frequency doesn’t preserve word order, reduces documents one instance token. Since use tf-idf can’t merely add column, summarize_tf_idf() avoids add_ naming convention. Results returned descending strength tf-idf. Tf-idf’s method understandably emphasizes proper nouns unique document. remove_names argument load_texts() can help filter words appear capitalized form. Removing names Dubliners makes noticeable difference tf-idf results: load_texts() used pos = TRUE, proper nouns can filtered, tags sometimes inaccurate.","code":"tfidf_dubliners <- corpus_dubliners |>    summarize_tf_idf()  tfidf_dubliners #> # A tibble: 17,656 × 6 #>    doc_id                        word         n      tf   idf tf_idf #>    <fct>                         <chr>    <int>   <dbl> <dbl>  <dbl> #>  1 Clay                          maria       40 0.0151   2.71 0.0409 #>  2 Two Gallants                  corley      46 0.0117   2.71 0.0318 #>  3 After the Race                jimmy       24 0.0107   2.71 0.0291 #>  4 Ivy Day in the Committee Room henchy      53 0.0101   2.71 0.0272 #>  5 A Little Cloud                gallaher    48 0.00964  2.71 0.0261 #>  6 The Dead                      gabriel    142 0.00906  2.71 0.0245 #>  7 Grace                         kernan      66 0.00873  2.71 0.0236 #>  8 Ivy Day in the Committee Room o’connor    45 0.00854  2.71 0.0231 #>  9 A Little Cloud                chandler    41 0.00823  2.71 0.0223 #> 10 A Mother                      kearney     50 0.0110   2.01 0.0223 #> # ℹ 17,646 more rows tfidf_dubliners <- get_gutenberg_corpus(2814) |>    load_texts(remove_names = TRUE) |>    identify_by(part) |>    standardize_titles() |>    summarize_tf_idf()  tfidf_dubliners #> # A tibble: 16,721 × 6 #>    doc_id         word         n      tf   idf  tf_idf #>    <fct>          <chr>    <int>   <dbl> <dbl>   <dbl> #>  1 The Dead       aunt       101 0.00693 1.61  0.0112  #>  2 Araby          bazaar       9 0.00406 2.71  0.0110  #>  3 The Sisters    aunt        19 0.00649 1.61  0.0104  #>  4 After the Race cars         6 0.00286 2.71  0.00773 #>  5 An Encounter   we          58 0.0189  0.405 0.00767 #>  6 After the Race car         11 0.00524 1.32  0.00692 #>  7 Eveline        avenue       4 0.00225 2.71  0.00610 #>  8 Counterparts   weathers    11 0.00283 2.01  0.00570 #>  9 Counterparts   pa           8 0.00206 2.71  0.00557 #> 10 The Sisters    snuff        6 0.00205 2.71  0.00555 #> # ℹ 16,711 more rows"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"preparing-tables","dir":"Articles","previous_headings":"","what":"Preparing tables","title":"Introduction to tmtyro","text":"tabulize() function prepares tables every kind measurement. repetition makes easy see appreciate findings without struggling recall specialized function.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"corpus-details","dir":"Articles","previous_headings":"Preparing tables","what":"Corpus details","title":"Introduction to tmtyro","text":"default, tabulize() prepares table showing lengths document.","code":"corpus_joyce |>    tabulize()"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"word-counts","dir":"Articles","previous_headings":"Preparing tables","what":"Word counts","title":"Introduction to tmtyro","text":"Adding count = TRUE show counts -frequent words.","code":"corpus_joyce |>    tabulize(count = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"vocabulary-richness-1","dir":"Articles","previous_headings":"Preparing tables","what":"Vocabulary richness","title":"Introduction to tmtyro","text":"used add_vocabulary(), tabulize() function prepares clean summary table.","code":"corpus_joyce |>    add_vocabulary() |>    tabulize()"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"sentiment-1","dir":"Articles","previous_headings":"Preparing tables","what":"Sentiment","title":"Introduction to tmtyro","text":"sentiment analysis, tabulize() returns summary figures document. Setting drop_na = TRUE removes rows without sentiment measure. ignore parameter aids selecting subset sentiments, converting rest NA.","code":"# dplyr is used here to choose a smaller example for comparison sentiment_dubliners_part <- sentiment_dubliners |>    dplyr::filter(doc_id %in% c(\"The Sisters\", \"An Encounter\",  \"Araby\"))  sentiment_dubliners_part |>    tabulize() sentiment_dubliners_part |>    tabulize(drop_na = TRUE) # dplyr is used here to choose a smaller example for comparison sentiment_ulysses_part <- sentiment_ulysses |>    dplyr::filter(doc_id %in% c(\"[ 1 ]\", \"[ 2 ]\", \"[ 3 ]\"))  sentiment_ulysses_part |>    tabulize(ignore = c(\"anger\", \"anticipation\", \"disgust\", \"fear\", \"trust\", \"positive\", \"negative\"))"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"n-grams-1","dir":"Articles","previous_headings":"Preparing tables","what":"N-grams","title":"Introduction to tmtyro","text":"add_ngrams(), tabulize() function returns top n-grams per document. default, first six shown group, rows can chosen freely.","code":"bigrams_joyce |>    tabulize(rows = 1:2)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"tf-idf-1","dir":"Articles","previous_headings":"Preparing tables","what":"Tf-idf","title":"Introduction to tmtyro","text":"data frames prepared summarize_tf_idf(), tabulize() function returns six rows top-scoring words document. amount can specified rows argument.","code":"tfidf_dubliners |>    tabulize(rows = 1:3)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"preparing-figures","dir":"Articles","previous_headings":"","what":"Preparing figures","title":"Introduction to tmtyro","text":"tmtyro provides many functions preparing figures, one typically needed: visualize() works intuitively tmtyro objects, preparing figures suited whatever work done. Customization easy: change_colors() provides single interface modifying filled colored layers.","code":""},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"corpus-details-1","dir":"Articles","previous_headings":"Preparing figures","what":"Corpus details","title":"Introduction to tmtyro","text":"default, visualize() prepares figure showing lengths document.","code":"corpus_joyce |>    visualize(inorder = FALSE)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"word-counts-1","dir":"Articles","previous_headings":"Preparing figures","what":"Word counts","title":"Introduction to tmtyro","text":"Adding count = TRUE show counts -frequent words.","code":"corpus_joyce |>    visualize(count = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"vocabulary-richness-2","dir":"Articles","previous_headings":"Preparing figures","what":"Vocabulary richness","title":"Introduction to tmtyro","text":"used add_vocabulary(), visualize() function charts document length number unique tokens. figure like useful compare documents rate vocabulary growth.  features, type-token ratio (“ttr”), hapax-token ratio (“htr”), sampling hapax legomena (“hapax”) can also shown.","code":"corpus_dubliners |>    add_vocabulary() |>    visualize() vocab_dubliners |>    visualize(\"ttr\") corpus_joyce |>    add_vocabulary() |>    visualize(\"hapax\")"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"sentiment-2","dir":"Articles","previous_headings":"Preparing figures","what":"Sentiment","title":"Introduction to tmtyro","text":"sentiment analysis, visualize() allows comparison among documents set.  ignore parameter stipulates values remove Y-axis focus figure.","code":"sentiment_dubliners |>    visualize() sentiment_ulysses |>    visualize(ignore = c(\"anger\", \"anticipation\", \"disgust\", \"fear\", \"trust\", \"positive\", \"negative\"))"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"n-grams-2","dir":"Articles","previous_headings":"Preparing figures","what":"N-grams","title":"Introduction to tmtyro","text":"n-grams, visualize() typically returns network visualization inspired bigram network Text Mining R.","code":"bigrams_joyce |>    visualize()"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"combining-n-grams","dir":"Articles","previous_headings":"Preparing figures","what":"Combining n-grams","title":"Introduction to tmtyro","text":"N-gram frequencies can compared combining visualization. Certain arguments allow deviation typical charts, including choosing rows chart modifying colors set values Y-axis.","code":"bigrams_joyce |>    dplyr::filter(word_1 == \"he\") |>    combine_ngrams() |>    visualize(rows = 1:5, color_y = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"tf-idf-2","dir":"Articles","previous_headings":"Preparing figures","what":"Tf-idf","title":"Introduction to tmtyro","text":"visualize() function returns bars showing top words document. can useful way differentiate texts set . tfidf_dubliners prepared load_texts(remove_names = TRUE), resulting chart shows clearer delineation topics characteristic stories Joyce’s collection:","code":"tfidf_dubliners |>    visualize(rows = 1:4)"},{"path":"https://jmclawson.github.io/tmtyro/articles/tmtyro.html","id":"changing-colors","dir":"Articles","previous_headings":"Preparing figures","what":"Changing colors","title":"Introduction to tmtyro","text":"change_colors() function name implies. default, adopts “Dark2” palette Brewer.  Colors can chosen manually.  Optionally, use named vector set colors value instead order.  choose predetermined color set palette, described function documentation.","code":"sentiment_dubliners |>    visualize() |>    change_colors() library(ggraph) #> Loading required package: ggplot2 bigrams_joyce |>    visualize(top_n = 60) |>    change_colors(c(\"#555555\", \"blue\")) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale. bigrams_joyce |>    dplyr::filter(word_1 == \"he\") |>    combine_ngrams() |>    visualize(rows = 1:5, color_y = TRUE) |>    change_colors(c(rep(\"#555555\",5),                   \"he is\" = \"blue\",                    \"he has\" = \"navy\")) tfidf_dubliners |>    visualize(rows = 1:4) |>    change_colors(colorset = \"viridis\", palette = \"mako\", direction = -1)"},{"path":"https://jmclawson.github.io/tmtyro/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James Clawson. Author, maintainer.","code":""},{"path":"https://jmclawson.github.io/tmtyro/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Clawson J (2024). tmtyro: tmtyro: Simplified Workflows Text Mining Tyros. R package version 0.2.0, https://jmclawson.github.io/tmtyro/, https://github.com/jmclawson/tmtyro.","code":"@Manual{,   title = {tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros},   author = {James Clawson},   year = {2024},   note = {R package version 0.2.0, https://jmclawson.github.io/tmtyro/},   url = {https://github.com/jmclawson/tmtyro}, }"},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"tmtyro-","dir":"","previous_headings":"","what":"tmtyro: Simplified Workflows for Text Mining Tyros","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"tmtyro designed help beginners work analyze text simple complex features. Adopting tidytext principles, tmtyro abstracts processes levels allow tyros apply text mining techniques ’re deeply familiar R code.","code":""},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"can install development version tmtyro GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"jmclawson/tmtyro\")"},{"path":"https://jmclawson.github.io/tmtyro/index.html","id":"use","dir":"","previous_headings":"","what":"Use","title":"tmtyro: Simplified Workflows for Text Mining Tyros","text":"’re ready, begin introduction, start using package right away load texts directory, measure sentiment, visualize results:","code":"library(tmtyro)  mysteries <- load_texts(\"mycorpus\")  mysteries <- add_sentiment(mysteries)  visualize(mysteries)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":null,"dir":"Reference","previous_headings":"","what":"Add values from a dictionary — add_dictionary","title":"Add values from a dictionary — add_dictionary","text":"Add values dictionary","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add values from a dictionary — add_dictionary","text":"","code":"add_dictionary(df, dictionary, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add values from a dictionary — add_dictionary","text":"df tidy data frame, potentially containing column called \"word\" dictionary data frame two columns, potentially made make_dictionary() function feature column (like \"word\") use looking values dictionary","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add values from a dictionary — add_dictionary","text":"original data frame one columns added.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_dictionary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add values from a dictionary — add_dictionary","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  my_sentiments <- make_dictionary(   list(     \"😊\" = c(\"happy\", \"joy\", \"smile\"),     \"😔\" = c(\"unhappy\", \"sad\", \"frown\")),   identifier = \"emoji\")  dubliners |>    add_dictionary(my_sentiments) |>    drop_na() |>    head() #> # A tibble: 6 × 6 #>   doc_id       title     author       part         word    emoji #>   <fct>        <chr>     <chr>        <chr>        <chr>   <chr> #> 1 The Sisters  Dubliners Joyce, James THE SISTERS  smile   😊    #> 2 The Sisters  Dubliners Joyce, James THE SISTERS  smile   😊    #> 3 An Encounter Dubliners Joyce, James AN ENCOUNTER happy   😊    #> 4 Araby        Dubliners Joyce, James ARABY        smile   😊    #> 5 Eveline      Dubliners Joyce, James EVELINE      happy   😊    #> 6 Eveline      Dubliners Joyce, James EVELINE      unhappy 😔"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Add ngram columns — add_ngrams","title":"Add ngram columns — add_ngrams","text":"Add ngram columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add ngram columns — add_ngrams","text":"","code":"add_ngrams(   df,   n = 1:2,   feature = word,   keep = FALSE,   collapse = FALSE,   by = doc_id )"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add ngram columns — add_ngrams","text":"df tidy data frame, potentially containing column called \"word\" n range defining extent ngram---instance, word 1 word 3. Alternatively, single number signal number words include ngram. Default value 1:2 produce bigrams. feature feature use constructing ngrams keep Whether keep original feature column collapse Whether join ngram parts single column called \"ngram\" grouping column identifying document, doc_id.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add ngram columns — add_ngrams","text":"original data frame columns added subsequent parts ngrams","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/add_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add ngram columns — add_ngrams","text":"","code":"if (FALSE) {   my_corpus <- load_texts()    my_bigrams <- my_corpus |>     add_ngrams(3) }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_ngrams(2) |>   head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word_1 word_2 #>   <fct>       <chr>     <chr>        <chr>       <chr>  <chr>  #> 1 The Sisters Dubliners Joyce, James THE SISTERS there  was    #> 2 The Sisters Dubliners Joyce, James THE SISTERS was    no     #> 3 The Sisters Dubliners Joyce, James THE SISTERS no     hope   #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope   for    #> 5 The Sisters Dubliners Joyce, James THE SISTERS for    him    #> 6 The Sisters Dubliners Joyce, James THE SISTERS him    this"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":null,"dir":"Reference","previous_headings":"","what":"Divide documents in equal lengths — add_partitions","title":"Divide documents in equal lengths — add_partitions","text":"Divide documents equal lengths","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Divide documents in equal lengths — add_partitions","text":"","code":"add_partitions(df, length = 1000, by = doc_id)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Divide documents in equal lengths — add_partitions","text":"df tidy data frame, potentially containing column called \"word\" length Size partition column containing document grouping","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Divide documents in equal lengths — add_partitions","text":"original data frame column added partition.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_partitions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Divide documents in equal lengths — add_partitions","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_partitions() |>   head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word  partition #>   <fct>       <chr>     <chr>        <chr>       <chr>     <dbl> #> 1 The Sisters Dubliners Joyce, James THE SISTERS there         1 #> 2 The Sisters Dubliners Joyce, James THE SISTERS was           1 #> 3 The Sisters Dubliners Joyce, James THE SISTERS no            1 #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope          1 #> 5 The Sisters Dubliners Joyce, James THE SISTERS for           1 #> 6 The Sisters Dubliners Joyce, James THE SISTERS him           1"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Add sentiment markers — add_sentiment","title":"Add sentiment markers — add_sentiment","text":"add_sentiment() provides simple lexicon-based measures sentiment, comparing words text one number controlled dictionaries.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add sentiment markers — add_sentiment","text":"","code":"add_sentiment(   df,   lexicon = c(\"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\"),   feature = word )"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add sentiment markers — add_sentiment","text":"df tidy data frame, potentially containing column called \"word\" lexicon sentiment lexicon use tidytext package. Options include \"bing\", \"afinn\", \"loughran\", \"nrc\", \"nrc_eil\", \"nrc_vad\". feature column words containing one word per row, used dictionary look-.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add sentiment markers — add_sentiment","text":"original data frame one sentiment columns added.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_sentiment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add sentiment markers — add_sentiment","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>    add_sentiment() |>    drop_na() |>    head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word      sentiment #>   <fct>       <chr>     <chr>        <chr>       <chr>     <chr>     #> 1 The Sisters Dubliners Joyce, James THE SISTERS evenly    positive  #> 2 The Sisters Dubliners Joyce, James THE SISTERS dead      negative  #> 3 The Sisters Dubliners Joyce, James THE SISTERS darkened  negative  #> 4 The Sisters Dubliners Joyce, James THE SISTERS blind     negative  #> 5 The Sisters Dubliners Joyce, James THE SISTERS idle      negative  #> 6 The Sisters Dubliners Joyce, James THE SISTERS strangely negative"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Measure lexical variety — add_vocabulary","title":"Measure lexical variety — add_vocabulary","text":"add_vocabulary() augments tidy text table columns describing lexical variety corpus. Among things, checks uniqueness size vocabulary, additional ratios reporting measurements relation document size.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Measure lexical variety — add_vocabulary","text":"","code":"add_vocabulary(df, by = doc_id, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Measure lexical variety — add_vocabulary","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" grouping column feature column words containing one word per row","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Measure lexical variety — add_vocabulary","text":"data frame 7 added columns , first two logical rest numeric: new_word (logical) Indicates whether first instance given word hapax (logical) Indicates whether word incident given word, hapax legomenon vocabulary (integer) Running count words used ttr (double) Type-token ratio, derived running count words divided total number words used htr (double) Hapax-token ratio, derived running count hapax legomena divided total number words used progress_words (integer) Running count total words used far document progress_percent (double) Words used far percentage total number words used document","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/add_vocabulary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Measure lexical variety — add_vocabulary","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>    add_vocabulary() |>    head() #> # A tibble: 6 × 12 #>   doc_id      title     author part  word  new_word hapax vocabulary   ttr   htr #>   <fct>       <chr>     <chr>  <chr> <chr> <lgl>    <lgl>      <int> <dbl> <dbl> #> 1 The Sisters Dubliners Joyce… THE … there TRUE     FALSE          1     1 0     #> 2 The Sisters Dubliners Joyce… THE … was   TRUE     FALSE          2     1 0     #> 3 The Sisters Dubliners Joyce… THE … no    TRUE     FALSE          3     1 0     #> 4 The Sisters Dubliners Joyce… THE … hope  TRUE     TRUE           4     1 0.25  #> 5 The Sisters Dubliners Joyce… THE … for   TRUE     FALSE          5     1 0.2   #> 6 The Sisters Dubliners Joyce… THE … him   TRUE     FALSE          6     1 0.167 #> # ℹ 2 more variables: progress_words <int>, progress_percent <dbl>"},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose other colors — change_colors","title":"Choose other colors — change_colors","text":"change_colors() standardizes three methods choosing color palettes color fill mapping, providing access Brewer Viridis palettes alongside custom choices.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose other colors — change_colors","text":"","code":"change_colors(   x,   colorset = \"brewer\",   palette = 2,   kind = \"qualitative\",   direction = 1,   start = 1 )"},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choose other colors — change_colors","text":"x visualization made visualize() colorset Either \"brewer\", \"viridis\", \"okabe-ito\", \"dubois\", vector colors. palette number name palette (dependent setting colorset either \"brewer\" \"viridis\") kind Used Brewer palettes match numbered palette specific subset direction direction colors applied data. Setting anything 1 reverse order. start Useful predefined colorsets Okabe-Ito Brewer start color 1","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choose other colors — change_colors","text":"ggplot2 object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/change_colors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Choose other colors — change_colors","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  # Too many titles for categorical data. selected_titles <- dubliners$doc_id |>   {\\(x) x[grepl(\"^The |^A |^An \", x)]}() |>   unique()  dubliners2 <- dubliners |>   dplyr::filter(doc_id %in% selected_titles)  ### CATEGORICAL DATA ##  # By default, ggplot2's palette is applied dubliners2 |>   visualize()   # change_color() starts with Brewer's \"Dark2\" palette dubliners2 |>   visualize() |>   change_colors()   # Other color sets and palettes can be chosen dubliners2 |>   visualize() |>   change_colors(colorset = \"okabe\")   dubliners2 |>   visualize() |>   change_colors(colorset = \"viridis\", palette = \"turbo\")   dubliners2 |>   visualize() |>   change_colors(colorset = \"brewer\", palette = \"Set1\")   # Named cases can be highlighted dubliners2 |>   visualize(inorder = FALSE) |>   change_colors(c(     rep(\"darkgray\", 6),     \"A Painful Case\" = \"blue\"))   ### SEQUENTIAL DATA ###  # By default, the \"viridis\" palette is applied dubliners2 |>   visualize(type = \"heatmap\")   # change_colors()  starts with Brewer's \"BuGn\" palette dubliners2 |>   visualize(type = \"heatmap\") |>   change_colors() #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.   # Palettes can be numbered or named dubliners2 |>   visualize(type = \"heatmap\") |>   change_colors(\"viridis\", palette = 6) #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.   dubliners2 |>   visualize(type = \"heatmap\") |>   change_colors(\"viridis\", palette = \"mako\") #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.   ### POINT DATA ###  dubliners |>   add_ngrams() |>   visualize() |>   change_colors(\"orange\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"Collapse gt rows in the style of kableExtra — collapse_rows","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"Collapse gt rows style kableExtra","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"","code":"collapse_rows(df_g, col, lookleft = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"df_g gt table data object col column collapse lookleft Whether depend collapsing column one step left","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"gt table data object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/collapse_rows.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collapse gt rows in the style of kableExtra — collapse_rows","text":"","code":"library(gt) library(palmerpenguins) library(tmtyro)  penguins_gt <-   penguins |>   select(-year) |>   summarize(     across(       ends_with(\"_mm\"), mean, na.rm = TRUE),     .by = c(species, island, sex)) |>   gt() |>   fmt_number() |>   tab_spanner(     \"bill\",     columns = starts_with(\"bill_\")) |>   tab_spanner(     \"flipper\",     starts_with(\"flip\")) |>   cols_label(     bill_length_mm = \"length\",     bill_depth_mm = \"depth\",     flipper_length_mm = \"length\") |>   sub_missing()  penguins_gt |>   collapse_rows(species) |>   collapse_rows(island)"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine ngram columns — combine_ngrams","title":"Combine ngram columns — combine_ngrams","text":"Combine ngram columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine ngram columns — combine_ngrams","text":"","code":"combine_ngrams(df, feature = word, keep = FALSE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine ngram columns — combine_ngrams","text":"df tidy data frame, potentially containing columns called \"word_1\", \"word_2\", etc. feature column name prefix numbered columns ngrams keep Whether keep original columns called \"word_1\", \"word_2\", etc., alongside new \"ngram\" column.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine ngram columns — combine_ngrams","text":"data frame column called ngram","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/combine_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine ngram columns — combine_ngrams","text":"","code":"if (FALSE) {   my_corpus <- load_texts(n = 2)    my_bigrams <- my_corpus |>     add_ngrams(collapse = FALSE) |>     combine_ngrams() }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_ngrams(2) |>   combine_ngrams() |>   head() #> # A tibble: 6 × 5 #>   doc_id      title     author       part        ngram     #>   <fct>       <chr>     <chr>        <chr>       <chr>     #> 1 The Sisters Dubliners Joyce, James THE SISTERS there was #> 2 The Sisters Dubliners Joyce, James THE SISTERS was no    #> 3 The Sisters Dubliners Joyce, James THE SISTERS no hope   #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope for  #> 5 The Sisters Dubliners Joyce, James THE SISTERS for him   #> 6 The Sisters Dubliners Joyce, James THE SISTERS him this"},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":null,"dir":"Reference","previous_headings":"","what":"Count values in one or more columns — count","title":"Count values in one or more columns — count","text":"Count values one columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count values in one or more columns — count","text":"","code":"count(x, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count values in one or more columns — count","text":"x data frame ... columns count. one column chosen, combinations values counted.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count values in one or more columns — count","text":"data frame one column every grouping identified ... additional column number values counted","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count values in one or more columns — count","text":"","code":"mtcars |>   count(cyl) #>   cyl  n #> 1   4 11 #> 2   6  7 #> 3   8 14"},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a file once — download_once","title":"Download a file once — download_once","text":"download_once() checks local copy file found online. copy exist, downloads copy local use.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a file once — download_once","text":"","code":"download_once(url, filename = NULL, destdir = \"data\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a file once — download_once","text":"url URL online document. filename file name saved locally. many cases parameter necessary, since file name can automatically parsed URL, web addresses obscure . destdir destination directory save file. default, \"data/\" folder, created yet exist.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a file once — download_once","text":"Path local file, returned invisibly","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/download_once.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download a file once — download_once","text":"","code":"if (FALSE) { download_once(\"example.com/sample.csv\") }"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop rows containing missing values — drop_na","title":"Drop rows containing missing values — drop_na","text":"drop_na() drops rows column specified ... contains missing value.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop rows containing missing values — drop_na","text":"","code":"drop_na(data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop rows containing missing values — drop_na","text":"data data frame. ... <tidy-select> Columns inspect missing values. empty, columns used.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Drop rows containing missing values — drop_na","text":"Another way interpret drop_na() keeps \"complete\" rows (rows contain missing values). Internally, completeness computed vctrs::vec_detect_complete().","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Drop rows containing missing values — drop_na","text":"","code":"data.frame(   A = 1:3,   B = c(\"red\", NA, \"green\"),   C = c(TRUE, TRUE, TRUE)) |> drop_na() #>   A     B    C #> 1 1   red TRUE #> 2 3 green TRUE"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove stopwords — drop_stopwords","title":"Remove stopwords — drop_stopwords","text":"Remove stopwords","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove stopwords — drop_stopwords","text":"","code":"drop_stopwords(df, wordlist = NULL, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove stopwords — drop_stopwords","text":"df tidy data frame, potentially containing column called \"word\" wordlist list stopwords feature column words containing one word per row checked stopwords.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove stopwords — drop_stopwords","text":"original data frame fewer rows.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/drop_stopwords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove stopwords — drop_stopwords","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>    drop_stopwords() #> # A tibble: 34,242 × 5 #>    doc_id      title     author       part        word     #>    <fct>       <chr>     <chr>        <chr>       <chr>    #>  1 The Sisters Dubliners Joyce, James THE SISTERS hope     #>  2 The Sisters Dubliners Joyce, James THE SISTERS time     #>  3 The Sisters Dubliners Joyce, James THE SISTERS third    #>  4 The Sisters Dubliners Joyce, James THE SISTERS stroke   #>  5 The Sisters Dubliners Joyce, James THE SISTERS night    #>  6 The Sisters Dubliners Joyce, James THE SISTERS night    #>  7 The Sisters Dubliners Joyce, James THE SISTERS passed   #>  8 The Sisters Dubliners Joyce, James THE SISTERS house    #>  9 The Sisters Dubliners Joyce, James THE SISTERS vacation #> 10 The Sisters Dubliners Joyce, James THE SISTERS time     #> # ℹ 34,232 more rows"},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame from long tidy format to wider format — expand_documents","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"resulting data frame simpler form document feature matrix used packages. my_df |> expand_documents(percent = FALSE, sort = FALSE) compares my_df |> count(doc_id, word) |> tidytext::cast_dfm(doc_id, word, n), equivalent. latter prepares DFM used quanteda package.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"","code":"expand_documents(   df,   feature = word,   by = doc_id,   percent = TRUE,   sort = TRUE,   columns = NULL )"},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"df tidy data frame, potentially containing column called \"word\" feature column words containing one word per row, counted frequency column containing document grouping percent Whether frequencies converted percentages per-document basis sort Whether sort features frequency columns features keep","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"data frame one row per document many features words.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/expand_documents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame from long tidy format to wider format — expand_documents","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   expand_documents() #> # A tibble: 15 × 7,340 #>    doc_id         the    and     of     to      he      a     was     his   `in` #>    <fct>        <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 The Sisters 0.0549 0.0379 0.0222 0.0302 0.0180  0.0148 0.0180  0.0157  0.0173 #>  2 An Encount… 0.0556 0.0329 0.0273 0.0264 0.0310  0.0218 0.0181  0.0107  0.0129 #>  3 Araby       0.0810 0.0299 0.0273 0.0299 0.00682 0.0209 0.0171  0.00341 0.0175 #>  4 Eveline     0.0563 0.0251 0.0257 0.0371 0.0246  0.0218 0.0218  0.00601 0.0180 #>  5 After the … 0.0728 0.0299 0.0446 0.025  0.0196  0.0299 0.0268  0.0183  0.0214 #>  6 Two Gallan… 0.0548 0.0332 0.0334 0.0240 0.0416  0.0288 0.0143  0.0286  0.0120 #>  7 The Boardi… 0.0493 0.0316 0.0312 0.0312 0.0241  0.0273 0.0213  0.0174  0.0135 #>  8 A Little C… 0.0502 0.0356 0.0263 0.0247 0.0346  0.0206 0.0136  0.0261  0.0146 #>  9 Counterpar… 0.0761 0.0328 0.0275 0.0265 0.0335  0.0228 0.0187  0.0236  0.0163 #> 10 Clay        0.0594 0.0530 0.0229 0.0301 0.00978 0.0203 0.0259  0.00414 0.0117 #> 11 A Painful … 0.0665 0.0266 0.0352 0.0275 0.0398  0.0255 0.0137  0.0250  0.0190 #> 12 Ivy Day in… 0.0610 0.0242 0.0233 0.0212 0.0259  0.0274 0.00762 0.0160  0.0128 #> 13 A Mother    0.0619 0.0348 0.0227 0.0304 0.0170  0.0211 0.0227  0.0108  0.0152 #> 14 Grace       0.0643 0.0269 0.0299 0.0224 0.0235  0.0260 0.0178  0.0190  0.0150 #> 15 The Dead    0.0551 0.0362 0.0252 0.0234 0.0180  0.0216 0.0159  0.0160  0.0168 #> # ℹ 7,330 more variables: her <dbl>, had <dbl>, said <dbl>, that <dbl>, #> #   it <dbl>, with <dbl>, `for` <dbl>, him <dbl>, at <dbl>, on <dbl>, i <dbl>, #> #   she <dbl>, but <dbl>, as <dbl>, were <dbl>, when <dbl>, all <dbl>, #> #   you <dbl>, they <dbl>, not <dbl>, out <dbl>, up <dbl>, be <dbl>, by <dbl>, #> #   one <dbl>, from <dbl>, an <dbl>, would <dbl>, then <dbl>, little <dbl>, #> #   what <dbl>, no <dbl>, have <dbl>, there <dbl>, them <dbl>, which <dbl>, #> #   so <dbl>, could <dbl>, `if` <dbl>, into <dbl>, went <dbl>, asked <dbl>, …"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a corpus or corpora of texts — get_corpus","title":"Prepare a corpus or corpora of texts — get_corpus","text":"get_corpus() works nearly identically load_texts(), two fundamental differences. First, adds \"corpus\" column resulting table help record keeping. Second, adds option caching output local RDS file, saved project directory.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a corpus or corpora of texts — get_corpus","text":"","code":"get_corpus(   corpus,   name = \".txt\",   word = TRUE,   lemma = FALSE,   lemma_replace = FALSE,   to_lower = TRUE,   remove_names = FALSE,   pos = FALSE,   poetry = FALSE,   paragraph = TRUE,   cache = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a corpus or corpora of texts — get_corpus","text":"corpus Vector length, value either string identifying directory texts first part filename cached RDS file prepared tmtyro. name naming pattern search folder. Defaults \".txt\". word Whether split one word per line. Defaults TRUE. lemma Whether lemmatize text. word TRUE, adds new column called lemma. step can add lot time, defaults FALSE. lemma_replace lemma word TRUE, toggles whether replace word column lemmatized tokens. Defaults FALSE to_lower word TRUE, toggles whether convert words lowercase. Defaults TRUE. remove_names word TRUE, toggles whether remove words appear form initial capitals. Defaults FALSE. pos Whether add column part--speech tag. step can add lot time, defaults FALSE. poetry Whether detect indicate stanza breaks line breaks. Defaults FALSE. paragraph Whether detect paragraph breaks prose. Defaults TRUE. cache Whether save cached copy corpus. options like pos = TRUE lemma = TRUE can add significant time corpus preparation, setting cache = TRUE saves need repeat steps time corpus loaded. Defaults TRUE.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare a corpus or corpora of texts — get_corpus","text":"data frame columns corpus, doc_id, data.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare a corpus or corpora of texts — get_corpus","text":"","code":"if (FALSE) {   austen <- get_corpus(\"austen\")    shakespeare <- get_corpus(     c(\"comedy\",       \"history\",       \"tragedy\")) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"get_gutenberg_corpus() improves upon functionality gutenbergr::gutenberg_download() three key ways. First, default setting retrieve \".htm\" version texts parse headers. change allows consideration texts sections chapters. Parsing handled parse_html(), move_header_to_text() available correct parsing errors. Second, using \".txt\" format, get_gutenberg_corpus() rely presence \".zip\" files. change improves coverage files dramatically. Finally, caches copy files locally avoid need repeated downloads. change helps code portability, offline access, server bandwidth. changes made consideration server bandwidth, two-second delay introduced download attempt. slow initial acquisition corpora, offline caching speeds things considerably subsequent use.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"","code":"get_gutenberg_corpus(   gutenberg_id,   dir = \"gutenberg\",   mirror = NULL,   meta_fields = c(\"title\", \"author\"),   type = c(\"htm\", \"txt\"),   html_title = FALSE,   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"gutenberg_id vector ID numbers Project Gutenberg data frame containing gutenberg_id column, results call gutenbergr::gutenberg_works(). dir directory storing downloaded .txt files. Default value \"gutenberg\". mirror Optionally mirror URL retrieve books . default uses mirror gutenbergr::gutenberg_get_mirror(). meta_fields Additional fields add gutenbergr::gutenberg_metadata describing book. default, title author added. type Indicate whether corpus created plain text \"txt\" versions books (previously type) enhanced \"htm\" versions, attempt find markers chapters sections. html_title Whether use h1 header HTML file determine document's title. default, uses gutenbergr::gutenberg_metadata. ... Additional parameters passed along gutenbergr::gutenberg_strip().","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"data frame one row line texts corpus.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_gutenberg_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build and load a corpus from Project Gutenberg — get_gutenberg_corpus","text":"","code":"library(gutenbergr)  dalloway <- gutenberg_works(author == \"Woolf, Virginia\",                             title == \"Mrs Dalloway in Bond Street\") |>   get_gutenberg_corpus()"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a MICUSP corpus — get_micusp_corpus","title":"Get a MICUSP corpus — get_micusp_corpus","text":"function accepts filters columns micusp_metadata() downloads parses MICUSP (Michigan Corpus Upper-level Student Papers) texts locally copies yet exist. returns table combining metadata text data processing.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a MICUSP corpus — get_micusp_corpus","text":"","code":"get_micusp_corpus(...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a MICUSP corpus — get_micusp_corpus","text":"... filter rows columns micusp_metadata(). Accepted columns include following: paper_id, title, discipline, paper_type, student_level, sex, nativeness, textual_features.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a MICUSP corpus — get_micusp_corpus","text":"data frame 1 row document corpus 9 columns. first 8 columns contain metadata, final column called text contains full text document.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/get_micusp_corpus.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a MICUSP corpus — get_micusp_corpus","text":"","code":"if (FALSE) { physics_f <- get_micusp_corpus(discipline == \"Physics\", sex == \"Female\") physics_m <- get_micusp_corpus(discipline == \"Physics\", sex == \"Male\")  discipline_by_sex <-   micusp_metadata() |>   count(discipline, sex) |>   tidyr::pivot_wider(     names_from = \"sex\",     values_from = \"n\") |>   dplyr::mutate(     ratio_f = (Female) / (Male + Female)) |>     dplyr::arrange(ratio_f)   disciplines_low_f <-   discipline_by_sex |>   head(3) |>   dplyr::pull(discipline)   disciplines_low_m <-   discipline_by_sex |>   tail(3) |>   dplyr::pull(discipline)  low_representation_f <- get_micusp_corpus(   sex == \"Female\",   discipline %in% disciplines_low_f)   low_representation_m <- get_micusp_corpus(   sex == \"Male\",   discipline %in% disciplines_low_m) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":null,"dir":"Reference","previous_headings":"","what":"Choose a new doc_id column — identify_by","title":"Choose a new doc_id column — identify_by","text":"Choose new doc_id column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Choose a new doc_id column — identify_by","text":"","code":"identify_by(data, ..., inorder = TRUE, sep = \"_\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Choose a new doc_id column — identify_by","text":"data data frame, potentially doc_id column ... column columns become new identifier inorder Whether establish doc_id order shown document sep Separator values identifying multiple columns","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Choose a new doc_id column — identify_by","text":"data frame redefined doc_id column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/identify_by.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Choose a new doc_id column — identify_by","text":"","code":"if (FALSE) {   corpus |>     load_texts() |>     identify_by(author) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"Explore topics interactively — interactive_topic_distributions","title":"Explore topics interactively — interactive_topic_distributions","text":"interactive_topic_distributions() uses plotly prepare interactive visualization explore topic model, showing top \"n\" topics document. kind visualization use interactive IDE web page.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Explore topics interactively — interactive_topic_distributions","text":"","code":"interactive_topic_distributions(   lda,   top_n = 4,   title = FALSE,   height = NULL,   omit = NULL,   smooth = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Explore topics interactively — interactive_topic_distributions","text":"lda topic model used. top_n number topics visualize. default, top 4 topics document shown. title default, function add title chart, corresponding name object passed lda parameter. Set FALSE return chart title. height height resulting HTML widget. omit Upon exploration, topics may found contain common stop words unhelpful material. Use omit parameter define vector topic numbers wish omit visualization. smooth samples rejoined, measured value topic vary wildly, even samples beside document. can make charts distractingly jittery. default TRUE value parameter reduces chart noise calculating rolling averages across three samples. Set parameter FALSE skip step allow visualization extreme values.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Explore topics interactively — interactive_topic_distributions","text":"Interactive plotly object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/interactive_topic_distributions.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Explore topics interactively — interactive_topic_distributions","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  interactive_topic_distributions(austen_lda)"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a folder or data frame of texts — load_texts","title":"Load a folder or data frame of texts — load_texts","text":"load_texts() loads corpus folder texts data frame prepares study using tidytext principles. default, load_texts() add paragraph numbers (suitable prose), unnest word level, options exist change defaults poetry, avoid unnesting, even remove words seem like proper nouns apply techniques natural language processing lemmatizing words tagging parts speech.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a folder or data frame of texts — load_texts","text":"","code":"load_texts(   src = \"data\",   name = \".txt\",   word = TRUE,   lemma = FALSE,   lemma_replace = FALSE,   to_lower = TRUE,   remove_names = FALSE,   pos = FALSE,   poetry = FALSE,   paragraph = TRUE,   n = 1L )"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a folder or data frame of texts — load_texts","text":"src Either string identifying name directory containing texts data frame containing unnested column called \"text\" one column name ending \"_id\". Files either stored directory within project folder subdirectory called \"data\". Defaults \"data\" load texts directory. name naming pattern search folder. Defaults \".txt\". word Whether split one word per line. Defaults TRUE. lemma Whether lemmatize text. word TRUE, adds new column called lemma. step can add lot time, defaults FALSE. lemma_replace lemma word TRUE, toggles whether replace word column lemmatized tokens. Defaults FALSE to_lower word TRUE, toggles whether convert words lowercase. Defaults TRUE. remove_names word TRUE, toggles whether remove words appear form initial capitals. Defaults FALSE. pos Whether add column part--speech tag. step can add lot time, defaults FALSE. poetry Whether detect indicate stanza breaks line breaks. Defaults FALSE. paragraph Whether detect paragraph breaks prose. Defaults TRUE. n number words per row. default, load_texts() unnests text one word time using column called word. n value greater 1, load_texts() instead use tidytext::unnest_tokens() token = \"ngrams\" create column called ngram.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a folder or data frame of texts — load_texts","text":"data frame two five columns one row token (optionally, one row paragraph one row line) corpus.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a folder or data frame of texts — load_texts","text":"","code":"if (FALSE) { mysteries <-   load_texts(\"mystery-novels\")  dickinson <-   load_texts(\"dickinson-poems\",              poetry = TRUE)  # `load_texts()` can also be used with # a traditional tidytext workflow: mysteries <-   load_texts(\"mystery-novels\",              word = FALSE,              to_lower = FALSE) |>   tidytext::unnest_tokens(word, text) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Load (or cache and load) a topic model — load_topic_model","title":"Load (or cache and load) a topic model — load_topic_model","text":"load_topic_model() checks see whether cached topic model exists creating one make_topic_model() caching .","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load (or cache and load) a topic model — load_topic_model","text":"","code":"load_topic_model(df, k = 15, by = doc_id, sample_size = 1000, lda_name = NULL)"},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load (or cache and load) a topic model — load_topic_model","text":"df data frame nested text \"text\" column. k number topics search . default, 15 topics sought. column identifying document. default, \"title\" column used. sample_size sample size document chunk. default, samples include 1000 words. lda_name name use looking caching model \"data\" folder. default, value derived name data frame passed function, may helpful define explicitly intervening steps loading topic model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load (or cache and load) a topic model — load_topic_model","text":"topic model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/load_topic_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load (or cache and load) a topic model — load_topic_model","text":"","code":"if (FALSE) { mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   load_topic_model(k = 10)   }"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a lexicon — make_dictionary","title":"Create a lexicon — make_dictionary","text":"make_dictionary() creates dictionary use add_dictionary().","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a lexicon — make_dictionary","text":"","code":"make_dictionary(list, identifier = \"value\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a lexicon — make_dictionary","text":"list list named word vectors identifier kind dictionary","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a lexicon — make_dictionary","text":"data frame two columns, \"word\" ","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_dictionary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a lexicon — make_dictionary","text":"","code":"my_sentiments <- make_dictionary(   list(     \"😊\" = c(\"happy\", \"joy\", \"smile\"),     \"😔\" = c(\"unhappy\", \"sad\", \"frown\")),   identifier = \"emoji\")  border_states <- make_dictionary(   list(     \"Canada\" = c(       \"Alaska\", \"Washington\", \"Idaho\",       \"Montana\", \"North_Dakota\", \"Minnesota\",       \"Wisconsin\", \"Michigan\", \"Ohio\",       \"Pennsylvania\", \"New_York\", \"Vermont\",       \"New_Hampshire\", \"Maine\", \"AK\", \"WA\",       \"ID\", \"MT\", \"ND\", \"MN\", \"WI\", \"MI\",       \"OH\", \"PA\", \"NY\", \"VT\", \"NH\", \"ME\"),     \"Mexico\" = c(       \"California\", \"Arizona\", \"New_Mexico\",       \"Texas\", \"CA\", \"AZ\", \"NM\", \"TX\")),   identifier = \"borders\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a topic model — make_topic_model","title":"Construct a topic model — make_topic_model","text":"make_topic_model() moves table texts necessary steps preparation building topic model. function applies seven steps: identifies text divisions doc_id column divides texts -sized chunks sample_size words (default 1000 words) unnests text table table one word per row removes stop words proper nouns (identified word appears capitalized first letter) counts word frequencies chunk converts table frequencies document term matrix builds topic model k topics","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a topic model — make_topic_model","text":"","code":"make_topic_model(df, by = doc_id, sample_size = 1000, k = 15, cache = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a topic model — make_topic_model","text":"df data frame nested text \"text\" column. column identifying document. default, \"title\" column used. sample_size sample size document chunk. default, samples include 1000 words. k number topics search . default, 15 topics sought. cache Whether cache resulting model RDS file \"data/\" folder. Set TRUE default. Delete RDS file create new model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a topic model — make_topic_model","text":"topic model.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/make_topic_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a topic model — make_topic_model","text":"","code":"if (FALSE) { mysteries <- load_texts(\"mystery-novels\", word = FALSE)  mysteries_lda <- mysteries |>   make_topic_model(k = 10)   }"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Get MICUSP metadata — micusp_metadata","title":"Get MICUSP metadata — micusp_metadata","text":"Explore metadata available MICUSP (Michigan Corpus Upper-level Student Papers) texts choose corpus. first use, function creates folder working directory downloads \"micusp_metadata.csv\" file opening . Subsequent use function load local copy.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get MICUSP metadata — micusp_metadata","text":"","code":"micusp_metadata(micusp_dir = \"micusp\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get MICUSP metadata — micusp_metadata","text":"micusp_dir name directory storing local copies MICUSP materials. Defaults \"micusp/\".","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get MICUSP metadata — micusp_metadata","text":"data frame 1 row document corpus 8 columns metadata: paper_id, title, discipline, paper_type, student_level, sex, nativeness, textual_features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/micusp_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get MICUSP metadata — micusp_metadata","text":"","code":"if (FALSE) { micusp_metadata() |> head() }"},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Move a header column to text — move_header_to_text","title":"Move a header column to text — move_header_to_text","text":"texts, header tags particular level indicate typographical variance confused section tags. move_header_to_text() provides simple method adjust table.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Move a header column to text — move_header_to_text","text":"","code":"move_header_to_text(.data, column, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Move a header column to text — move_header_to_text","text":".data data frame column called text least one column indicating parts, chapters, sections. column header column move ... (optional) Filtering condition, title == \"Ulysses\".","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Move a header column to text — move_header_to_text","text":"data frame header column moved text, conditional ...","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/move_header_to_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Move a header column to text — move_header_to_text","text":"","code":"if (FALSE) {   joyce2 <- joyce |>     move_column_to_text(subsection, title == \"Ulysses\") }"},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":null,"dir":"Reference","previous_headings":"","what":"Read HTML headers and text from file — parse_html","title":"Read HTML headers and text from file — parse_html","text":"Read HTML headers text file","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read HTML headers and text from file — parse_html","text":"","code":"parse_html(html, title = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read HTML headers and text from file — parse_html","text":"html file HTML format title Whether keep H1 tags even one unique value","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read HTML headers and text from file — parse_html","text":"data frame column called text header columns called title, part, section, subsection needed. Header columns limited page elements tagged h1, h2, h3, h4.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/parse_html.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read HTML headers and text from file — parse_html","text":"","code":"if (FALSE) {   ulysses <- parse_html(\"4300.htm\") }"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize bigram chains — plot_bigrams","title":"Visualize bigram chains — plot_bigrams","text":"Visualize bigram chains","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize bigram chains — plot_bigrams","text":"","code":"plot_bigrams(   df,   feature = word,   random_seed = TRUE,   set_seed = NULL,   legend = FALSE,   top_n = 35 )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize bigram chains — plot_bigrams","text":"df tidy data frame potentially containing column called \"word\" columns called \"word_1\" \"word_2\". feature feature use constructing ngrams random_seed Whether randomize creation network chart. set_seed specific seed use random legend Whether show legend edge color top_n number pairs visualize","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize bigram chains — plot_bigrams","text":"ggplot2 object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_bigrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize bigram chains — plot_bigrams","text":"","code":"if (FALSE) { # It isn't necessary to use add_ngrams() df |>   plot_bigrams()  # Adding them first allows for filtering steps df |>   add_ngrams() |>   drop_stopwords(word_1) |>   drop_stopwords(word_2) |>   plot_bigrams()  # Only bigrams influence the visualization These show the same networks: df |>   add_ngrams() |>   plot_bigrams()  df |>   add_ngrams(4) |>   plot_bigrams()  }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   plot_bigrams()   # Loading `ggraph` enables edge to show connection strengths library(ggraph) #> Loading required package: ggplot2  dubliners |>   plot_bigrams()   dubliners |>   add_ngrams(2) |>   drop_stopwords(feature = word_1) |>   drop_stopwords(feature = word_2) |>   plot_bigrams()   dubliners |>   dplyr::filter(doc_id == \"The Dead\") |>   plot_bigrams(top_n = 70) |>   change_colors(c(\"black\", \"orange\")) #> Scale for edge_colour is already present. #> Adding another scale for edge_colour, which will replace the existing scale."},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bar graphs of frequent features — plot_doc_word_bars","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"Plot bar graphs frequent features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"","code":"plot_doc_word_bars(   df,   rows = 1:10,   by = doc_id,   feature = word,   inorder = TRUE,   reorder_y = NULL,   color_y = FALSE,   percents = TRUE,   label = FALSE,   label_tweak = 2,   label_inside = FALSE,   na_rm = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" rows features show column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" inorder Whether retain factor order \"\" column reorder_y Whether reorder Y-values facet color_y Whether bars filled Y-values percents Whether display word frequencies percentage instead raw counts label Whether show value label bar label_tweak numeric value tweak label, shown. percentages, value adjusts decimal-point precision. raw counts, value adjusts labels' offset bars label_inside Whether show value label inside bar na_rm Whether drop empty features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_bars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot bar graphs of frequent features — plot_doc_word_bars","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts(lemma = TRUE) |>   identify_by(part) |>   standardize_titles()  dubliners |>   plot_doc_word_bars(rows = 1:4)   dubliners |>   dplyr::filter(doc_id %in% c(\"The Sisters\", \"The Dead\")) |>   plot_doc_word_bars(feature = lemma, rows = 1:20)"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a heatmap of ranked features — plot_doc_word_heatmap","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"Plot heatmap ranked features","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"","code":"plot_doc_word_heatmap(   df,   rows = 1:10,   by = doc_id,   feature = word,   label = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" rows ranks show, counting ties column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" label Whether show rank label heatmap","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_doc_word_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a heatmap of ranked features — plot_doc_word_heatmap","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts(lemma = TRUE) |>   identify_by(part) |>   standardize_titles()  # Make a smaller example selected_titles <-   c(\"The Sisters\", \"An Encounter\", \"Araby\",     \"Counterparts\", \"The Dead\")  dubliners |>   dplyr::filter(doc_id %in% selected_titles) |>   plot_doc_word_heatmap()   dubliners |>   dplyr::filter(doc_id %in% selected_titles) |>   plot_doc_word_heatmap(feature = lemma, rows = 1:6)"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":null,"dir":"Reference","previous_headings":"","what":"Project hapax legomena onto vocabulary growth — plot_hapax","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"plot_hapax() visualizes sampling hapax legomena projected faceted curves vocabulary growth time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"","code":"plot_hapax(   df,   prop = 0.01,   x = progress_words,   y = vocabulary,   by = doc_id,   descriptive_labels = TRUE,   feature = hapax )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" prop proportion hapax sample. chart can become illegible proportions ~1% x progress column show. Default option progress_percent, progress_words also appropriate. y Y-axis variable chart. Default value cumulative vocabulary size. grouping column, doc_id descriptive_labels toggle disabling descriptive labels progress_percent X-axis feature column check new features. Defaults hapax, function might also used new_word instead plot sample new additions documents' vocabularies.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_hapax.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Project hapax legomena onto vocabulary growth — plot_hapax","text":"","code":"if (FALSE) {   dubliners <- get_gutenberg_corpus(2814) |>     load_texts() |>     identify_by(part) |>     standardize_titles()    dubliners_measured <- dubliners |>     add_vocabulary()    dubliners_measured |>     plot_hapax() }"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":null,"dir":"Reference","previous_headings":"","what":"Show hapax-token ratio over time — plot_htr","title":"Show hapax-token ratio over time — plot_htr","text":"Show hapax-token ratio time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show hapax-token ratio over time — plot_htr","text":"","code":"plot_htr(   df,   x = progress_words,   by = doc_id,   identity = doc_id,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inline\", \"axis\", \"inset\"),   log_y = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show hapax-token ratio over time — plot_htr","text":"df tidy data frame, potentially containing column called \"doc_id\" \"word\" x progress column show. Default option progress_percent, progress_words also appropriate. grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show hapax-token ratio over time — plot_htr","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_htr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show hapax-token ratio over time — plot_htr","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners_measured <- dubliners |>   add_vocabulary()  dubliners_measured |>   standardize_titles() |>   plot_htr()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the top terms by tf-idf — plot_tf_idf","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"Visualize top terms tf-idf","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"","code":"plot_tf_idf(   df,   rows = 1:10,   by = doc_id,   feature = word,   label = FALSE,   label_tweak = 2,   label_inside = FALSE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" rows rows terms chart document column containing document grouping feature column containing terms measured across document groupings label yet working label_tweak yet working label_inside yet working","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_tf_idf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize the top terms by tf-idf — plot_tf_idf","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   plot_tf_idf()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot bars for words in each topic — plot_topic_bars","title":"Plot bars for words in each topic — plot_topic_bars","text":"Plot bars words topic","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot bars for words in each topic — plot_topic_bars","text":"","code":"plot_topic_bars(   lda,   topics,   top_n = 10,   expand_bars = TRUE,   save = TRUE,   saveas = \"png\",   savedir = \"plots\" )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot bars for words in each topic — plot_topic_bars","text":"lda topic model used. topics topic numbers view top_n number words show topic expand_bars Whether stretch bars length X-axis facet save default, visualization saved. Set FALSE skip saving. saveas filetype saving resulting visualizations. default, files \"png\" format, options \"pdf\" \"jpg also work. savedir directory saving output images. default, set \"plots/\".","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot bars for words in each topic — plot_topic_bars","text":"ggplot2 visualization showing top words chosen topics.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_bars.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot bars for words in each topic — plot_topic_bars","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  austen_lda |>   plot_topic_bars(topics = c(22, 6)) +   labs(title = \"Competing topics in Northanger Abbey\")"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot topic distributions — plot_topic_distributions","title":"Plot topic distributions — plot_topic_distributions","text":"plot_topic_distributions() prepares visualization exploring significant topics document time.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot topic distributions — plot_topic_distributions","text":"","code":"plot_topic_distributions(   lda,   top_n = 4,   direct_label = TRUE,   title = TRUE,   save = TRUE,   saveas = \"png\",   savedir = \"plots\",   omit = NULL,   smooth = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot topic distributions — plot_topic_distributions","text":"lda topic model used. top_n number topics visualize. default, top 4 topics document shown. direct_label default, directly labels topic numbers chart. Set FALSE show legend corresponding color. title default, function add title chart, corresponding name object passed lda parameter. Set FALSE return chart title. save default, visualization saved. Set FALSE skip saving. saveas filetype saving resulting visualizations. default, files \"png\" format, options \"pdf\" \"jpg also work. savedir directory saving output images. default, set \"plots/\". omit Upon exploration, topics may found contain common stop words unhelpful material. Use omit parameter define vector topic numbers wish omit visualization. smooth samples rejoined, measured value topic vary wildly, even samples beside document. can make charts distractingly jittery. default TRUE value parameter reduces chart noise calculating rolling averages across three samples. Set parameter FALSE skip step allow visualization extreme values.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot topic distributions — plot_topic_distributions","text":"ggplot2 visualization showing vertical facets texts. length text shown X-axis, area plots Y-axis show distribution strongest topics part text.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_distributions.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot topic distributions — plot_topic_distributions","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  plot_topic_distributions(austen_lda)"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot topic wordclouds — plot_topic_wordcloud","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"plot_topic_wordcloud() prepares, saves, displays word clouds topics topic model. function can display word clouds one specific topics, can show word clouds every topic.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"","code":"plot_topic_wordcloud(lda, topics = NULL, crop = TRUE, savedir = \"plots\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"lda topic model used. topics Topic numbers visualized. left undefined, topics visualized crop Whether remove white space visualized word clouds savedir directory save plots . Defaults \"plots\"","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"Graphic(s) prepared knitr Quarto RMarkdown","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_topic_wordcloud.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot topic wordclouds — plot_topic_wordcloud","text":"","code":"austen <-   get_gutenberg_corpus(c(105, 121, 141, 158, 161, 946, 1342)) |>   dplyr::select(doc_id = title, text)  austen_lda <-   austen |>   make_topic_model(k = 30)  austen_lda |>   plot_topic_wordcloud(topic = 6)"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":null,"dir":"Reference","previous_headings":"","what":"Show type-token ratio over time — plot_ttr","title":"Show type-token ratio over time — plot_ttr","text":"Show type-token ratio time","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show type-token ratio over time — plot_ttr","text":"","code":"plot_ttr(   df,   x = progress_words,   by = doc_id,   identity = NULL,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inline\", \"axis\", \"inset\"),   log_y = TRUE )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show type-token ratio over time — plot_ttr","text":"df tidy data frame, potentially containing column called \"doc_id\" \"word\" x progress column show. Default option progress_percent, progress_words also appropriate. grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show type-token ratio over time — plot_ttr","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_ttr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show type-token ratio over time — plot_ttr","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners_measured <- dubliners |>   add_vocabulary()  dubliners_measured |>   plot_ttr(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")' #> Error in geomtextpath::geom_textsmooth(ggplot2::aes(label = {    {        by    }}), hjust = 0.9, method = \"gam\"): Problem while converting geom to grob. #> ℹ Error occurred in the 1st layer. #> Caused by error in `txt$shape[, shape_vars]`: #> ! Can't subset columns that don't exist. #> ✖ Column `x_midpoint` doesn't exist.  dubliners_measured |>   plot_ttr()"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Show vocabulary growth — plot_vocabulary","title":"Show vocabulary growth — plot_vocabulary","text":"plot_vocabulary() visualizes vocabulary growth new words used document.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show vocabulary growth — plot_vocabulary","text":"","code":"plot_vocabulary(   df,   x = progress_words,   by = doc_id,   identity = NULL,   descriptive_labels = TRUE,   labeling = c(\"point\", \"inset\", \"inline\", \"axis\") )"},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show vocabulary growth — plot_vocabulary","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" x column showing cumulative count words grouping column colors labels identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show vocabulary growth — plot_vocabulary","text":"ggplot object","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/plot_vocabulary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show vocabulary growth — plot_vocabulary","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners_measured <- dubliners |>   add_vocabulary()  dubliners_measured |>   plot_vocabulary(progress_percent)   dubliners_measured |>   plot_vocabulary()   if (FALSE) {   get_micusp_corpus(     discipline %in% c(\"Physics\", \"Economics\")) |>     load_texts() |>     add_vocabulary() |>     plot_vocabulary(by = discipline) }"},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":null,"dir":"Reference","previous_headings":"","what":"Part of speech tags — pos_tags","title":"Part of speech tags — pos_tags","text":"Tags descriptions English parts speech, designated Penn Treebank Project.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Part of speech tags — pos_tags","text":"","code":"pos_tags"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"-pos-tags-","dir":"Reference","previous_headings":"","what":"\"pos_tags\"","title":"Part of speech tags — pos_tags","text":"data frame 36 rows 2 columns tag speech tag description meaning tag","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/pos_tags.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Part of speech tags — pos_tags","text":"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate one word per column — separate_ngrams","title":"Separate one word per column — separate_ngrams","text":"Separate one word per column","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate one word per column — separate_ngrams","text":"","code":"separate_ngrams(df, names_prefix = \"word\")"},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate one word per column — separate_ngrams","text":"df tidy data frame containing column called \"ngram\" names_prefix prefixed name new columns, \"word_1\", \"word_2\", etc.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Separate one word per column — separate_ngrams","text":"data frame one column separated many","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/separate_ngrams.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Separate one word per column — separate_ngrams","text":"","code":"if (FALSE) {   my_corpus <- load_texts(n = 2)    my_bigrams <- my_corpus |>     separate_ngrams() }  dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   add_ngrams() |>   combine_ngrams() |>   separate_ngrams() |>   head() #> # A tibble: 6 × 6 #>   doc_id      title     author       part        word_1 word_2 #>   <fct>       <chr>     <chr>        <chr>       <chr>  <chr>  #> 1 The Sisters Dubliners Joyce, James THE SISTERS there  was    #> 2 The Sisters Dubliners Joyce, James THE SISTERS was    no     #> 3 The Sisters Dubliners Joyce, James THE SISTERS no     hope   #> 4 The Sisters Dubliners Joyce, James THE SISTERS hope   for    #> 5 The Sisters Dubliners Joyce, James THE SISTERS for    him    #> 6 The Sisters Dubliners Joyce, James THE SISTERS him    this"},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize document titles — standardize_titles","title":"Standardize document titles — standardize_titles","text":"Useful especially visualizations. standardize_titles applies English-language conventions, including converting underscores spaces, capitalizing important words, removing leading articles, dropping subtitles.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize document titles — standardize_titles","text":"","code":"standardize_titles(.data, title = doc_id, drop_articles = FALSE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize document titles — standardize_titles","text":".data tidy data frame, potentially containing title column called \"doc_id\". Alternatively, simple character vector titles. title column containing titles standardized drop_articles Whether remove opening articles like \"\" \"\"","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize document titles — standardize_titles","text":"data frame one column adjusted. .data character vector instead data frame, character vector returned.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/standardize_titles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize document titles — standardize_titles","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part)  ##### Standardizing strings ##### # Before `standardize_titles()` unique(dubliners$doc_id) #>  [1] THE SISTERS                   AN ENCOUNTER                  #>  [3] ARABY                         EVELINE                       #>  [5] AFTER THE RACE                TWO GALLANTS                  #>  [7] THE BOARDING HOUSE            A LITTLE CLOUD                #>  [9] COUNTERPARTS                  CLAY                          #> [11] A PAINFUL CASE                IVY DAY IN THE COMMITTEE ROOM #> [13] A MOTHER                      GRACE                         #> [15] THE DEAD                      #> 15 Levels: THE SISTERS AN ENCOUNTER ARABY EVELINE ... THE DEAD  # After `standardize_titles()` unique(dubliners$doc_id) |>   standardize_titles() #>  [1] The Sisters                   An Encounter                  #>  [3] Araby                         Eveline                       #>  [5] After the Race                Two Gallants                  #>  [7] The Boarding House            A Little Cloud                #>  [9] Counterparts                  Clay                          #> [11] A Painful Case                Ivy Day in the Committee Room #> [13] A Mother                      Grace                         #> [15] The Dead                      #> 15 Levels: The Sisters An Encounter Araby Eveline ... The Dead  ##### Standardizing a data frame #####  dubliners_measured <- dubliners |>   add_vocabulary()  # Before `standardize_titles()` dubliners_measured |>   plot_vocabulary(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")' #> Error in geomtextpath::geom_textsmooth(ggplot2::aes(label = {    {        by    }}), hjust = 0.9, method = \"gam\"): Problem while converting geom to grob. #> ℹ Error occurred in the 1st layer. #> Caused by error in `txt$shape[, shape_vars]`: #> ! Can't subset columns that don't exist. #> ✖ Column `x_midpoint` doesn't exist.  # After `standardize_titles()` dubliners_measured |>   standardize_titles() |>   plot_vocabulary(labeling = \"inline\") #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")' #> Error in geomtextpath::geom_textsmooth(ggplot2::aes(label = {    {        by    }}), hjust = 0.9, method = \"gam\"): Problem while converting geom to grob. #> ℹ Error occurred in the 1st layer. #> Caused by error in `txt$shape[, shape_vars]`: #> ! Can't subset columns that don't exist. #> ✖ Column `x_midpoint` doesn't exist."},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare usage across a corpus — summarize_tf_idf","title":"Compare usage across a corpus — summarize_tf_idf","text":"summarize_tf_idf() prepares summary table term corpus, including frequencies document \"tf-idf\" measurements comparing relative importance comparison documents set.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare usage across a corpus — summarize_tf_idf","text":"","code":"summarize_tf_idf(df, by = doc_id, feature = word)"},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare usage across a corpus — summarize_tf_idf","text":"df tidy data frame, potentially containing columns called \"doc_id\" \"word\" column containing document grouping feature column containing terms measured across document groupings","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare usage across a corpus — summarize_tf_idf","text":"summary original data frame, rows document term pairing columns document identifier, term, n (number times term used document), tf (term's frequency document), idf (inverse document frequency), tf_idf (previous two columns combined).","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/summarize_tf_idf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare usage across a corpus — summarize_tf_idf","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  dubliners |>   summarize_tf_idf() #> # A tibble: 17,686 × 6 #>    doc_id                        word         n      tf   idf tf_idf #>    <fct>                         <chr>    <int>   <dbl> <dbl>  <dbl> #>  1 Clay                          maria       40 0.0150   2.71 0.0407 #>  2 Two Gallants                  corley      46 0.0117   2.71 0.0318 #>  3 After the Race                jimmy       24 0.0107   2.71 0.0290 #>  4 Ivy Day in the Committee Room henchy      53 0.0101   2.71 0.0274 #>  5 A Little Cloud                gallaher    48 0.00972  2.71 0.0263 #>  6 The Dead                      gabriel    142 0.00903  2.71 0.0244 #>  7 Grace                         kernan      66 0.00875  2.71 0.0237 #>  8 Ivy Day in the Committee Room o’connor    45 0.00858  2.71 0.0232 #>  9 A Little Cloud                chandler    41 0.00830  2.71 0.0225 #> 10 A Mother                      kearney     50 0.0110   2.01 0.0222 #> # ℹ 17,676 more rows"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.combined_ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","title":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","text":"Prepare table n-gram frequencies","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.combined_ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","text":"","code":"# S3 method for combined_ngrams tabulize(.data, rows = NULL, count = TRUE, digits = 2, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.combined_ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of n-gram frequencies — tabulize.combined_ngrams","text":".data data processed one functions tmtyro rows Chooses rows shown count Determines whether frequencies counted individual features digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a default table view — tabulize.default","title":"Prepare a default table view — tabulize.default","text":"Prepare default table view","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a default table view — tabulize.default","text":"","code":"# S3 method for default tabulize(   .data,   summary = TRUE,   inorder = TRUE,   count = FALSE,   rows = NULL,   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a default table view — tabulize.default","text":".data data processed one functions tmtyro summary Indicates whether prepare summary table rows exist inorder Indicates whether labels doc_id column order preserved count Determines whether frequencies counted individual features rows Chooses rows shown ... optional parameters (unused)","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.expanded.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table showing a document-feature matrix — tabulize.expanded","title":"Prepare a table showing a document-feature matrix — tabulize.expanded","text":"Prepare table showing document-feature matrix","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.expanded.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table showing a document-feature matrix — tabulize.expanded","text":"","code":"# S3 method for expanded tabulize(.data, columns = NULL, digits = 2, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.expanded.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table showing a document-feature matrix — tabulize.expanded","text":".data data processed one functions tmtyro columns Chooses columns shown digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of data — tabulize","title":"Prepare a table of data — tabulize","text":"tabulize() provides simple method sharing results. Based previous functions used, tabulize() choose method, resolving one set tables.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of data — tabulize","text":"","code":"tabulize(.data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of data — tabulize","text":".data data processed one functions tmtyro ... Arguments passed tabulize.default summary Indicates whether prepare summary table rows exist inorder Indicates whether labels doc_id column order preserved count Determines whether frequencies counted individual features rows Chooses rows shown","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare a table of data — tabulize","text":"gt table data object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare a table of data — tabulize","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  # A data frame with `doc_id` and `word` columns will show word counts by default dubliners |>    tabulize() # Applying tmtyro functions will prepare other tables   dubliners |>    add_vocabulary() |>    tabulize() dubliners |>      dplyr::filter(doc_id == \"The Dead\") |>      add_sentiment() |>      tabulize()"},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.ngrams.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of n-gram frequencies — tabulize.ngrams","title":"Prepare a table of n-gram frequencies — tabulize.ngrams","text":"Prepare table n-gram frequencies","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.ngrams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of n-gram frequencies — tabulize.ngrams","text":"","code":"# S3 method for ngrams tabulize(.data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.ngrams.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of n-gram frequencies — tabulize.ngrams","text":".data data processed one functions tmtyro ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.sentiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table for sentiment analysis — tabulize.sentiment","title":"Prepare a table for sentiment analysis — tabulize.sentiment","text":"Prepare table sentiment analysis","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.sentiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table for sentiment analysis — tabulize.sentiment","text":"","code":"# S3 method for sentiment tabulize(   .data,   inorder = TRUE,   digits = 2,   drop_na = FALSE,   ignore = NULL,   rows = NULL,   count = TRUE,   ... )"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.sentiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table for sentiment analysis — tabulize.sentiment","text":".data data processed one functions tmtyro inorder Indicates whether labels doc_id column order preserved digits number digits show past decimal point drop_na Removes rows lacking sentiment ignore Removes rows matching set sentiments rows Chooses rows shown count Determines whether frequencies counted sentiments ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.tf_idf.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of term frequency--inverse document frequency — tabulize.tf_idf","title":"Prepare a table of term frequency--inverse document frequency — tabulize.tf_idf","text":"Prepare table term frequency--inverse document frequency","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.tf_idf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of term frequency--inverse document frequency — tabulize.tf_idf","text":"","code":"# S3 method for tf_idf tabulize(.data, rows = NULL, digits = 5, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.tf_idf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of term frequency--inverse document frequency — tabulize.tf_idf","text":".data data processed one functions tmtyro rows Chooses rows shown digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.vocabulary.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare a table of lexical variety — tabulize.vocabulary","title":"Prepare a table of lexical variety — tabulize.vocabulary","text":"Prepare table lexical variety","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.vocabulary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare a table of lexical variety — tabulize.vocabulary","text":"","code":"# S3 method for vocabulary tabulize(.data, digits = 3, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/tabulize.vocabulary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare a table of lexical variety — tabulize.vocabulary","text":".data data processed one functions tmtyro digits number digits show past decimal point ... optional parameters passed along methods","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/tmtyro-package.html","id":null,"dir":"Reference","previous_headings":"","what":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","title":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","text":"Work analyze text simple complex features. Adopting tidytext principles, tmtyro abstracts processes levels allow beginners use familiarize techniques understand much code.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/tmtyro-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"tmtyro: tmtyro: Simplified Workflows for Text Mining Tyros — tmtyro-package","text":"Maintainer: James Clawson clawson@gmail.com (ORCID)","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":null,"dir":"Reference","previous_headings":"","what":"Split text into words and drop proper nouns — unnest_without_caps","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"Split column text using tidytext::unnest_tokens(), flattening table one token per row also omitting token present capitalized form.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"","code":"unnest_without_caps(df, output = \"word\", input = \"text\", to_lower = TRUE)"},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"df data frame output Output column created. input Input column gets split word. to_lower Whether convert final words lowercase.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"data frame","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/unnest_without_caps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split text into words and drop proper nouns — unnest_without_caps","text":"","code":"if (FALSE) { mysteries <-   load_texts(\"mystery-novels\",              to_lower = FALSE) |>   unnest_without_caps()  # Since `unnest_without_caps()` is # incorporated into `load_texts()`, # it may be unnecessary for many # scenarios. mysteries <-   load_texts(\"mystery-novels\",              remove_names = TRUE)   }"},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize output — visualize","title":"Visualize output — visualize","text":"visualize() provides simple method displaying results. Based previous functions used, visualize() choose method, resolving one visualizing helpers.","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize output — visualize","text":"","code":"visualize(.data, ...)"},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize output — visualize","text":".data data processed one functions tmtyro ... Arguments passed plot_doc_word_bars, plot_bigrams, plot_vocabulary, plot_ttr, plot_htr, plot_topic_distributions, plot_topic_bars, plot_topic_wordcloud rows features show column used document grouping, doc_id default feature column measure, \"word\" \"lemma\" inorder Whether retain factor order \"\" column reorder_y Whether reorder Y-values facet color_y Whether bars filled Y-values percents Whether display word frequencies percentage instead raw counts label Whether show value label bar label_tweak numeric value tweak label, shown. percentages, value adjusts decimal-point precision. raw counts, value adjusts labels' offset bars label_inside Whether show value label inside bar na_rm Whether drop empty features random_seed Whether randomize creation network chart. set_seed specific seed use random legend Whether show legend edge color top_n number pairs visualize identity grouping column lines descriptive_labels toggle disabling descriptive labels progress_percent X-axis labeling Options labeling groups: \"point\" labels final value \"inline\" prints label within smoothed curve \"axis\" prints labels secondary Y-axis might go \"inset\" prints legend within plot area Anything else prints legend right plot area. log_y toggle logarithmic scaling Y-axis; defaults TRUE topics topic numbers view","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize output — visualize","text":"ggplot2 object","code":""},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Visualize output — visualize","text":"visualizations, optional type parameter may helpful change visualization. example, setting type = \"htr\", type = \"ttr\", type = \"hapax\" add_vocabulary() emphasize different columns added function. Similarly, type = \"cloud\" type = \"wordcloud\" show topic word clouds make_topic_model(), type = \"heatmap\" show alternative visualization word frequencies.","code":""},{"path":[]},{"path":"https://jmclawson.github.io/tmtyro/reference/visualize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize output — visualize","text":"","code":"dubliners <- get_gutenberg_corpus(2814) |>   load_texts() |>   identify_by(part) |>   standardize_titles()  # A data frame with `doc_id` and `word` columns will visualize frequency by default dubliners |>    visualize()   # Applying `tmtyro` functions will choose an appropriate visualization  dubliners |>    add_ngrams() |>    visualize()   dubliners |>    add_ngrams() |>    combine_ngrams() |>    visualize()   dubliners |>    summarize_tf_idf() |>    visualize()   dubliners |>    add_vocabulary() |>    visualize()   if (FALSE) { # sentiment requires interaction on first load   dubliners |>      add_sentiment() |>      visualize() }  # Some visualizations are specified with the `type` argument dubliners |>    add_vocabulary() |>    visualize(type = \"ttr\")   if (FALSE) { # puzzlingly broken for Dubliners, but usually works dubliners |>    add_vocabulary() |>    visualize(type = \"hapax\") }  # Other arguments get passed along dubliners |>    add_ngrams() |>    visualize(top_n = 25)   dubliners |>    add_vocabulary() |>    visualize(x = progress_percent)"},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-020","dir":"Changelog","previous_headings":"","what":"tmtyro 0.2.0","title":"tmtyro 0.2.0","text":"add_partitions() adds partition column, useful getting -sized samples identify_by() now works multiple columns, keeps existing metadata columns. especially useful new add_partitions() column, using something like my_corpus() |> add_partitions() |> identify_by(title, partition) continuing work partitioned documents. return framing unpartitioned data, used identify_by(title) whatever column relevant. New visualization tabulization methods expand_documents() Functions now imported: count() drop_na() ggraph package loaded, plot_bigrams() now uses color scale edges, rather spot color nodes, full support change_color() Improved documentation website articles customizing colors showing code comparisons","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-010","dir":"Changelog","previous_headings":"","what":"tmtyro 0.1.0","title":"tmtyro 0.1.0","text":"First “public” release! 🎉 Unnecessary components removed dependencies reduced Examples standardized made reproducible change_colors() now works plot_bigrams() change_colors() now includes “dubois” colorset tabulize() documentation now improved online output standardize_titles() now works factors Added default behavior visualize() corpus Part speech tagging now work texts","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-development-version-0089000","dir":"Changelog","previous_headings":"","what":"tmtyro (development version 0.0.8.9000)","title":"tmtyro (development version 0.0.8.9000)","text":"New tabulize() generic function preparing tables supported methods Standardizing argument names visualize() tabulize() New package documentation getting started New collapse_rows() function clean tables using gt::gt() New feature standardize_titles() keep initial articles New options plot_doc_word_bars() keep order Y-axis values consistent color Y-axis value instead facet Rename add_lexical_diversity() add_vocabulary() Add option renaming existing doc_id column using identify_by()","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-development-version-0079000","dir":"Changelog","previous_headings":"","what":"tmtyro (development version 0.0.7.9000)","title":"tmtyro (development version 0.0.7.9000)","text":"get_gutenberg_corpus() now retrieves HTML versions texts Project Gutenberg parses header tags section markers New function parse_html() reading headers HTML file New function move_header_to_text() converting header text New function identify_by() simplify using something doc_id Improved internal linking within documentation","code":""},{"path":"https://jmclawson.github.io/tmtyro/news/index.html","id":"tmtyro-development-version-0069000","dir":"Changelog","previous_headings":"","what":"tmtyro (development version 0.0.6.9000)","title":"tmtyro (development version 0.0.6.9000)","text":"Better working visualize() function generic supported methods Improved change_colors() added support Okabe-Ito colorset option starting something first color palette. changes, color options removed visualization functions consolidate within change_colors(). data set includes one unique doc_id, visualizations longer divided facets. effort reduce number dependencies, many packages removed “Imports” (geomtextpath, ggrepel, glue, NLP, openNLP, plotly, RColorBrewer, stopwords, textstem, wordcloud). appropriate, shifted “Suggests” dropped entirely.","code":""}]
